import { useRef, useState, useCallback, useEffect } from 'react';
import { Scribe, AudioFormat, RealtimeEvents, CommitStrategy } from "@elevenlabs/client";

interface ScribeConfig {
  languageCode?: string;
  onPartialTranscript?: (text: string) => void;
  onFinalTranscript?: (text: string, timestamps?: any) => void;
  onError?: (error: any) => void;
}

export function useElevenLabsRealtimeSTT(config: ScribeConfig = {}) {
  const [isConnected, setIsConnected] = useState(false);
  const [partialText, setPartialText] = useState('');
  const [finalText, setFinalText] = useState('');
  const connectionRef = useRef<any>(null);

  // Store all committed transcripts for combining when connection closes
  const allTranscriptsRef = useRef<string[]>([]);

  // Store callbacks in refs to avoid dependency issues
  const callbacksRef = useRef(config);

  // Update callbacks ref when config changes
  useEffect(() => {
    callbacksRef.current = config;
  }, [config]);

  const connect = useCallback(async () => {
    try {
      console.log('ðŸ”Œ Starting connection to ElevenLabs Scribe...');

      // Reset transcript accumulator for new session
      allTranscriptsRef.current = [];

      // Reset UI state for fresh session
      setFinalText('');
      setPartialText('');

      // 1. Get single-use token from backend
      const tokenRes = await fetch('/api/elevenlabs-stt-token', {
        method: 'POST'
      });
      const { token } = await tokenRes.json();
      console.log('âœ… Token received');

      // 2. Connect with Scribe SDK
      console.log('ðŸŽ¤ Requesting microphone access...');

      const connection = Scribe.connect({
        token,
        modelId: "scribe_v2_realtime",
        languageCode: callbacksRef.current.languageCode || "th",
        audioFormat: AudioFormat.PCM_16000,
        commitStrategy: CommitStrategy.VAD,
        vadSilenceThresholdSecs: 1.5,
        vadThreshold: 0.4,
        minSpeechDurationMs: 100,
        minSilenceDurationMs: 100,
        // âœ… CRITICAL FIX: Enable automatic microphone capture
        microphone: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      } as any);

      console.log('ðŸ“¦ Connection object created');
      connectionRef.current = connection;

      // 3. Handle events
      connection.on(RealtimeEvents.SESSION_STARTED, () => {
        console.log('âœ… SESSION_STARTED - ElevenLabs Scribe session started');
        console.log('ðŸŽ™ï¸ You can now speak into your microphone...');
        setIsConnected(true);
      });

      connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data: any) => {
        console.log('ðŸŽ¤ PARTIAL_TRANSCRIPT:', data.text);
        setPartialText(data.text);
        callbacksRef.current.onPartialTranscript?.(data.text);
      });

      connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data: any) => {
        console.log('âœ… COMMITTED_TRANSCRIPT:', data.text);

        // Store transcript for combining later
        allTranscriptsRef.current.push(data.text);

        setFinalText(prev => prev + ' ' + data.text);
        callbacksRef.current.onFinalTranscript?.(data.text);
        setPartialText('');
      });

      connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS, (data: any) => {
        console.log('ðŸ“ COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS:', data);
        callbacksRef.current.onFinalTranscript?.(data.text, data.timestamps);
      });

      connection.on(RealtimeEvents.ERROR, (error: any) => {
        console.error('âŒ ERROR:', error);
        callbacksRef.current.onError?.(error);
      });

      connection.on(RealtimeEvents.AUTH_ERROR, (error: any) => {
        console.error('ðŸš« AUTH_ERROR:', error);
        callbacksRef.current.onError?.(error);
      });

      connection.on(RealtimeEvents.CLOSE, () => {
        console.log('ðŸ”Œ CONNECTION CLOSED');

        // Display combined transcript from the entire session
        if (allTranscriptsRef.current.length > 0) {
          const combinedText = allTranscriptsRef.current.join(' ');
          console.log('ðŸ“ [REALTIME STT] Combined full transcript:', combinedText);
          console.log('ðŸ“Š [REALTIME STT] Total segments:', allTranscriptsRef.current.length);
          console.log('ðŸ“Š [REALTIME STT] Total length:', combinedText.length, 'characters');
        } else {
          console.log('ðŸ“ [REALTIME STT] No transcripts in this session');
        }

        setIsConnected(false);
      });

    } catch (error) {
      console.error('âŒ Failed to connect:', error);
      callbacksRef.current.onError?.(error);
    }
  }, []); // Empty dependency array - callbacks handled via ref

  const disconnect = useCallback(() => {
    if (connectionRef.current) {
      connectionRef.current.close();
      connectionRef.current = null;
    }
    setIsConnected(false);
    setPartialText('');
  }, []);

  const reset = useCallback(() => {
    setFinalText('');
    setPartialText('');
  }, []);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      disconnect();
    };
  }, [disconnect]);

  return {
    isConnected,
    partialText,
    finalText,
    connect,
    disconnect,
    reset
  };
}
