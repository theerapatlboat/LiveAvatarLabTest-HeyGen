# TROUBLESHOOTING: ElevenLabs Realtime STT Integration

## ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Connection ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ Transcript ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤

### üîç Symptoms (‡∏≠‡∏≤‡∏Å‡∏≤‡∏£)
- ‚úÖ "SESSION_STARTED" ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô console
- ‚úÖ "Connected: true" ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô UI
- ‚úÖ Microphone permission ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÅ‡∏•‡πâ‡∏ß
- ‚ùå ‡πÅ‡∏ï‡πà‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏π‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏°‡∏Ñ‡πå ‡πÑ‡∏°‡πà‡∏°‡∏µ PARTIAL_TRANSCRIPT ‡∏´‡∏£‡∏∑‡∏≠ COMMITTED_TRANSCRIPT logs
- ‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô partial text ‡∏´‡∏£‡∏∑‡∏≠ final text ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô UI
- ‚úÖ ‡∏õ‡∏∏‡πà‡∏° "Hold to Talk" (OpenAI Whisper) ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏õ‡∏Å‡∏ï‡∏¥

### üêõ Root Cause (‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏´‡∏•‡∏±‡∏Å)

#### **PRIMARY ISSUE: Missing `microphone` Configuration Object** ‚ö†Ô∏è

**‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤!**

SDK ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ `microphone` configuration object ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô **automatic microphone capture**:

```typescript
// ‚ùå ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡πÑ‡∏°‡πà‡∏°‡∏µ microphone config - Connection ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á!
const connection = Scribe.connect({
  token,
  modelId: "scribe_v2_realtime",
  languageCode: "th",
  // ... missing microphone config!
});
```

**‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö:**
- Connection ‡∏à‡∏∞‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (SESSION_STARTED event fires)
- ‡πÅ‡∏ï‡πà SDK ‡∏à‡∏∞**‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡∏Ñ‡πå‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥**
- ‡πÑ‡∏°‡πà‡∏°‡∏µ audio stream ‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏ó‡∏µ‡πà ElevenLabs API
- ‡∏à‡∏∂‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ transcripts ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤

**‚úÖ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ (CRITICAL FIX):**
```typescript
const connection = Scribe.connect({
  token,
  modelId: "scribe_v2_realtime",
  languageCode: "th",
  audioFormat: AudioFormat.PCM_16000,
  commitStrategy: CommitStrategy.VAD,
  // ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° microphone config ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô automatic capture
  microphone: {
    echoCancellation: true,    // ‡∏•‡∏î echo
    noiseSuppression: true,     // ‡∏•‡∏î background noise
    autoGainControl: true,      // ‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
  },
});
```

**‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:** [ElevenLabs Realtime STT Documentation](https://elevenlabs.io/docs/cookbooks/speech-to-text/streaming)

---

#### 2. **Secondary Issue: React useCallback Dependency** (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß)

```typescript
// ‚ùå ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏£‡∏≠‡∏á: config object ‡πÉ‡∏ô dependency array
const connect = useCallback(async () => {
  // ... code that uses config
}, [config]); // config ‡πÄ‡∏õ‡πá‡∏ô object ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å render
```

**‚úÖ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
```typescript
// ‡πÉ‡∏ä‡πâ ref ‡πÅ‡∏ó‡∏ô direct config access
const callbacksRef = useRef(config);

useEffect(() => {
  callbacksRef.current = config;
}, [config]);

const connect = useCallback(async () => {
  // ‡πÉ‡∏ä‡πâ callbacksRef.current ‡πÅ‡∏ó‡∏ô config
  const connection = Scribe.connect({
    languageCode: callbacksRef.current.languageCode || "th",
    // ...
  });
}, []); // Empty dependency array
```

### üîß Solution (‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤)

#### Step 1: ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç `useElevenLabsRealtimeSTT.ts`

‡πÑ‡∏ü‡∏•‡πå: `apps/demo/src/liveavatar/useElevenLabsRealtimeSTT.ts`

**‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÅ‡∏•‡πâ‡∏ß:**

1. **‚úÖ CRITICAL: ‡πÄ‡∏û‡∏¥‡πà‡∏° `microphone` configuration object ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ automatic audio capture**
2. **‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° callback refs ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á dependency issues**
3. **‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° detailed logging ‡πÄ‡∏û‡∏∑‡πà‡∏≠ debug**
4. **‚úÖ ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á event listeners**

```typescript
import { useRef, useState, useCallback, useEffect } from 'react';
import { Scribe, AudioFormat, RealtimeEvents, CommitStrategy } from "@elevenlabs/client";

interface ScribeConfig {
  languageCode?: string;
  onPartialTranscript?: (text: string) => void;
  onFinalTranscript?: (text: string, timestamps?: any) => void;
  onError?: (error: any) => void;
}

export function useElevenLabsRealtimeSTT(config: ScribeConfig = {}) {
  const [isConnected, setIsConnected] = useState(false);
  const [partialText, setPartialText] = useState('');
  const [finalText, setFinalText] = useState('');
  const connectionRef = useRef<any>(null);

  // ‚úÖ FIX: Store callbacks in refs to avoid dependency issues
  const callbacksRef = useRef(config);

  // ‚úÖ FIX: Update callbacks ref when config changes
  useEffect(() => {
    callbacksRef.current = config;
  }, [config]);

  const connect = useCallback(async () => {
    try {
      console.log('üîå Starting connection to ElevenLabs Scribe...');

      // 1. Get single-use token from backend
      const tokenRes = await fetch('/api/elevenlabs-stt-token', {
        method: 'POST'
      });
      const { token } = await tokenRes.json();
      console.log('‚úÖ Token received');

      // 2. Connect with Scribe SDK
      console.log('üé§ Requesting microphone access...');

      const connection = Scribe.connect({
        token,
        modelId: "scribe_v2_realtime",
        languageCode: callbacksRef.current.languageCode || "th",
        audioFormat: AudioFormat.PCM_16000,
        commitStrategy: CommitStrategy.VAD,
        vadSilenceThresholdSecs: 1.5,
        vadThreshold: 0.4,
        minSpeechDurationMs: 100,
        minSilenceDurationMs: 100,
        // ‚úÖ CRITICAL FIX: Enable automatic microphone capture
        microphone: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      } as any);

      console.log('üì¶ Connection object created');
      connectionRef.current = connection;

      // 3. Handle events with proper logging
      connection.on(RealtimeEvents.SESSION_STARTED, () => {
        console.log('‚úÖ SESSION_STARTED - ElevenLabs Scribe session started');
        console.log('üéôÔ∏è You can now speak into your microphone...');
        setIsConnected(true);
      });

      connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data: any) => {
        console.log('üé§ PARTIAL_TRANSCRIPT:', data.text);
        setPartialText(data.text);
        callbacksRef.current.onPartialTranscript?.(data.text);
      });

      connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data: any) => {
        console.log('‚úÖ COMMITTED_TRANSCRIPT:', data.text);
        setFinalText(prev => prev + ' ' + data.text);
        callbacksRef.current.onFinalTranscript?.(data.text);
        setPartialText('');
      });

      connection.on(RealtimeEvents.ERROR, (error: any) => {
        console.error('‚ùå ERROR:', error);
        callbacksRef.current.onError?.(error);
      });

      connection.on(RealtimeEvents.CLOSE, () => {
        console.log('üîå CONNECTION CLOSED');
        setIsConnected(false);
      });

    } catch (error) {
      console.error('‚ùå Failed to connect:', error);
      callbacksRef.current.onError?.(error);
    }
  }, []); // ‚úÖ Empty dependency array - callbacks handled via ref

  const disconnect = useCallback(() => {
    if (connectionRef.current) {
      connectionRef.current.close();
      connectionRef.current = null;
    }
    setIsConnected(false);
    setPartialText('');
  }, []);

  const reset = useCallback(() => {
    setFinalText('');
    setPartialText('');
  }, []);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      disconnect();
    };
  }, [disconnect]);

  return {
    isConnected,
    partialText,
    finalText,
    connect,
    disconnect,
    reset
  };
}
```

#### Step 2: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç

1. **Refresh browser** (Hard refresh: Ctrl+Shift+R)
2. **Clear console** (‡∏Ñ‡∏•‡∏¥‡∏Å clear button ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏î Ctrl+L)
3. **Start Session** ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å CUSTOM Mode
4. **Click "Start Realtime Voice Chat"**
5. **‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï Microphone** (‡∏ñ‡πâ‡∏≤‡∏ñ‡∏π‡∏Å‡∏ñ‡∏≤‡∏°)
6. **‡∏û‡∏π‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏°‡∏Ñ‡πå** ‡πÄ‡∏ä‡πà‡∏ô "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö"

**Expected Logs:**
```
üîå Starting connection to ElevenLabs Scribe...
‚úÖ Token received
üé§ Requesting microphone access...
üì¶ Connection object created
‚úÖ SESSION_STARTED - ElevenLabs Scribe session started
üéôÔ∏è You can now speak into your microphone...
üé§ PARTIAL_TRANSCRIPT: ‡∏™‡∏ß‡∏±‡∏™
üé§ PARTIAL_TRANSCRIPT: ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ
üé§ PARTIAL_TRANSCRIPT: ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö
‚úÖ COMMITTED_TRANSCRIPT: ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö
```

### üîç Additional Debugging Steps

#### 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö SDK Version
```bash
# ‡πÉ‡∏ô terminal
cd apps/demo
pnpm list @elevenlabs/client

# Expected: @elevenlabs/client@0.10.0
```

#### 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Microphone Permission
```javascript
// ‡πÉ‡∏ô Browser Console
navigator.mediaDevices.getUserMedia({ audio: true })
  .then(stream => {
    console.log('‚úÖ Microphone access granted:', stream);
    stream.getTracks().forEach(track => track.stop());
  })
  .catch(error => {
    console.error('‚ùå Microphone access denied:', error);
  });
```

#### 3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö SDK ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
```javascript
// ‡πÉ‡∏ô Browser Console (‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ‡πÅ‡∏•‡πâ‡∏ß)
(async () => {
  const { Scribe, AudioFormat, RealtimeEvents, CommitStrategy } =
    await import('@elevenlabs/client');

  const tokenRes = await fetch('/api/elevenlabs-stt-token', { method: 'POST' });
  const { token } = await tokenRes.json();

  const connection = Scribe.connect({
    token,
    modelId: "scribe_v2_realtime",
    languageCode: "th",
    audioFormat: AudioFormat.PCM_16000,
    commitStrategy: CommitStrategy.VAD,
    vadSilenceThresholdSecs: 1.5,
    vadThreshold: 0.4,
    minSpeechDurationMs: 100,
    minSilenceDurationMs: 100,
    // ‚úÖ CRITICAL: Enable microphone capture
    microphone: {
      echoCancellation: true,
      noiseSuppression: true,
      autoGainControl: true,
    },
  });

  connection.on(RealtimeEvents.SESSION_STARTED, () => {
    console.log('‚úÖ Test: Session started');
  });

  connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data) => {
    console.log('‚úÖ Test: Partial:', data.text);
  });

  connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {
    console.log('‚úÖ Test: Final:', data.text);
  });

  window.testConnection = connection;
})();
```

### ‚ö†Ô∏è Known Issues

#### 1. Browser Compatibility
**Issue:** Safari ‡πÅ‡∏•‡∏∞‡∏ö‡∏≤‡∏á browser versions ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö WebSocket features ‡∏Ç‡∏≠‡∏á SDK

**Solution:**
- ‡πÉ‡∏ä‡πâ Chrome, Edge, ‡∏´‡∏£‡∏∑‡∏≠ Firefox (latest versions)
- Check browser support: https://caniuse.com/websockets

#### 2. HTTPS Required
**Issue:** ‡∏ö‡∏≤‡∏á browser ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ HTTPS ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö microphone access

**Current Setup:** localhost ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ HTTP ‡πÑ‡∏î‡πâ
**Production:** ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ HTTPS

#### 3. Token Expiration
**Issue:** Token ‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏‡πÉ‡∏ô 15 ‡∏ô‡∏≤‡∏ó‡∏µ

**Symptoms:**
- Connection ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥ ‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
- ‡πÄ‡∏´‡πá‡∏ô AUTH_ERROR ‡πÉ‡∏ô console

**Solution:**
- Disconnect ‡πÅ‡∏•‡∏∞ Connect ‡πÉ‡∏´‡∏°‡πà
- Implement auto token refresh (future enhancement)

#### 4. Multiple Microphone Inputs
**Issue:** ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ microphone ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß SDK ‡∏≠‡∏≤‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ú‡∏¥‡∏î

**Solution:**
```javascript
// Check available devices
navigator.mediaDevices.enumerateDevices()
  .then(devices => {
    const audioInputs = devices.filter(d => d.kind === 'audioinput');
    console.log('Available microphones:', audioInputs);
  });
```

### üìä Comparison: Working vs Not Working

| Aspect | ‚ùå Not Working | ‚úÖ Working |
|--------|---------------|-----------|
| **SESSION_STARTED** | ‚úÖ Shows | ‚úÖ Shows |
| **Microphone Permission** | ‚úÖ Granted | ‚úÖ Granted |
| **PARTIAL_TRANSCRIPT** | ‚ùå No logs | ‚úÖ Shows while speaking |
| **COMMITTED_TRANSCRIPT** | ‚ùå No logs | ‚úÖ Shows after silence |
| **UI Partial Text** | ‚ùå Empty | ‚úÖ Updates real-time |
| **UI Final Text** | ‚ùå Empty | ‚úÖ Shows after commit |

### üéØ Quick Fix Checklist

- [ ] ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç `useElevenLabsRealtimeSTT.ts` ‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô
- [ ] Hard refresh browser (Ctrl+Shift+R)
- [ ] Clear browser cache ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
- [ ] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö console ‡∏ß‡πà‡∏≤‡∏°‡∏µ detailed logs
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏û‡∏π‡∏î‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö"
- [ ] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏´‡πá‡∏ô PARTIAL_TRANSCRIPT logs
- [ ] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏´‡πá‡∏ô COMMITTED_TRANSCRIPT logs

### üí° Tips

1. **‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà work:**
   - ‡∏•‡∏≠‡∏á disconnect ‡πÅ‡∏•‡∏∞ connect ‡πÉ‡∏´‡∏°‡πà
   - ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ microphone ‡∏≠‡∏∑‡πà‡∏ô
   - ‡∏•‡∏≠‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô browser

2. **‡∏ñ‡πâ‡∏≤ partial transcripts ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á:**
   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏û‡∏π‡∏î‡∏î‡∏±‡∏á‡∏û‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
   - ‡∏•‡∏≠‡∏á adjust `vadThreshold` (‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏•‡∏á ‡πÄ‡∏ä‡πà‡∏ô 0.2)
   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ background noise ‡∏°‡∏≤‡∏Å

3. **‡∏ñ‡πâ‡∏≤ committed transcripts ‡∏≠‡∏≠‡∏Å‡∏ä‡πâ‡∏≤:**
   - ‡∏•‡∏î `vadSilenceThresholdSecs` (‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≤‡∏Å 1.5 ‡πÄ‡∏õ‡πá‡∏ô 1.0)
   - ‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ commit ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏á‡∏µ‡∏¢‡∏ö

### üìû Support

‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ:
1. Check ElevenLabs API status: https://status.elevenlabs.io/
2. Review ElevenLabs SDK docs: https://elevenlabs.io/docs/cookbooks/speech-to-text/streaming
3. Check browser console for any errors
4. Try the manual SDK test (above) to isolate the issue

---

## üìã Summary

### The Problem
Connection to ElevenLabs Scribe v2 Realtime was successful (SESSION_STARTED event fired), but no audio was captured from the microphone, resulting in no transcripts being generated.

### The Root Cause
**Missing `microphone` configuration object in `Scribe.connect()` call.**

The ElevenLabs SDK requires an explicit `microphone` configuration object to enable automatic microphone access and audio streaming. Without it:
- ‚úÖ Connection establishes successfully
- ‚úÖ SESSION_STARTED event fires
- ‚ùå **No audio is captured from the microphone**
- ‚ùå No transcripts are generated

### The Solution
Added the `microphone` configuration object with audio processing options:

```typescript
const connection = Scribe.connect({
  // ... other config
  microphone: {
    echoCancellation: true,
    noiseSuppression: true,
    autoGainControl: true,
  },
});
```

### Files Modified
1. **`apps/demo/src/liveavatar/useElevenLabsRealtimeSTT.ts`** - Added microphone config
2. **`documents/TROUBLESHOOTING.md`** - Documented the issue and solution

### Verification Steps
1. Hard refresh browser (Ctrl+Shift+R)
2. Clear console
3. Click "Start Realtime Voice Chat"
4. Allow microphone permission
5. Speak into microphone
6. **Expected:** PARTIAL_TRANSCRIPT and COMMITTED_TRANSCRIPT logs appear
7. **Expected:** Partial and final text displayed in UI

---

**Last Updated:** 2025-01-15
**Status:** ‚úÖ Fixed - Missing microphone configuration resolved
**Critical Fix:** Added `microphone` object to enable automatic audio capture
