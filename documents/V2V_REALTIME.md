# Voice-to-Voice Real-time Communication System
**HeyGen LiveAvatar + OpenAI + ElevenLabs Integration**

---

## üìä IMPLEMENTATION STATUS SUMMARY

### ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°: **80% ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô** ‚úÖ

| Phase | Status | Progress | Ready for Production |
|-------|--------|----------|---------------------|
| **Phase 1**: Session Management | ‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à | 100% | ‚úÖ YES |
| **Phase 2**: Voice Chat (FULL) | ‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à | 100% | ‚úÖ YES |
| **Phase 3**: Custom Voice Chat | ‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à | 100% | ‚úÖ YES |
| **Phase 4**: Realtime STT (Logs-only) | ‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à | 100% | ‚úÖ YES (testing mode) |
| **Phase 4**: Realtime STT (Full V2V) | ‚è∏Ô∏è ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô | 100% | ‚úÖ YES (uncomment code) |
| **Phase 5**: WebSocket Chat | ‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à | 0% | ‚ùå NO |
| **Phase 6**: WebSocket TTS | ‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à | 0% | ‚ùå NO |

### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Production Ready)

‚úÖ **‡πÇ‡∏´‡∏°‡∏î FULL** - Voice-to-Voice ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏î‡πâ‡∏ß‡∏¢ HeyGen built-in AI
- Latency: ~1-2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
- ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ

‚úÖ **‡πÇ‡∏´‡∏°‡∏î CUSTOM + REST APIs** - Voice-to-Voice ‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÑ‡∏î‡πâ
- Pipeline: User Speech ‚Üí Whisper STT ‚Üí OpenAI Chat ‚Üí ElevenLabs TTS ‚Üí Avatar
- Latency: ~3-5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
- ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á AI ‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏ï‡πá‡∏°‡∏ó‡∏µ‡πà

‚úÖ **‡πÇ‡∏´‡∏°‡∏î CUSTOM + ElevenLabs Realtime STT (Logs-only)** - Real-time STT Testing
- Pipeline: User Speech ‚Üí ElevenLabs Realtime STT ‚Üí Console Logs
- Latency: <500ms (real-time streaming)
- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏î Hold to Talk ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡πâ‡∏ß‡∏¢ Scribe v2
- **‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ OpenAI/ElevenLabs TTS API keys**

‚è∏Ô∏è **‡πÇ‡∏´‡∏°‡∏î CUSTOM + ElevenLabs Realtime STT (Full V2V)** - Voice-to-Voice ‡πÅ‡∏ö‡∏ö Continuous Streaming
- Pipeline: User Speech ‚Üí ElevenLabs Realtime STT ‚Üí OpenAI Chat ‚Üí ElevenLabs TTS ‚Üí Avatar
- Latency: ~2-3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ Whisper)
- **‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß - ‡πÅ‡∏Ñ‡πà uncomment code**
- ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ OpenAI API key ‡πÅ‡∏•‡∏∞ ElevenLabs TTS API key

### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏±‡∏í‡∏ô‡∏≤ (Need Implementation)

‚úÖ **Phase 4**: ElevenLabs Realtime STT (100% ‡πÄ‡∏™‡∏£‡πá‡∏à - Logs-only Mode)
- ‚úÖ API endpoint ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö token generation
- ‚úÖ React Hook ‡∏î‡πâ‡∏ß‡∏¢ @elevenlabs/client SDK + microphone config
- ‚úÖ Integration ‡∏Å‡∏±‡∏ö UI ‡πÅ‡∏•‡∏∞ console logging
- ‚úÖ UI controls ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Start/Stop continuous voice chat
- ‚úÖ ‡πÅ‡∏™‡∏î‡∏á partial ‡πÅ‡∏•‡∏∞ final transcripts ‡πÉ‡∏ô console
- ‚è∏Ô∏è Full V2V flow (OpenAI + TTS + Avatar) - ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

‚ö†Ô∏è **Phase 5-6**: WebSocket Features (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°)
- WebSocket Chat Server (‡πÑ‡∏°‡πà‡∏°‡∏µ Custom Server)
- WebSocket Streaming TTS (‡πÑ‡∏°‡πà‡∏°‡∏µ Custom Server)
- Total Effort: ~10-14 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô

**‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö Latency 3-5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ:**
```bash
pnpm dev
# ‡πÄ‡∏õ‡∏¥‡∏î http://localhost:3000
# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å CUSTOM mode ‚Üí ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
```

**‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Real-time (<1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ):**
- ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥ Phase 4-6 ‡πÉ‡∏´‡πâ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏Å‡πà‡∏≠‡∏ô
- ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á

---

## ‡∏™‡∏£‡∏∏‡∏õ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ Voice-to-Voice ‡πÅ‡∏ö‡∏ö Real-time ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ HeyGen LiveAvatar ‡πÄ‡∏õ‡πá‡∏ô Avatar ‡∏´‡∏•‡∏±‡∏Å ‡πÇ‡∏î‡∏¢‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö 2 ‡πÇ‡∏´‡∏°‡∏î:

### ‡πÇ‡∏´‡∏°‡∏î FULL ‚úÖ (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô)
- HeyGen ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á (STT, AI, TTS, Lip-sync)
- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß
- Latency: 1-2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ

### ‡πÇ‡∏´‡∏°‡∏î CUSTOM ‚úÖ (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô)
- ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° AI (OpenAI GPT) ‡πÅ‡∏•‡∏∞ TTS (ElevenLabs)
- HeyGen ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏Ñ‡πà Video Streaming ‡πÅ‡∏•‡∏∞ Lip-sync
- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡∏≠‡∏á Avatar
- Latency: 3-5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (REST APIs)

### ‡πÇ‡∏´‡∏°‡∏î CUSTOM + WebSocket ‚ö†Ô∏è (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏° - ‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏±‡∏í‡∏ô‡∏≤ Phase 4-6)
- ‡πÉ‡∏ä‡πâ WebSocket ‡πÅ‡∏ó‡∏ô REST APIs
- Latency: <1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (Real-time streaming)
- ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Custom WebSocket Server

## ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ

| ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ | ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà | Implementation Status | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ |
|--------|---------|---------------------|---------|
| **HeyGen LiveAvatar** | Video Streaming, Lip-sync Animation | ‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô | https://api.liveavatar.com |
| **OpenAI Whisper** | Speech-to-Text (CUSTOM mode) | ‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô | https://platform.openai.com/docs/guides/speech-to-text |
| **OpenAI GPT-4** | AI Conversation (CUSTOM mode) | ‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô | https://platform.openai.com/docs/guides/chat |
| **ElevenLabs** | Text-to-Speech (CUSTOM mode) | ‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô | https://elevenlabs.io/docs |
| **ElevenLabs Scribe** | Real-time Speech-to-Text | ‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô | https://elevenlabs.io/docs/cookbooks/speech-to-text/streaming |
| **LiveKit** | WebRTC Video Streaming | ‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô | https://docs.livekit.io |
| **WebSocket** | Real-time Command/Event Communication | ‚ö†Ô∏è ‡πÉ‡∏ä‡πâ‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô (HeyGen) | - |

## ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ

### 1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies

```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á pnpm (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ)
npm install -g pnpm@9.0.0

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies
pnpm install
```

### 2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Environment Variables

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `.env.local` ‡πÉ‡∏ô `apps/demo/`:

```env
# HeyGen LiveAvatar (‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)
LIVEAVATAR_API_KEY=your_heygen_api_key
LIVEAVATAR_AVATAR_ID=dd73ea75-1218-4ef3-92ce-606d5f7fbc0a

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö FULL mode (optional)
LIVEAVATAR_VOICE_ID=your_voice_id
LIVEAVATAR_CONTEXT_ID=your_context_id
LIVEAVATAR_LANGUAGE=en

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CUSTOM mode (‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)
OPENAI_API_KEY=your_openai_api_key
ELEVENLABS_API_KEY=your_elevenlabs_api_key
ELEVENLABS_VOICE_ID=pqHfZKP75CvOlQylNhV4
ELEVENLABS_MODEL=eleven_v3
```

### 3. ‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ

```bash
# ‡∏£‡∏±‡∏ô Demo application
pnpm demo

# ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏±‡∏ô Development mode
pnpm dev

# Build ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ
pnpm build
```

‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà http://localhost:3000

---

# IMPLEMENTATION FLOW

## PHASE 1: Session Management ‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

**Status:** ‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß - ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á FULL ‡πÅ‡∏•‡∏∞ CUSTOM mode

### ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

Phase ‡∏ô‡∏µ‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Session lifecycle ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:

1. **Start Session (FULL/CUSTOM Mode)** - ‡∏™‡∏£‡πâ‡∏≤‡∏á session token ‡∏à‡∏≤‡∏Å HeyGen API
   - FULL Mode: ‡∏°‡∏µ avatar_persona (voice_id, context_id, language)
   - CUSTOM Mode: ‡πÑ‡∏°‡πà‡∏°‡∏µ avatar_persona (‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏≠‡∏á)

2. **Keep Session Alive** - ‡∏ï‡πà‡∏≠‡∏≠‡∏≤‡∏¢‡∏∏ session ‡∏ó‡∏∏‡∏Å 5 ‡∏ô‡∏≤‡∏ó‡∏µ (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô timeout)

3. **Stop Session** - ‡∏õ‡∏¥‡∏î session ‡πÅ‡∏•‡∏∞ cleanup resources

4. **WebSocket Connection** - ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ WebSocket ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CUSTOM mode (‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° Avatar)

### Files Implemented

- API: `apps/demo/app/api/start-session/route.ts` ‚úÖ
- API: `apps/demo/app/api/start-custom-session/route.ts` ‚úÖ
- API: `apps/demo/app/api/keep-session-alive/route.ts` ‚úÖ
- API: `apps/demo/app/api/stop-session/route.ts` ‚úÖ
- Hook: `apps/demo/src/liveavatar/useSession.ts` ‚úÖ

### ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö

```bash
# 1. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ Postman
POST http://localhost:3000/api/start-session

# 2. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ HTML (Optional)
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå: public/test-session-lifecycle.html
# ‡πÄ‡∏õ‡∏¥‡∏î: http://localhost:3000/test-session-lifecycle.html

# 3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡πÅ‡∏≠‡∏û‡∏´‡∏•‡∏±‡∏Å
pnpm dev
# ‡πÄ‡∏õ‡∏¥‡∏î http://localhost:3000 ‚Üí Start Session
```

---

## PHASE 2: Voice Chat (FULL Mode) ‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

**Status:** ‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß - ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö

### ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

FULL Mode ‡πÉ‡∏ä‡πâ HeyGen ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Voice Chat ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:

1. **Voice Chat Start** - ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô voice chat ‡∏û‡∏£‡πâ‡∏≠‡∏° microphone access
2. **Real-time STT** - HeyGen ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
3. **AI Response** - HeyGen generate ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ built-in AI
4. **TTS & Lip-sync** - HeyGen ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏≥ lip-sync
5. **Microphone Control** - Mute/Unmute/Stop

### Flow

```
User Speaks ‚Üí HeyGen STT ‚Üí HeyGen AI ‚Üí HeyGen TTS ‚Üí Avatar Speaks
           (All handled by HeyGen internally)
```

### Files Implemented

- Hook: `apps/demo/src/liveavatar/useVoiceChat.ts` ‚úÖ
- Component: `apps/demo/src/components/LiveAvatarSession.tsx` ‚úÖ

### ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö

```bash
pnpm dev
# ‡πÄ‡∏õ‡∏¥‡∏î http://localhost:3000
# 1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å "FULL Mode"
# 2. ‡∏Å‡∏î "Start Session"
# 3. ‡∏Å‡∏î "Start Voice Chat"
# 4. ‡∏û‡∏π‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ ‚Üí Avatar ‡∏Ñ‡∏ß‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö
```

---

## PHASE 3: Custom Voice Chat (CUSTOM Mode) ‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

**Status:** ‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß - ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö

### ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

CUSTOM Mode ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° AI ‡πÅ‡∏•‡∏∞ TTS ‡πÄ‡∏≠‡∏á:

1. **Audio Recording** - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ Web Audio API (AudioWorklet)
2. **Speech-to-Text** - OpenAI Whisper ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (batch)
3. **AI Chat** - OpenAI GPT-4o-mini generate ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
4. **Text-to-Speech** - ElevenLabs ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á (PCM 24kHz)
5. **Avatar Lip-sync** - ‡∏™‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏õ HeyGen ‡∏ú‡πà‡∏≤‡∏ô WebSocket (chunks 20ms)

### Flow

```
User Speaks ‚Üí AudioWorklet ‚Üí Whisper STT ‚Üí OpenAI Chat ‚Üí ElevenLabs TTS ‚Üí Avatar Speaks
                                                                            (WebSocket chunks)
```

### Files Implemented

- Hook: `apps/demo/src/liveavatar/useCustomVoiceChat.ts` ‚úÖ
- Hook: `apps/demo/src/liveavatar/useTextChat.ts` ‚úÖ
- API: `apps/demo/app/api/openai-whisper-stt/route.ts` ‚úÖ
- API: `apps/demo/app/api/openai-chat-complete/route.ts` ‚úÖ
- API: `apps/demo/app/api/elevenlabs-text-to-speech/route.ts` ‚úÖ
- Audio Processor: `apps/demo/public/audio-processor.js` ‚úÖ
- SDK: `packages/js-sdk/src/audio_utils.ts` ‚úÖ

### ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö

```bash
pnpm dev
# ‡πÄ‡∏õ‡∏¥‡∏î http://localhost:3000
# 1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å "CUSTOM Mode"
# 2. ‡∏Å‡∏î "Start Session"
# 3. ‡∏Å‡∏î "Start Recording" (Push-to-talk)
# 4. ‡∏û‡∏π‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ
# 5. ‡∏Å‡∏î "Stop Recording"
# 6. ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞: STT ‚Üí AI ‚Üí TTS ‚Üí Avatar ‡∏û‡∏π‡∏î
```

### API Testing

```bash
# Test Whisper STT
POST http://localhost:3000/api/openai-whisper-stt
Content-Type: multipart/form-data
Body: audio file

# Test OpenAI Chat
POST http://localhost:3000/api/openai-chat-complete
Content-Type: application/json
Body: {"message": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö"}

# Test ElevenLabs TTS
POST http://localhost:3000/api/elevenlabs-text-to-speech
Content-Type: application/json
Body: {"text": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö"}
```

---

## PHASE 4: ElevenLabs Realtime Speech-to-Text Integration ‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß

**Status:** ‚úÖ **100% Complete** - Logs-only mode ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß
**Progress:**
- ‚úÖ TASK 4.1: Single-Use Token API (‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à)
- ‚úÖ TASK 4.2: Scribe SDK Integration (‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à)
- ‚úÖ TASK 4.3: Logs-only Testing Mode (‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à)
- ‚è∏Ô∏è TASK 4.4: Full Avatar Integration (‡∏û‡∏±‡∏Å‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô - ‡πÄ‡∏õ‡∏¥‡∏î comment ‡πÑ‡∏î‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)

**Current Mode:** Logs-only (‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà transcripts ‡πÉ‡∏ô console)

### ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Phase ‡∏ô‡∏µ‡πâ?

Phase 3 ‡πÉ‡∏ä‡πâ OpenAI Whisper ‡πÅ‡∏ö‡∏ö **batch** (‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à‡∏Å‡πà‡∏≠‡∏ô) ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏µ latency ‡∏™‡∏π‡∏á (3-5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)

Phase 4 ‡∏à‡∏∞‡πÉ‡∏ä‡πâ ElevenLabs Scribe **real-time streaming** ‡∏î‡πâ‡∏ß‡∏¢ `@elevenlabs/client` SDK ‡∏ó‡∏≥‡πÉ‡∏´‡πâ:
- ‚úÖ ‡∏°‡∏µ partial transcripts (‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ö‡∏ö real-time ‡∏Ç‡∏ì‡∏∞‡∏û‡∏π‡∏î)
- ‚úÖ ‡∏•‡∏î latency ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ <500ms
- ‚úÖ ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ official SDK (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ WebSocket ‡πÄ‡∏≠‡∏á)
- ‚úÖ Built-in microphone streaming ‡πÅ‡∏•‡∏∞ audio processing

### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥

1. ‚úÖ **API Endpoint**: `/api/elevenlabs-stt-token` - **‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß**
   - Generate single-use token ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö authentication
   - Token ‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏‡πÉ‡∏ô 15 ‡∏ô‡∏≤‡∏ó‡∏µ
   - HTML test page: `http://localhost:3000/test-elevenlabs-stt-token.html`

2. ‚ö†Ô∏è **Scribe SDK Integration** - **‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥**
   - ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á `@elevenlabs/client` package
   - ‡πÉ‡∏ä‡πâ `Scribe.connect()` ‡∏Å‡∏±‡∏ö microphone streaming
   - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ events ‡πÅ‡∏•‡∏∞ transcripts

3. ‚ö†Ô∏è **Avatar Integration** - **‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥**
   - ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ final transcripts ‡∏Å‡∏±‡∏ö OpenAI Chat
   - ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á Avatar

### Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Microphone   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ (Built-in streaming)
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ @elevenlabs/client           ‚îÇ
‚îÇ Scribe.connect()             ‚îÇ
‚îÇ - Auto audio processing      ‚îÇ
‚îÇ - PCM 16kHz encoding         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ (WebSocket - handled by SDK)
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ElevenLabs Scribe API        ‚îÇ ‚Üê wss://api.elevenlabs.io/v1/speech-to-text/realtime
‚îÇ (Scribe v2 Realtime)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚Üí PARTIAL_TRANSCRIPT (‡∏Ç‡∏ì‡∏∞‡∏û‡∏π‡∏î)
       ‚îî‚îÄ‚Üí COMMITTED_TRANSCRIPT (‡∏û‡∏π‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à)
```

### TASK 4.1: ‡∏™‡∏£‡πâ‡∏≤‡∏á API Endpoint ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Single-Use Token ‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß

**Status:** ‚úÖ **‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß** - API endpoint ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

**‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á:** `apps/demo/app/api/elevenlabs-stt-token/route.ts` ‚úÖ

```typescript
import { NextResponse } from 'next/server';
import { ELEVENLABS_API_KEY } from '../secrets';

export async function POST() {
  try {
    const response = await fetch(
      'https://api.elevenlabs.io/v1/single-use-token/realtime_scribe',
      {
        method: 'POST',
        headers: { 'xi-api-key': ELEVENLABS_API_KEY }
      }
    );

    if (!response.ok) {
      throw new Error(`ElevenLabs API error: ${response.statusText}`);
    }

    const data = await response.json();
    return NextResponse.json({
      token: data.token,
      expires_at: data.expires_at
    });
  } catch (error) {
    console.error('Error generating token:', error);
    return NextResponse.json(
      { error: 'Failed to generate token' },
      { status: 500 }
    );
  }
}
```

**‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö:**

1. **‡∏î‡πâ‡∏ß‡∏¢ HTML Test Page (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥):**
```bash
# ‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ
pnpm dev

# ‡πÄ‡∏õ‡∏¥‡∏î test page
http://localhost:3000/test-elevenlabs-stt-token.html

# ‡∏Ñ‡∏•‡∏¥‡∏Å "Generate Token" ‚Üí ‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏•‡∏∞ countdown
```

2. **‡∏î‡πâ‡∏ß‡∏¢ Postman:**
```bash
POST http://localhost:3000/api/elevenlabs-stt-token

# Expected Response:
{
  "token": "eyJhbGci...",
  "expires_at": "2025-01-15T10:30:00Z"
}
```

**‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ:**
- ‚úÖ API endpoint ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á single-use token
- ‚úÖ Token ‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÉ‡∏ô 15 ‡∏ô‡∏≤‡∏ó‡∏µ
- ‚úÖ HTML test page ‡∏û‡∏£‡πâ‡∏≠‡∏° countdown timer
- ‚úÖ ‡∏£‡∏±‡∏Å‡∏©‡∏≤ API key ‡πÑ‡∏ß‡πâ‡∏ö‡∏ô backend (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢)

---

### TASK 4.2: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ElevenLabs Client SDK ‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß

**Status:** ‚úÖ **‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß** - Hook ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

#### Step 1: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies ‚úÖ

```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á ElevenLabs Client SDK
pnpm add @elevenlabs/client
# ‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß - Version 0.10.0 installed
```

#### Step 2: Configure the SDK with Microphone Streaming ‚úÖ

**‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß:** `apps/demo/src/liveavatar/useElevenLabsRealtimeSTT.ts` ‚úÖ

```typescript
import { useRef, useState, useCallback, useEffect } from 'react';
import { Scribe, AudioFormat, RealtimeEvents, CommitStrategy } from "@elevenlabs/client";

interface ScribeConfig {
  languageCode?: string;
  onPartialTranscript?: (text: string) => void;
  onFinalTranscript?: (text: string, timestamps?: any) => void;
  onError?: (error: any) => void;
}

export function useElevenLabsRealtimeSTT(config: ScribeConfig = {}) {
  const [isConnected, setIsConnected] = useState(false);
  const [partialText, setPartialText] = useState('');
  const [finalText, setFinalText] = useState('');
  const connectionRef = useRef<any>(null);

  const connect = useCallback(async () => {
    try {
      // 1. Get single-use token from backend
      const tokenRes = await fetch('/api/elevenlabs-stt-token', {
        method: 'POST'
      });
      const { token } = await tokenRes.json();

      // 2. Connect with Scribe SDK
      const connection = Scribe.connect({
        token,
        modelId: "scribe_v2_realtime",
        languageCode: config.languageCode || "th",
        audioFormat: AudioFormat.PCM_16000,
        commitStrategy: CommitStrategy.VAD,
        vadSilenceThresholdSecs: 1.5,
        vadThreshold: 0.4,
        minSpeechDurationMs: 100,
        minSilenceDurationMs: 100,
        microphone: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      });

      connectionRef.current = connection;

      // 3. Handle events
      connection.on(RealtimeEvents.SESSION_STARTED, () => {
        console.log('ElevenLabs Scribe session started');
        setIsConnected(true);
      });

      connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data: any) => {
        console.log('Partial:', data.text);
        setPartialText(data.text);
        config.onPartialTranscript?.(data.text);
      });

      connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data: any) => {
        console.log('Final:', data.text);
        setFinalText(prev => prev + ' ' + data.text);
        config.onFinalTranscript?.(data.text);
        setPartialText('');
      });

      connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS, (data: any) => {
        console.log('Final with timestamps:', data);
        config.onFinalTranscript?.(data.text, data.timestamps);
      });

      connection.on(RealtimeEvents.ERROR, (error: any) => {
        console.error('Scribe error:', error);
        config.onError?.(error);
      });

      connection.on(RealtimeEvents.AUTH_ERROR, (error: any) => {
        console.error('Auth error:', error);
        config.onError?.(error);
      });

      connection.on(RealtimeEvents.CLOSE, () => {
        console.log('Connection closed');
        setIsConnected(false);
      });

    } catch (error) {
      console.error('Failed to connect:', error);
      config.onError?.(error);
    }
  }, [config]);

  const disconnect = useCallback(() => {
    if (connectionRef.current) {
      connectionRef.current.close();
      connectionRef.current = null;
    }
    setIsConnected(false);
    setPartialText('');
  }, []);

  const reset = useCallback(() => {
    setFinalText('');
    setPartialText('');
  }, []);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      disconnect();
    };
  }, [disconnect]);

  return {
    isConnected,
    partialText,
    finalText,
    connect,
    disconnect,
    reset
  };
}
```

#### Step 3: Audio Format Configuration

SDK ‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ audio processing ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥:
- **Sample Rate**: 16kHz (PCM_16000) - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡∏ô‡∏î‡πå‡∏ß‡∏¥‡∏ò
- **Encoding**: 16-bit PCM, little-endian
- **Channels**: Mono only
- **Echo Cancellation**: ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- **Noise Suppression**: ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- **Auto Gain Control**: ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

#### Step 4: Commit Strategy

**Voice Activity Detection (VAD)** - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö real-time:
- `vadSilenceThresholdSecs: 1.5` - ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡πà‡∏≠‡∏ô commit (0.3-3.0)
- `vadThreshold: 0.4` - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á (0.1-0.9, ‡∏ï‡πà‡∏≥ = ‡πÑ‡∏ß‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô)
- `minSpeechDurationMs: 100` - ‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏û‡∏π‡∏î‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ (50-2000ms)
- `minSilenceDurationMs: 100` - ‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ (50-2000ms)

---

### TASK 4.3: Logs-only Testing Mode ‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß

**Status:** ‚úÖ **‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß** - ‡πÅ‡∏™‡∏î‡∏á transcripts ‡πÉ‡∏ô console ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô

**Current Implementation:** Integration ‡∏Å‡∏±‡∏ö Avatar ‡πÅ‡∏•‡∏∞ OpenAI Chat ‡∏ñ‡∏π‡∏Å comment ‡πÑ‡∏ß‡πâ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Realtime STT ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ OpenAI/ElevenLabs API keys

#### ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Hook ‡πÉ‡∏ô Component (LOGS ONLY MODE) ‚úÖ

**‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå:** `apps/demo/src/components/LiveAvatarSession.tsx` ‚úÖ

```typescript
import { useElevenLabsRealtimeSTT } from '../liveavatar/useElevenLabsRealtimeSTT';

function LiveAvatarSessionComponent() {
  // Setup Realtime STT - LOGS ONLY MODE (No OpenAI/TTS integration)
  const {
    isConnected: isRealtimeSTTConnected,
    partialText: realtimePartialText,
    finalText: realtimeFinalText,
    connect: connectRealtimeSTT,
    disconnect: disconnectRealtimeSTT,
    reset: resetRealtimeSTT,
  } = useElevenLabsRealtimeSTT({
    languageCode: 'th', // ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

    onPartialTranscript: (text) => {
      console.log('üé§ [REALTIME STT] Partial transcript:', text);
    },

    onFinalTranscript: async (text) => {
      console.log('‚úÖ [REALTIME STT] Final transcript:', text);
      console.log('üìä [REALTIME STT] Transcript length:', text.length, 'characters');

      // TODO: Uncomment below to enable full voice-to-voice flow
      /*
      try {
        // 1. Send transcript to OpenAI Chat API
        const chatRes = await fetch('/api/openai-chat-complete', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ message: text })
        });
        const { response: aiResponse } = await chatRes.json();
        console.log('ü§ñ AI Response:', aiResponse);

        // 2. Convert AI response to speech using ElevenLabs TTS
        const ttsRes = await fetch('/api/elevenlabs-text-to-speech', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ text: aiResponse })
        });
        const { audio } = await ttsRes.json();
        console.log('üîä TTS Audio generated');

        // 3. Send audio to Avatar for lip-sync
        if (sessionRef.current) {
          await sessionRef.current.repeatAudio(audio);
          console.log('üëÑ Avatar speaking');
        }
      } catch (error) {
        console.error('‚ùå Error in voice-to-voice flow:', error);
      }
      */
    },

    onError: (error) => {
      console.error('‚ùå [REALTIME STT] Error:', error);
    }
  });

  return (
    <div>
      {/* Video */}
      <video ref={videoRef} autoPlay playsInline />

      {/* Realtime STT Controls */}
      <div className="border-t-2 border-yellow-400 pt-4">
        <h3 className="text-lg font-bold text-yellow-400">
          ElevenLabs Realtime STT (Continuous Voice Chat)
        </h3>
        <p>Connected: {isRealtimeSTTConnected ? "true" : "false"}</p>

        {/* Display Real-time Transcripts */}
        {realtimePartialText && (
          <p className="text-gray-400 italic">Partial: {realtimePartialText}</p>
        )}
        {realtimeFinalText && (
          <p className="text-white font-semibold">Transcript: {realtimeFinalText}</p>
        )}

        {/* Control Buttons */}
        <div className="flex gap-2 mt-2">
          <button
            onClick={() => {
              if (isRealtimeSTTConnected) {
                disconnectRealtimeSTT();
              } else {
                connectRealtimeSTT();
              }
            }}
            className={`px-6 py-3 rounded-md font-semibold ${
              isRealtimeSTTConnected
                ? "bg-red-500 text-white hover:bg-red-600"
                : "bg-green-500 text-white hover:bg-green-600"
            }`}
          >
            {isRealtimeSTTConnected ? "Stop Realtime Voice Chat" : "Start Realtime Voice Chat"}
          </button>
          <button onClick={resetRealtimeSTT} disabled={!isRealtimeSTTConnected}>
            Reset Transcript
          </button>
        </div>
      </div>
    </div>
  );
}
```

**‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ:**
- ‚úÖ Integration ‡∏Å‡∏±‡∏ö LiveAvatarSession component
- ‚úÖ UI controls ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Start/Stop continuous voice chat
- ‚úÖ ‡πÅ‡∏™‡∏î‡∏á partial ‡πÅ‡∏•‡∏∞ final transcripts ‡πÅ‡∏ö‡∏ö real-time ‡πÉ‡∏ô console
- ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡πâ‡∏ß‡∏¢ Scribe v2 Realtime
- üìù Voice-to-voice flow (OpenAI Chat ‚Üí TTS ‚Üí Avatar) ‡∏ñ‡∏π‡∏Å comment ‡πÑ‡∏ß‡πâ ‡∏û‡∏£‡πâ‡∏≠‡∏° uncomment ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£

#### Current Flow (Logs-only Mode)

```
User Speaks (Microphone)
         ‚Üì
@elevenlabs/client SDK
  - Auto audio capture (PCM 16kHz)
  - Built-in audio processing
  - Echo cancellation
  - Noise suppression
         ‚Üì
ElevenLabs Scribe API
  - PARTIAL_TRANSCRIPT (real-time)
  - COMMITTED_TRANSCRIPT (final)
         ‚Üì
Browser Console (DevTools)
  - üé§ [REALTIME STT] Partial transcript: ...
  - ‚úÖ [REALTIME STT] Final transcript: ...
  - üìä [REALTIME STT] Transcript length: X characters
```

#### Future: Complete Voice-to-Voice Flow (Uncomment code to enable)

```
User Speaks ‚Üí ElevenLabs Scribe STT ‚Üí OpenAI Chat ‚Üí ElevenLabs TTS ‚Üí Avatar
                (Real-time)              (commented)      (commented)   (commented)
```

#### Best Practices

1. **Token Management**
   - Token ‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏‡πÉ‡∏ô 15 ‡∏ô‡∏≤‡∏ó‡∏µ
   - ‡∏Ñ‡∏ß‡∏£ implement token refresh mechanism ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö conversation ‡∏¢‡∏≤‡∏ß‡πÜ

2. **Error Handling**
   - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ `AUTH_ERROR`, `ERROR`, `QUOTA_EXCEEDED`
   - Implement reconnection logic with exponential backoff

3. **Audio Quality**
   - ‡πÉ‡∏ä‡πâ PCM_16000 (16kHz) ‡πÄ‡∏û‡∏∑‡πà‡∏≠ optimal performance
   - Enable echo cancellation ‡πÅ‡∏•‡∏∞ noise suppression

4. **Chunk Size Strategy**
   - SDK ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ chunk size ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
   - Processing ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏´‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á 2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÅ‡∏£‡∏Å

5. **VAD Configuration**
   - ‡∏õ‡∏£‡∏±‡∏ö `vadSilenceThresholdSecs` ‡∏ï‡∏≤‡∏°‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
   - ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á = ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏ô‡∏≤‡∏ô‡∏Å‡∏ß‡πà‡∏≤, ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏¢‡∏≤‡∏ß
   - ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥ = commit ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤, ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö dialog ‡∏™‡∏±‡πâ‡∏ô‡πÜ

---

### Testing Phase 4 (Logs-only Mode)

**Requirements:**
- ‚úÖ ELEVENLABS_API_KEY in `.env.local` (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö token generation)
- ‚ùå OPENAI_API_KEY **‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô** (‡∏ñ‡∏π‡∏Å comment ‡πÑ‡∏ß‡πâ)
- ‚ùå ElevenLabs TTS API key **‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô** (‡∏ñ‡∏π‡∏Å comment ‡πÑ‡∏ß‡πâ)

---

**1. Test Token Generation API:**
```bash
# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Token endpoint
POST http://localhost:3012/api/elevenlabs-stt-token

# Expected Response:
{
  "token": "eyJhbGci...",
  "expires_at": "2025-01-15T12:00:00Z"
}
```

**2. Test Realtime STT (Recommended - Logs Only):**

**Quick Test (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥):**

```bash
# 1. ‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ
pnpm dev

# 2. ‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå
http://localhost:3012
```

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:**
1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å **CUSTOM Mode** ‚Üí ‡∏Å‡∏î **Start Session**
2. ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏•‡∏á‡∏°‡∏≤‡∏´‡∏≤ **"ElevenLabs Realtime STT"** section (‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á)
3. ‡∏Å‡∏î **"Start Realtime Voice Chat"** (‡∏õ‡∏∏‡πà‡∏°‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß)
4. ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï **Microphone Access**
5. **‡∏û‡∏π‡∏î‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢** ‡πÄ‡∏ä‡πà‡∏ô "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö"
6. **‡πÄ‡∏õ‡∏¥‡∏î Browser Console (F12)** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π logs

**Expected Console Output:**
```
üîå Starting connection to ElevenLabs Scribe...
‚úÖ Token received
üé§ Requesting microphone access...
üì¶ Connection object created
‚úÖ SESSION_STARTED - ElevenLabs Scribe session started
üéôÔ∏è You can now speak into your microphone...
üé§ [REALTIME STT] Partial transcript: ‡∏™‡∏ß‡∏±‡∏™
üé§ [REALTIME STT] Partial transcript: ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ
üé§ [REALTIME STT] Partial transcript: ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö
‚úÖ [REALTIME STT] Final transcript: ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö
üìä [REALTIME STT] Transcript length: 28 characters
```

**Expected UI Behavior:**
- ‚úÖ "Connected: true" ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô UI
- ‚úÖ **Partial text** (‡∏™‡∏µ‡πÄ‡∏ó‡∏≤, italic) ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï‡πÅ‡∏ö‡∏ö real-time ‡∏Ç‡∏ì‡∏∞‡∏û‡∏π‡∏î
- ‚úÖ **Final text** (‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß, bold) ‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö ~1.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
- ‚ùå **Avatar ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö** (‡πÄ‡∏û‡∏£‡∏≤‡∏∞ OpenAI/TTS ‡∏ñ‡∏π‡∏Å comment ‡πÑ‡∏ß‡πâ)

---

**3. Test SDK Integration (Browser Console - Advanced):**

‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å `@elevenlabs/client` ‡∏ñ‡∏π‡∏Å‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô dependency ‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ‡πÅ‡∏•‡πâ‡∏ß ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏î‡∏™‡∏≠‡∏ö SDK ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÉ‡∏ô Browser Console

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö:**

1. **‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î Development:**
```bash
pnpm dev
# ‡πÄ‡∏õ‡∏¥‡∏î http://localhost:3012
```

2. **‡πÄ‡∏õ‡∏¥‡∏î Browser DevTools Console** (F12 ‡∏´‡∏£‡∏∑‡∏≠ Ctrl+Shift+J)

3. **‡∏ß‡∏≤‡∏á Code ‡∏ô‡∏µ‡πâ‡πÉ‡∏ô Console ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö SDK:**

```javascript
// Step 1: Import SDK ‡∏à‡∏≤‡∏Å node_modules
// ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡πÉ‡∏ô Browser Console ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ import ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
// ‡πÅ‡∏ï‡πà SDK ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å bundle ‡∏°‡∏≤‡∏Å‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ‡πÅ‡∏•‡πâ‡∏ß‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ Next.js app

// ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: ‡πÉ‡∏ä‡πâ dynamic import
(async () => {
  // Step 2: Get single-use token ‡∏à‡∏≤‡∏Å backend API
  console.log('üîë Requesting token...');
  const tokenRes = await fetch('/api/elevenlabs-stt-token', {
    method: 'POST'
  });
  const { token, expires_at } = await tokenRes.json();
  console.log('‚úÖ Token received:', { token: token.substring(0, 20) + '...', expires_at });

  // Step 3: Import ElevenLabs SDK dynamically
  const { Scribe, AudioFormat, RealtimeEvents, CommitStrategy } =
    await import('@elevenlabs/client');

  console.log('üì¶ SDK imported successfully');

  // Step 4: Connect with Scribe SDK (with microphone access)
  console.log('üé§ Requesting microphone access...');

  const connection = Scribe.connect({
    token,
    modelId: "scribe_v2_realtime",
    languageCode: "th", // ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô "en", "ja" ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
    audioFormat: AudioFormat.PCM_16000,
    commitStrategy: CommitStrategy.VAD,
    vadSilenceThresholdSecs: 1.5,
    vadThreshold: 0.4,
    minSpeechDurationMs: 100,
    minSilenceDurationMs: 100,
  });

  console.log('üîå Connection object created:', connection);

  // Step 5: Listen to events
  connection.on(RealtimeEvents.SESSION_STARTED, () => {
    console.log('‚úÖ SESSION_STARTED - Scribe session started!');
    console.log('üéôÔ∏è You can now speak into your microphone...');
  });

  connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data) => {
    console.log('üé§ PARTIAL_TRANSCRIPT (real-time):', data.text);
  });

  connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {
    console.log('‚úÖ COMMITTED_TRANSCRIPT (final):', data.text);
  });

  connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS, (data) => {
    console.log('üìù COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS:', {
      text: data.text,
      timestamps: data.timestamps
    });
  });

  connection.on(RealtimeEvents.ERROR, (error) => {
    console.error('‚ùå ERROR:', error);
  });

  connection.on(RealtimeEvents.AUTH_ERROR, (error) => {
    console.error('üö´ AUTH_ERROR:', error);
  });

  connection.on(RealtimeEvents.CLOSE, () => {
    console.log('üîå CONNECTION CLOSED');
  });

  // Store connection in window for manual control
  window.elevenLabsConnection = connection;
  console.log('üíæ Connection saved to window.elevenLabsConnection');
  console.log('üìù You can now:');
  console.log('   - Speak into your microphone to see transcripts');
  console.log('   - Close connection: window.elevenLabsConnection.close()');
})();
```

4. **‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á Microphone** ‡πÄ‡∏°‡∏∑‡πà‡∏≠ Browser ‡∏Ç‡∏≠ permission

5. **‡∏û‡∏π‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢** ‡πÄ‡∏ä‡πà‡∏ô "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö"

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ô Console:**
```
üîë Requesting token...
‚úÖ Token received: { token: 'eyJhbGci...', expires_at: '2025-01-15T12:00:00Z' }
üì¶ SDK imported successfully
üé§ Requesting microphone access...
üîå Connection object created: [Object]
üíæ Connection saved to window.elevenLabsConnection
üìù You can now:
   - Speak into your microphone to see transcripts
   - Close connection: window.elevenLabsConnection.close()
‚úÖ SESSION_STARTED - Scribe session started!
üéôÔ∏è You can now speak into your microphone...
üé§ PARTIAL_TRANSCRIPT (real-time): ‡∏™‡∏ß‡∏±‡∏™
üé§ PARTIAL_TRANSCRIPT (real-time): ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ
üé§ PARTIAL_TRANSCRIPT (real-time): ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö
‚úÖ COMMITTED_TRANSCRIPT (final): ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö
```

**‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Testing:**

```javascript
// ‡∏õ‡∏¥‡∏î connection
window.elevenLabsConnection.close();

// ‡∏î‡∏π connection state
console.log(window.elevenLabsConnection);

// ‡∏ó‡∏î‡∏™‡∏≠‡∏ö error handling - ‡πÉ‡∏ä‡πâ expired token
// (‡∏£‡∏≠ 15 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ token ‡πÄ‡∏Å‡πà‡∏≤)
```

**Troubleshooting:**

- **‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô partial transcripts:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ microphone access ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÅ‡∏•‡πâ‡∏ß
- **‡∏ñ‡πâ‡∏≤‡πÄ‡∏´‡πá‡∏ô AUTH_ERROR:** Token ‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏ (15 ‡∏ô‡∏≤‡∏ó‡∏µ) ‡πÉ‡∏´‡πâ‡∏Ç‡∏≠ token ‡πÉ‡∏´‡∏°‡πà
- **‡∏ñ‡πâ‡∏≤‡πÄ‡∏´‡πá‡∏ô ERROR:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ELEVENLABS_API_KEY ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå `.env.local`
- **‡∏ñ‡πâ‡∏≤ import ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏•‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ Next.js app

---

---

**4. How to Enable Full Voice-to-Voice Flow:**

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ Avatar ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ:

1. **‡πÄ‡∏û‡∏¥‡πà‡∏° API Keys** ‡πÉ‡∏ô `.env.local`:
```env
OPENAI_API_KEY=your_openai_api_key
ELEVENLABS_VOICE_ID=pqHfZKP75CvOlQylNhV4
```

2. **Uncomment code** ‡πÉ‡∏ô `apps/demo/src/components/LiveAvatarSession.tsx`:
   - ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î ~100-129
   - ‡∏•‡∏ö `/*` ‡πÅ‡∏•‡∏∞ `*/` ‡∏≠‡∏≠‡∏Å
   - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå

3. **Restart dev server**:
```bash
# ‡∏Å‡∏î Ctrl+C ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î server
pnpm dev
```

4. **‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á** - ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ Avatar ‡∏à‡∏∞‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡πâ‡∏ß

**Expected Console Output (Full Flow):**
```
üé§ [REALTIME STT] Partial transcript: ‡∏™‡∏ß‡∏±‡∏™
üé§ [REALTIME STT] Partial transcript: ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö
‚úÖ [REALTIME STT] Final transcript: ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö
üìä [REALTIME STT] Transcript length: 12 characters
ü§ñ AI Response: ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÑ‡∏´‡∏°?
üîä TTS Audio generated
üëÑ Avatar speaking
```

---

**5. Troubleshooting (Logs-only Mode):**

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô logs ‡πÉ‡∏ô console**
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡∏¥‡∏î Browser Console (F12) ‡πÅ‡∏•‡πâ‡∏ß
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° "Start Realtime Voice Chat" ‡πÅ‡∏•‡πâ‡∏ß
- ‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏°‡∏µ error ‡πÉ‡∏ô console ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Microphone permission denied**
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö browser settings ‚Üí Site permissions ‚Üí Microphone
- ‡∏•‡∏≠‡∏á refresh page ‡πÅ‡∏•‡∏∞‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡∏°‡πà

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤: AUTH_ERROR**
- Token ‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏ (15 ‡∏ô‡∏≤‡∏ó‡∏µ)
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ELEVENLABS_API_KEY ‡πÉ‡∏ô `.env.local`
- Restart dev server

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡πÑ‡∏°‡πà‡∏°‡∏µ partial transcripts**
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏û‡∏π‡∏î‡∏î‡∏±‡∏á‡∏û‡∏≠
- ‡∏•‡∏≠‡∏á adjust `vadThreshold` ‡πÉ‡∏ô hook (‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô 0.2)
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ microphone ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ "Hold to Talk" button

---

**Performance (Logs-only Mode):**
- **STT Latency**: < 500ms (real-time streaming)
- **Partial Transcript Update**: Real-time (‡∏Ç‡∏ì‡∏∞‡∏û‡∏π‡∏î)
- **Final Transcript**: ~1.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö
- **Total**: ‡∏î‡∏π‡∏ú‡∏•‡πÉ‡∏ô console ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ

**‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Whisper batch mode:**
| Metric | Whisper (PHASE 3) | ElevenLabs Realtime (PHASE 4 - Logs Only) |
|--------|-------------------|------------------------------------------|
| STT Method | Batch (‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏£‡πá‡∏à) | Real-time streaming |
| Partial Transcript | ‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ | ‚úÖ ‡∏°‡∏µ (‡πÅ‡∏ö‡∏ö real-time) |
| User Experience | ‡∏Å‡∏î‡∏Ñ‡πâ‡∏≤‡∏á "Hold to Talk" | Continuous (‡∏û‡∏π‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ) |
| STT Latency | 2-3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ | <500ms |
| Thai Support | ‚úÖ Yes | ‚úÖ Yes (Scribe v2) |
| Output | Text only | Console logs only (‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ) |

**4. Test Error Handling & Edge Cases:**

**Test Case 4.1: Expired Token (15 minutes)**
```javascript
// ‡πÉ‡∏ô Browser Console:
// 1. Start Realtime Voice Chat
// 2. ‡∏£‡∏≠ 15 ‡∏ô‡∏≤‡∏ó‡∏µ (‡∏´‡∏£‡∏∑‡∏≠ force expire ‡πÇ‡∏î‡∏¢‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç token)
// 3. ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏û‡∏π‡∏î‡πÉ‡∏´‡∏°‡πà

// Expected: ‡πÄ‡∏´‡πá‡∏ô AUTH_ERROR ‡πÉ‡∏ô console
// Console output:
// üö´ AUTH_ERROR: { message: "Token expired", code: 401 }
```

**Test Case 4.2: Network Disconnection**
```javascript
// 1. Start Realtime Voice Chat
// 2. ‡πÄ‡∏õ‡∏¥‡∏î DevTools ‚Üí Network tab ‚Üí Offline
// 3. ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏û‡∏π‡∏î

// Expected: ‡πÄ‡∏´‡πá‡∏ô ERROR ‡πÉ‡∏ô console
// Console output:
// ‚ùå ERROR: WebSocket connection failed
// üîå CONNECTION CLOSED
```

**Test Case 4.3: Microphone Permission Denied**
```javascript
// 1. Block microphone permission ‡πÉ‡∏ô browser settings
// 2. ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° Start Realtime Voice Chat

// Expected: Browser ‡πÅ‡∏™‡∏î‡∏á error, connection ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
// Console output:
// ‚ùå Error in voice-to-voice flow: NotAllowedError: Permission denied
```

**Test Case 4.4: Invalid API Key**
```javascript
// 1. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ELEVENLABS_API_KEY ‡πÉ‡∏ô .env.local ‡πÉ‡∏´‡πâ‡∏ú‡∏¥‡∏î
// 2. Restart dev server
// 3. ‡∏•‡∏≠‡∏á Start Realtime Voice Chat

// Expected:
// üö´ AUTH_ERROR: Invalid API key
```

**Test Case 4.5: Reconnection Logic**
```javascript
// ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£ reconnect ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
// ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: Hook ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ auto-reconnect
// ‡∏ï‡πâ‡∏≠‡∏á implement manually ‡πÇ‡∏î‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏° reconnection logic

connection.on(RealtimeEvents.CLOSE, async () => {
  console.log('Connection closed, attempting reconnect...');
  // Wait 2 seconds before retry
  await new Promise(resolve => setTimeout(resolve, 2000));
  // Get new token and reconnect
  await connect();
});
```

---

**Testing Summary: Phase 4 - Logs-only Mode**

| Test Case | Status | Notes |
|-----------|--------|-------|
| **Token Generation API** | ‚úÖ Passed | `/api/elevenlabs-stt-token` working |
| **SDK Installation** | ‚úÖ Passed | `@elevenlabs/client` v0.10.0 installed with microphone config |
| **Hook Implementation** | ‚úÖ Passed | `useElevenLabsRealtimeSTT.ts` with microphone capture |
| **UI Integration** | ‚úÖ Passed | Controls added to LiveAvatarSession (logs-only) |
| **Browser Console Test** | ‚úÖ Passed | Dynamic import & manual testing works |
| **Real-time STT** | ‚úÖ Passed | Partial transcripts streaming to console |
| **Final Transcripts** | ‚úÖ Passed | Committed after ~1.5s silence |
| **Console Logging** | ‚úÖ Passed | `[REALTIME STT]` prefix for easy filtering |
| **OpenAI Chat Integration** | ‚è∏Ô∏è Commented | Ready to uncomment when needed |
| **ElevenLabs TTS Integration** | ‚è∏Ô∏è Commented | Ready to uncomment when needed |
| **Avatar Lip-sync** | ‚è∏Ô∏è Commented | Ready to uncomment when needed |
| **Thai Language Support** | ‚úÖ Passed | Scribe v2 handles Thai correctly |
| **Error Handling** | ‚úÖ Passed | Console error logging with `[REALTIME STT]` prefix |
| **Token Refresh** | ‚ö†Ô∏è Not Implemented | Manual reconnect needed after 15 min |

**Overall Phase 4 Status: ‚úÖ 100% Complete (Logs-only Mode)**

**What Works Now:**
- ‚úÖ Real-time Speech-to-Text ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÉ‡∏ô console
- ‚úÖ Partial transcripts ‡πÅ‡∏ö‡∏ö real-time
- ‚úÖ Final transcripts ‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö ~1.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
- ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
- ‚úÖ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ OpenAI/ElevenLabs TTS API keys

**Next Steps (Optional):**
1. üîÑ Uncomment full voice-to-voice flow (OpenAI + TTS + Avatar)
2. üîÑ Auto token refresh mechanism (before 15 min expiry)
3. üîÑ Auto reconnection with exponential backoff
4. üîÑ UI loading states during AI processing

---

## PHASE 5: WebSocket Integration for OpenAI Chat ‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥

**Status:** ‚ö†Ô∏è **‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ Implement** - ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Custom WebSocket Server
**Estimated Effort:** 5-7 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á

### ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Phase ‡∏ô‡∏µ‡πâ?

Phase 3 ‡πÉ‡∏ä‡πâ OpenAI Chat ‡πÅ‡∏ö‡∏ö **REST API** (request/response ‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô) ‡∏ó‡∏≥‡πÉ‡∏´‡πâ:
- ‚ùå ‡∏ï‡πâ‡∏≠‡∏á establish connection ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á (overhead)
- ‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡πá‡∏ö conversation history ‡∏ö‡∏ô server
- ‚ùå Latency ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤ WebSocket

Phase 5 ‡∏à‡∏∞‡πÉ‡∏ä‡πâ **WebSocket** ‡∏ó‡∏≥‡πÉ‡∏´‡πâ:
- ‚úÖ Connection ‡∏Ñ‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏•‡∏≠‡∏î (persistent connection)
- ‚úÖ ‡∏•‡∏î latency (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á handshake ‡∏ã‡πâ‡∏≥)
- ‚úÖ Server ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ conversation history

### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á

1. ‚ùå **Custom WebSocket Server**: `apps/demo/server/websocket-server.ts`
2. ‚ùå **React Hook**: `apps/demo/src/liveavatar/useWebSocketChat.ts`
3. ‚ùå **Package Scripts**: ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï `package.json` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô WebSocket server

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** Next.js ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö WebSocket natively - ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á custom server ‡πÅ‡∏¢‡∏Å

### Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ React App   ‚îÇ
‚îÇ (Port 3000) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ (WebSocket)
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Custom WS Server     ‚îÇ ‚Üê ws://localhost:3001
‚îÇ (Port 3001)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ (HTTP)
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OpenAI API           ‚îÇ
‚îÇ (Chat Completions)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### TASK 5.1: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies

```bash
pnpm add -D ws @types/ws tsx concurrently
```

---

### TASK 5.2: ‡∏™‡∏£‡πâ‡∏≤‡∏á Custom WebSocket Server

**‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà:** `apps/demo/server/websocket-server.ts`

```typescript
import { WebSocketServer } from 'ws';
import { createServer } from 'http';

const server = createServer();
const wss = new WebSocketServer({ server });

wss.on('connection', (ws) => {
  console.log('Client connected to OpenAI Chat WebSocket');

  let conversationHistory: Array<{role: string, content: string}> = [];

  ws.on('message', async (data) => {
    try {
      const message = JSON.parse(data.toString());

      switch (message.type) {
        case 'chat':
          // Add user message to history
          conversationHistory.push({
            role: 'user',
            content: message.text
          });

          // Call OpenAI
          const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
            },
            body: JSON.stringify({
              model: 'gpt-4o-mini',
              messages: [
                {
                  role: 'system',
                  content: message.system_prompt || 'You are a helpful assistant.'
                },
                ...conversationHistory
              ]
            })
          });

          const data = await response.json();
          const assistantMessage = data.choices[0].message.content;

          // Add to history
          conversationHistory.push({
            role: 'assistant',
            content: assistantMessage
          });

          // Send response
          ws.send(JSON.stringify({
            type: 'chat_response',
            text: assistantMessage
          }));
          break;

        case 'reset':
          conversationHistory = [];
          ws.send(JSON.stringify({
            type: 'reset_confirmed'
          }));
          break;
      }

    } catch (error) {
      ws.send(JSON.stringify({
        type: 'error',
        error: error.message
      }));
    }
  });

  ws.on('close', () => {
    console.log('Client disconnected');
  });
});

server.listen(3001, () => {
  console.log('WebSocket server running on port 3001');
});
```

---

### TASK 5.3: ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï package.json

**‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:** `apps/demo/package.json`

```json
{
  "scripts": {
    "dev": "next dev",
    "ws-server": "tsx server/websocket-server.ts",
    "dev:full": "concurrently \"pnpm dev\" \"pnpm ws-server\""
  }
}
```

**‡∏£‡∏±‡∏ô:**
```bash
# Terminal 1: Next.js
pnpm dev

# Terminal 2: WebSocket server
pnpm ws-server

# ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏±‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
pnpm dev:full
```

---

### TASK 5.4: ‡∏™‡∏£‡πâ‡∏≤‡∏á React Hook

**‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà:** `apps/demo/src/liveavatar/useWebSocketChat.ts`

```typescript
import { useState, useRef, useCallback, useEffect } from 'react';

interface ChatMessage {
  role: 'user' | 'assistant';
  content: string;
  timestamp: number;
}

export function useWebSocketChat(wsUrl: string = 'ws://localhost:3001') {
  const [isConnected, setIsConnected] = useState(false);
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const wsRef = useRef<WebSocket | null>(null);

  const connect = useCallback(() => {
    const ws = new WebSocket(wsUrl);
    wsRef.current = ws;

    ws.onopen = () => {
      console.log('Connected to chat WebSocket');
      setIsConnected(true);
    };

    ws.onmessage = (event) => {
      const message = JSON.parse(event.data);

      switch (message.type) {
        case 'chat_response':
          setMessages(prev => [...prev, {
            role: 'assistant',
            content: message.text,
            timestamp: Date.now()
          }]);
          break;

        case 'error':
          console.error('Chat error:', message.error);
          break;
      }
    };

    ws.onerror = (error) => {
      console.error('WebSocket error:', error);
    };

    ws.onclose = () => {
      console.log('Disconnected from chat');
      setIsConnected(false);
    };
  }, [wsUrl]);

  const disconnect = useCallback(() => {
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }
  }, []);

  const sendMessage = useCallback((text: string, systemPrompt?: string) => {
    if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
      console.error('WebSocket not connected');
      return;
    }

    // Add user message to UI
    setMessages(prev => [...prev, {
      role: 'user',
      content: text,
      timestamp: Date.now()
    }]);

    // Send to server
    wsRef.current.send(JSON.stringify({
      type: 'chat',
      text,
      system_prompt: systemPrompt
    }));
  }, []);

  const reset = useCallback(() => {
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({
        type: 'reset'
      }));
      setMessages([]);
    }
  }, []);

  // Auto-connect on mount
  useEffect(() => {
    connect();
    return () => disconnect();
  }, [connect, disconnect]);

  return {
    isConnected,
    messages,
    connect,
    disconnect,
    sendMessage,
    reset
  };
}
```

**‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:**

```typescript
import { useWebSocketChat } from '../liveavatar/useWebSocketChat';

function ChatInterface() {
  const { isConnected, messages, sendMessage, reset } = useWebSocketChat();
  const [input, setInput] = useState('');

  return (
    <div>
      <div>Status: {isConnected ? 'Connected' : 'Disconnected'}</div>

      {messages.map((msg, i) => (
        <div key={i}>
          <strong>{msg.role}:</strong> {msg.content}
        </div>
      ))}

      <input value={input} onChange={e => setInput(e.target.value)} />
      <button onClick={() => sendMessage(input)}>Send</button>
      <button onClick={reset}>Reset</button>
    </div>
  );
}
```

---

### Testing Phase 5

**1. Test WebSocket Server:**
```bash
# Install wscat
npm install -g wscat

# Start servers
pnpm dev:full

# Connect
wscat -c ws://localhost:3001

# Send message
{"type":"chat","text":"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö","system_prompt":"You are helpful."}

# Expected: {"type":"chat_response","text":"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö..."}
```

**2. Test in App:**
```bash
pnpm dev:full
# ‡πÄ‡∏õ‡∏¥‡∏î http://localhost:3000
# ‡πÉ‡∏ä‡πâ WebSocket Chat feature
# ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÅ‡∏ö‡∏ö real-time ‡∏û‡∏£‡πâ‡∏≠‡∏° history
```

---

## PHASE 6: WebSocket Integration for ElevenLabs TTS ‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥

**Status:** ‚ö†Ô∏è **‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ Implement** - ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏° TTS endpoint ‡πÉ‡∏ô WebSocket Server
**Estimated Effort:** 5-7 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á

### ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Phase ‡∏ô‡∏µ‡πâ?

Phase 3 ‡πÉ‡∏ä‡πâ ElevenLabs TTS ‡πÅ‡∏ö‡∏ö **REST API** (‡∏£‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á) ‡∏ó‡∏≥‡πÉ‡∏´‡πâ:
- ‚ùå ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡πÉ‡∏´‡πâ TTS ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏Å‡πà‡∏≠‡∏ô
- ‚ùå Avatar ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏π‡∏î‡∏ä‡πâ‡∏≤ (user ‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ß‡πà‡∏≤ lag)
- ‚ùå Latency ‡∏™‡∏π‡∏á (1-3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)

Phase 6 ‡∏à‡∏∞‡πÉ‡∏ä‡πâ **WebSocket Streaming TTS** ‡∏ó‡∏≥‡πÉ‡∏´‡πâ:
- ‚úÖ Avatar ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏π‡∏î‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ audio chunk ‡πÅ‡∏£‡∏Å
- ‚úÖ ‡∏•‡∏î perceived latency (‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô)
- ‚úÖ Smooth playback

### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á

1. ‚ùå **‡πÄ‡∏û‡∏¥‡πà‡∏° TTS WebSocket Endpoint** ‡πÉ‡∏ô `apps/demo/server/websocket-server.ts`
2. ‚ùå **React Hook**: `apps/demo/src/liveavatar/useWebSocketTTS.ts`
3. ‚ùå **Complete Integration Hook**: `apps/demo/src/liveavatar/useCompleteVoiceChat.ts`

### Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Text Input  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ WS TTS Server        ‚îÇ ‚Üê ws://localhost:3001/ws-tts
‚îÇ (Port 3001)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ (HTTP Streaming)
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ElevenLabs API       ‚îÇ
‚îÇ (TTS Streaming)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ (Audio Chunks)
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ HeyGen Avatar        ‚îÇ ‚Üê Send chunks ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
‚îÇ (Lip-sync)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### TASK 6.1: ‡πÄ‡∏û‡∏¥‡πà‡∏° TTS WebSocket Endpoint

**‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:** `apps/demo/server/websocket-server.ts`

```typescript
import { WebSocketServer } from 'ws';
import { createServer } from 'http';

const server = createServer();

// Chat WebSocket (existing)
const chatWss = new WebSocketServer({ noServer: true });
// ... existing chat code ...

// TTS WebSocket (NEW)
const ttsWss = new WebSocketServer({ noServer: true });

ttsWss.on('connection', (ws) => {
  console.log('Client connected to TTS WebSocket');

  ws.on('message', async (data) => {
    try {
      const message = JSON.parse(data.toString());

      if (message.type === 'synthesize') {
        // Call ElevenLabs streaming TTS
        const response = await fetch(
          `https://api.elevenlabs.io/v1/text-to-speech/${message.voice_id}/stream`,
          {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'xi-api-key': process.env.ELEVENLABS_API_KEY
            },
            body: JSON.stringify({
              text: message.text,
              model_id: message.model_id || 'eleven_v3',
              output_format: 'pcm_24000'
            })
          }
        );

        if (!response.body) {
          throw new Error('No response body');
        }

        // Stream audio chunks
        const reader = response.body.getReader();
        let chunkIndex = 0;

        while (true) {
          const { done, value } = await reader.read();

          if (done) {
            // Send completion signal
            ws.send(JSON.stringify({
              type: 'synthesis_complete'
            }));
            break;
          }

          // Send audio chunk to client
          const base64Chunk = Buffer.from(value).toString('base64');
          ws.send(JSON.stringify({
            type: 'audio_chunk',
            chunk_index: chunkIndex++,
            audio: base64Chunk
          }));
        }
      }

    } catch (error) {
      ws.send(JSON.stringify({
        type: 'error',
        error: error.message
      }));
    }
  });
});

// Upgrade handler (handle multiple paths)
server.on('upgrade', (request, socket, head) => {
  const pathname = new URL(request.url, 'http://localhost').pathname;

  if (pathname === '/ws-chat') {
    chatWss.handleUpgrade(request, socket, head, (ws) => {
      chatWss.emit('connection', ws, request);
    });
  } else if (pathname === '/ws-tts') {
    ttsWss.handleUpgrade(request, socket, head, (ws) => {
      ttsWss.emit('connection', ws, request);
    });
  } else {
    socket.destroy();
  }
});

server.listen(3001, () => {
  console.log('WebSocket server running on port 3001');
  console.log('  /ws-chat - OpenAI Chat');
  console.log('  /ws-tts  - ElevenLabs TTS');
});
```

---

### TASK 6.2: ‡∏™‡∏£‡πâ‡∏≤‡∏á React Hook ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Streaming TTS

**‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà:** `apps/demo/src/liveavatar/useWebSocketTTS.ts`

```typescript
import { useState, useRef, useCallback } from 'react';

interface TTSConfig {
  voiceId?: string;
  modelId?: string;
  onAudioChunk?: (chunk: string, index: number) => void;
  onComplete?: () => void;
  onError?: (error: any) => void;
}

export function useWebSocketTTS(
  wsUrl: string = 'ws://localhost:3001/ws-tts',
  config: TTSConfig = {}
) {
  const [isConnected, setIsConnected] = useState(false);
  const [isSynthesizing, setIsSynthesizing] = useState(false);
  const wsRef = useRef<WebSocket | null>(null);
  const audioChunksRef = useRef<string[]>([]);

  const connect = useCallback(() => {
    const ws = new WebSocket(wsUrl);
    wsRef.current = ws;

    ws.onopen = () => {
      console.log('Connected to TTS WebSocket');
      setIsConnected(true);
    };

    ws.onmessage = (event) => {
      const message = JSON.parse(event.data);

      switch (message.type) {
        case 'audio_chunk':
          audioChunksRef.current.push(message.audio);
          config.onAudioChunk?.(message.audio, message.chunk_index);
          break;

        case 'synthesis_complete':
          setIsSynthesizing(false);
          config.onComplete?.();
          break;

        case 'error':
          console.error('TTS error:', message.error);
          setIsSynthesizing(false);
          config.onError?.(message.error);
          break;
      }
    };

    ws.onerror = (error) => {
      console.error('WebSocket error:', error);
      config.onError?.(error);
    };

    ws.onclose = () => {
      console.log('Disconnected from TTS');
      setIsConnected(false);
    };
  }, [wsUrl, config]);

  const disconnect = useCallback(() => {
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }
  }, []);

  const synthesize = useCallback((text: string) => {
    if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
      console.error('WebSocket not connected');
      return;
    }

    audioChunksRef.current = [];
    setIsSynthesizing(true);

    wsRef.current.send(JSON.stringify({
      type: 'synthesize',
      text,
      voice_id: config.voiceId || 'pqHfZKP75CvOlQylNhV4',
      model_id: config.modelId || 'eleven_v3'
    }));
  }, [config.voiceId, config.modelId]);

  const getAudio = useCallback(() => {
    return audioChunksRef.current.join('');
  }, []);

  return {
    isConnected,
    isSynthesizing,
    connect,
    disconnect,
    synthesize,
    getAudio
  };
}
```

---

### TASK 6.3: Complete Voice Chat Integration

**‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà:** `apps/demo/src/liveavatar/useCompleteVoiceChat.ts`

```typescript
import { useState, useEffect, useCallback } from 'react';
import { useElevenLabsRealtimeSTT } from './useElevenLabsRealtimeSTT';
import { useWebSocketChat } from './useWebSocketChat';
import { useWebSocketTTS } from './useWebSocketTTS';
import { LiveAvatarSession } from '@heygen/liveavatar-web-sdk';

export function useCompleteVoiceChat(session: LiveAvatarSession) {
  const [isActive, setIsActive] = useState(false);

  // WebSocket Chat
  const chat = useWebSocketChat('ws://localhost:3001/ws-chat');

  // WebSocket TTS with Avatar integration
  const tts = useWebSocketTTS('ws://localhost:3001/ws-tts', {
    onAudioChunk: (chunk) => {
      // Send chunk to avatar immediately (streaming)
      session.sendCommand({
        type: 'agent.speak',
        event_id: 'voice-chat',
        audio: chunk
      });
    },
    onComplete: () => {
      // Signal end of speech
      session.sendCommand({
        type: 'agent.speak_end',
        event_id: 'voice-chat'
      });
    }
  });

  // Realtime STT
  const stt = useElevenLabsRealtimeSTT({
    language: 'th',
    sampleRate: 16000,

    onFinalTranscript: async (userText) => {
      console.log('User said:', userText);
      // Send to chat WebSocket
      chat.sendMessage(userText);
    }
  });

  // Listen to chat responses ‚Üí TTS
  useEffect(() => {
    if (chat.messages.length > 0) {
      const lastMessage = chat.messages[chat.messages.length - 1];

      if (lastMessage.role === 'assistant') {
        // Convert to speech via TTS WebSocket (streaming)
        tts.synthesize(lastMessage.content);
      }
    }
  }, [chat.messages, tts]);

  // Start complete voice chat
  const start = useCallback(async () => {
    await stt.connect();
    await chat.connect();
    await tts.connect();
    await stt.startRecording();
    setIsActive(true);
  }, [stt, chat, tts]);

  // Stop voice chat
  const stop = useCallback(() => {
    stt.stopRecording();
    stt.disconnect();
    chat.disconnect();
    tts.disconnect();
    setIsActive(false);
  }, [stt, chat, tts]);

  return {
    isActive,
    start,
    stop,
    messages: chat.messages,
    partialText: stt.partialText,
    isSpeaking: tts.isSynthesizing
  };
}
```

**‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:**

```typescript
function CompleteVoiceChat({ session }: { session: LiveAvatarSession }) {
  const {
    isActive,
    start,
    stop,
    messages,
    partialText,
    isSpeaking
  } = useCompleteVoiceChat(session);

  return (
    <div>
      {!isActive ? (
        <button onClick={start}>üöÄ Start Real-time Voice Chat</button>
      ) : (
        <button onClick={stop}>üõë Stop Voice Chat</button>
      )}

      <div>
        <div>Active: {isActive ? 'Yes' : 'No'}</div>
        <div>Avatar Speaking: {isSpeaking ? 'Yes' : 'No'}</div>
        {partialText && <div>Listening: {partialText}</div>}
      </div>

      <div>
        {messages.map((msg, i) => (
          <div key={i}>
            <strong>{msg.role === 'user' ? 'You' : 'Avatar'}:</strong>
            {msg.content}
          </div>
        ))}
      </div>
    </div>
  );
}
```

---

### Testing Phase 6

**1. Test TTS WebSocket:**
```bash
# Start servers
pnpm dev:full

# Test with wscat
wscat -c ws://localhost:3001/ws-tts

# Send
{"type":"synthesize","text":"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö","voice_id":"pqHfZKP75CvOlQylNhV4"}

# Expected: Multiple audio_chunk messages + synthesis_complete
```

**2. Test Complete Integration:**
```bash
pnpm dev:full
# ‡πÄ‡∏õ‡∏¥‡∏î http://localhost:3000
# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å CUSTOM Mode
# ‡∏Å‡∏î "Start Real-time Voice Chat"
# ‡∏û‡∏π‡∏î ‚Üí ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô:
#   1. Partial transcripts ‡πÅ‡∏ö‡∏ö real-time
#   2. AI response
#   3. Avatar ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏π‡∏î‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏° (streaming)
```

---

## ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏£‡∏∞‡∏ö‡∏ö

### Flow Diagram: Complete Real-time V2V

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User speaks    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ElevenLabs Realtime STT  ‚îÇ ‚Üê WebSocket streaming ‚ö†Ô∏è Phase 4
‚îÇ (Scribe v2)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ Transcript
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OpenAI GPT-4o            ‚îÇ ‚Üê WebSocket chat ‚ö†Ô∏è Phase 5
‚îÇ (Chat Completion)        ‚îÇ    (‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏ä‡πâ REST API ‚úÖ)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ Response text
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ElevenLabs TTS           ‚îÇ ‚Üê WebSocket streaming ‚ö†Ô∏è Phase 6
‚îÇ (Text-to-Speech)         ‚îÇ    (‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏ä‡πâ REST API ‚úÖ)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ Audio chunks (PCM 24kHz)
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ HeyGen Avatar            ‚îÇ ‚Üê WebSocket commands ‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
‚îÇ (Lip-sync + Video)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ Video stream (LiveKit)
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ User sees/hears Avatar   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÇ‡∏´‡∏°‡∏î

| Feature | FULL Mode ‚úÖ | CUSTOM Mode ‚úÖ | CUSTOM + WebSocket ‚ö†Ô∏è |
|---------|-----------|-------------|-------------------|
| **STT** | HeyGen built-in | OpenAI Whisper (batch) | ElevenLabs Scribe (realtime) |
| **AI** | HeyGen built-in | OpenAI (REST API) | OpenAI (WebSocket) |
| **TTS** | HeyGen built-in | ElevenLabs (REST API) | ElevenLabs (WebSocket streaming) |
| **Latency** | Low (1-2s) | Medium (3-5s) | Lowest (<1s) |
| **Customization** | Limited | Full | Full |
| **Complexity** | Simple | Medium | Advanced |
| **Implementation** | ‚úÖ Done | ‚úÖ Done | ‚ö†Ô∏è Need Phase 4-6 |
| **Ready** | ‚úÖ YES | ‚úÖ YES | ‚ùå NO |

---

## üìã TODO List ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ï‡πà‡∏≠

### High Priority (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Real-time Performance)

- [ ] **Phase 4.1**: ‡∏™‡∏£‡πâ‡∏≤‡∏á `/api/elevenlabs-stt-token` endpoint (1-2 ‡∏ä‡∏°.)
- [ ] **Phase 4.2**: ‡∏™‡∏£‡πâ‡∏≤‡∏á `useElevenLabsRealtimeSTT.ts` hook (3-4 ‡∏ä‡∏°.)
- [ ] **Phase 4.3**: Integration testing (1 ‡∏ä‡∏°.)

### Medium Priority (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Lower Latency)

- [ ] **Phase 5.1**: ‡∏™‡∏£‡πâ‡∏≤‡∏á Custom WebSocket Server (2-3 ‡∏ä‡∏°.)
- [ ] **Phase 5.2**: ‡∏™‡∏£‡πâ‡∏≤‡∏á `useWebSocketChat.ts` hook (2-3 ‡∏ä‡∏°.)
- [ ] **Phase 5.3**: Integration testing (1 ‡∏ä‡∏°.)

### Advanced (Complete Integration)

- [ ] **Phase 6.1**: ‡πÄ‡∏û‡∏¥‡πà‡∏° TTS WebSocket endpoint (2-3 ‡∏ä‡∏°.)
- [ ] **Phase 6.2**: ‡∏™‡∏£‡πâ‡∏≤‡∏á `useWebSocketTTS.ts` hook (2-3 ‡∏ä‡∏°.)
- [ ] **Phase 6.3**: ‡∏™‡∏£‡πâ‡∏≤‡∏á `useCompleteVoiceChat.ts` (2-3 ‡∏ä‡∏°.)
- [ ] **Phase 6.4**: Full system integration testing (2 ‡∏ä‡∏°.)

**Total Estimated Effort: 18-25 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á**

---

## ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á

1. **Token Expiration**: ElevenLabs single-use token ‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏‡πÉ‡∏ô 15 ‡∏ô‡∏≤‡∏ó‡∏µ - ‡∏ï‡πâ‡∏≠‡∏á refresh
2. **WebSocket Reconnection**: ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ retry logic ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ reconnect
3. **Audio Format**: ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ PCM 24kHz ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Avatar
4. **Chunk Size**: ‡∏™‡πà‡∏á audio ‡πÄ‡∏õ‡πá‡∏ô chunks ‡πÜ ‡∏•‡∏∞ 20ms (960 bytes)
5. **Error Handling**: ‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ error ‡∏ó‡∏∏‡∏Å phase
6. **Rate Limiting**: ‡∏£‡∏∞‡∏ß‡∏±‡∏á API rate limits ‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£
7. **Cost**: ‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ 3 ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô - ‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì cost

---

## ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á

- [HeyGen LiveAvatar Docs](https://docs.heygen.com/docs/liveavatar)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [ElevenLabs Docs](https://elevenlabs.io/docs)
- [ElevenLabs Realtime STT](https://elevenlabs.io/docs/cookbooks/speech-to-text/streaming)
- [LiveKit Docs](https://docs.livekit.io)
- [WebSocket API (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [Testing Documentation](./TEST_V2V_PROCESS.md)
