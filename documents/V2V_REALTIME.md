# Voice-to-Voice Real-time Communication System
**HeyGen LiveAvatar + OpenAI + ElevenLabs Integration**

---

## ğŸ“Š IMPLEMENTATION STATUS SUMMARY

### à¸£à¸°à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¸à¸£à¹‰à¸­à¸¡: **70% à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™** âœ…

| Phase | Status | Progress | Ready for Production |
|-------|--------|----------|---------------------|
| **Phase 1**: Session Management | âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 100% | âœ… YES |
| **Phase 2**: Voice Chat (FULL) | âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 100% | âœ… YES |
| **Phase 3**: Custom Voice Chat | âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 100% | âœ… YES |
| **Phase 4**: Realtime STT | âš ï¸ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 0% | âŒ NO |
| **Phase 5**: WebSocket Chat | âš ï¸ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 0% | âŒ NO |
| **Phase 6**: WebSocket TTS | âš ï¸ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 0% | âŒ NO |

### à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ (Production Ready)

âœ… **à¹‚à¸«à¸¡à¸” FULL** - Voice-to-Voice à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¸”à¹‰à¸§à¸¢ HeyGen built-in AI
- Latency: ~1-2 à¸§à¸´à¸™à¸²à¸—à¸µ
- à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¸—à¸±à¸™à¸—à¸µ

âœ… **à¹‚à¸«à¸¡à¸” CUSTOM + REST APIs** - Voice-to-Voice à¹à¸šà¸šà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹„à¸”à¹‰
- Pipeline: User Speech â†’ Whisper STT â†’ OpenAI Chat â†’ ElevenLabs TTS â†’ Avatar
- Latency: ~3-5 à¸§à¸´à¸™à¸²à¸—à¸µ
- à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡ AI à¹à¸¥à¸°à¹€à¸ªà¸µà¸¢à¸‡à¹„à¸”à¹‰à¹€à¸•à¹‡à¸¡à¸—à¸µà¹ˆ

### à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¸•à¹‰à¸­à¸‡à¸à¸±à¸’à¸™à¸² (Need Implementation)

âš ï¸ **Phase 4-6**: Real-time WebSocket Features
- ElevenLabs Realtime STT (à¹„à¸¡à¹ˆà¸¡à¸µ API endpoint à¹à¸¥à¸° Hook)
- WebSocket Chat Server (à¹„à¸¡à¹ˆà¸¡à¸µ Custom Server)
- WebSocket Streaming TTS (à¹„à¸¡à¹ˆà¸¡à¸µ Custom Server)
- Total Effort: ~18-25 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡

### à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™

**à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„à¸—à¸µà¹ˆà¸¢à¸­à¸¡à¸£à¸±à¸š Latency 3-5 à¸§à¸´à¸™à¸²à¸—à¸µ:**
```bash
pnpm dev
# à¹€à¸›à¸´à¸” http://localhost:3000
# à¹€à¸¥à¸·à¸­à¸ CUSTOM mode â†’ à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¹€à¸¥à¸¢
```

**à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£ Real-time (<1 à¸§à¸´à¸™à¸²à¸—à¸µ):**
- à¸•à¹‰à¸­à¸‡à¸—à¸³ Phase 4-6 à¹ƒà¸«à¹‰à¹€à¸ªà¸£à¹‡à¸ˆà¸à¹ˆà¸­à¸™
- à¸”à¸¹à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸”à¹‰à¸²à¸™à¸¥à¹ˆà¸²à¸‡

---

## à¸ªà¸£à¸¸à¸›à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™

à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„à¸™à¸µà¹‰à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸šà¸ªà¸™à¸—à¸™à¸² Voice-to-Voice à¹à¸šà¸š Real-time à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ HeyGen LiveAvatar à¹€à¸›à¹‡à¸™ Avatar à¸«à¸¥à¸±à¸ à¹‚à¸”à¸¢à¸£à¸­à¸‡à¸£à¸±à¸š 2 à¹‚à¸«à¸¡à¸”:

### à¹‚à¸«à¸¡à¸” FULL âœ… (à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™)
- HeyGen à¸ˆà¸±à¸”à¸à¸²à¸£à¸—à¸¸à¸à¸­à¸¢à¹ˆà¸²à¸‡ (STT, AI, TTS, Lip-sync)
- à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸„à¸§à¸²à¸¡à¸‡à¹ˆà¸²à¸¢à¹à¸¥à¸°à¸£à¸§à¸”à¹€à¸£à¹‡à¸§
- Latency: 1-2 à¸§à¸´à¸™à¸²à¸—à¸µ

### à¹‚à¸«à¸¡à¸” CUSTOM âœ… (à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™)
- à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸„à¸§à¸šà¸„à¸¸à¸¡ AI (OpenAI GPT) à¹à¸¥à¸° TTS (ElevenLabs)
- HeyGen à¸—à¸³à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆà¹à¸„à¹ˆ Video Streaming à¹à¸¥à¸° Lip-sync
- à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸šà¸¸à¸„à¸¥à¸´à¸à¸ à¸²à¸à¹à¸¥à¸°à¹€à¸ªà¸µà¸¢à¸‡à¸‚à¸­à¸‡ Avatar
- Latency: 3-5 à¸§à¸´à¸™à¸²à¸—à¸µ (REST APIs)

### à¹‚à¸«à¸¡à¸” CUSTOM + WebSocket âš ï¸ (à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸à¸£à¹‰à¸­à¸¡ - à¸•à¹‰à¸­à¸‡à¸à¸±à¸’à¸™à¸² Phase 4-6)
- à¹ƒà¸Šà¹‰ WebSocket à¹à¸—à¸™ REST APIs
- Latency: <1 à¸§à¸´à¸™à¸²à¸—à¸µ (Real-time streaming)
- à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ Custom WebSocket Server

## à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸«à¸¥à¸±à¸à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰

| à¸šà¸£à¸´à¸à¸²à¸£ | à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ | Implementation Status | à¹€à¸­à¸à¸ªà¸²à¸£ |
|--------|---------|---------------------|---------|
| **HeyGen LiveAvatar** | Video Streaming, Lip-sync Animation | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://api.liveavatar.com |
| **OpenAI Whisper** | Speech-to-Text (CUSTOM mode) | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://platform.openai.com/docs/guides/speech-to-text |
| **OpenAI GPT-4** | AI Conversation (CUSTOM mode) | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://platform.openai.com/docs/guides/chat |
| **ElevenLabs** | Text-to-Speech (CUSTOM mode) | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://elevenlabs.io/docs |
| **ElevenLabs Scribe** | Real-time Speech-to-Text | âš ï¸ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://elevenlabs.io/docs/cookbooks/speech-to-text/streaming |
| **LiveKit** | WebRTC Video Streaming | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://docs.livekit.io |
| **WebSocket** | Real-time Command/Event Communication | âš ï¸ à¹ƒà¸Šà¹‰à¸šà¸²à¸‡à¸ªà¹ˆà¸§à¸™ (HeyGen) | - |

## à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸£à¸±à¸™à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„

### 1. à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ Dependencies

```bash
# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ pnpm (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ)
npm install -g pnpm@9.0.0

# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ dependencies
pnpm install
```

### 2. à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Environment Variables

à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ `.env.local` à¹ƒà¸™ `apps/demo/`:

```env
# HeyGen LiveAvatar (à¸ˆà¸³à¹€à¸›à¹‡à¸™)
LIVEAVATAR_API_KEY=your_heygen_api_key
LIVEAVATAR_AVATAR_ID=dd73ea75-1218-4ef3-92ce-606d5f7fbc0a

# à¸ªà¸³à¸«à¸£à¸±à¸š FULL mode (optional)
LIVEAVATAR_VOICE_ID=your_voice_id
LIVEAVATAR_CONTEXT_ID=your_context_id
LIVEAVATAR_LANGUAGE=en

# à¸ªà¸³à¸«à¸£à¸±à¸š CUSTOM mode (à¸ˆà¸³à¹€à¸›à¹‡à¸™)
OPENAI_API_KEY=your_openai_api_key
ELEVENLABS_API_KEY=your_elevenlabs_api_key
ELEVENLABS_VOICE_ID=pqHfZKP75CvOlQylNhV4
ELEVENLABS_MODEL=eleven_v3
```

### 3. à¸£à¸±à¸™à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„

```bash
# à¸£à¸±à¸™ Demo application
pnpm demo

# à¸«à¸£à¸·à¸­à¸£à¸±à¸™ Development mode
pnpm dev

# Build à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„
pnpm build
```

à¹€à¸›à¸´à¸”à¹€à¸šà¸£à¸²à¸§à¹Œà¹€à¸‹à¸­à¸£à¹Œà¸—à¸µà¹ˆ http://localhost:3000

---

# IMPLEMENTATION FLOW

## PHASE 1: Session Management âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

**Status:** âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ - à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¸—à¸±à¹‰à¸‡ FULL à¹à¸¥à¸° CUSTOM mode

### à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™

Phase à¸™à¸µà¹‰à¸ˆà¸±à¸”à¸à¸²à¸£ Session lifecycle à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”:

1. **Start Session (FULL/CUSTOM Mode)** - à¸ªà¸£à¹‰à¸²à¸‡ session token à¸ˆà¸²à¸ HeyGen API
   - FULL Mode: à¸¡à¸µ avatar_persona (voice_id, context_id, language)
   - CUSTOM Mode: à¹„à¸¡à¹ˆà¸¡à¸µ avatar_persona (à¸„à¸§à¸šà¸„à¸¸à¸¡à¹€à¸­à¸‡)

2. **Keep Session Alive** - à¸•à¹ˆà¸­à¸­à¸²à¸¢à¸¸ session à¸—à¸¸à¸ 5 à¸™à¸²à¸—à¸µ (à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ timeout)

3. **Stop Session** - à¸›à¸´à¸” session à¹à¸¥à¸° cleanup resources

4. **WebSocket Connection** - à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ WebSocket à¸ªà¸³à¸«à¸£à¸±à¸š CUSTOM mode (à¸ªà¹ˆà¸‡à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸„à¸§à¸šà¸„à¸¸à¸¡ Avatar)

### Files Implemented

- API: `apps/demo/app/api/start-session/route.ts` âœ…
- API: `apps/demo/app/api/start-custom-session/route.ts` âœ…
- API: `apps/demo/app/api/keep-session-alive/route.ts` âœ…
- API: `apps/demo/app/api/stop-session/route.ts` âœ…
- Hook: `apps/demo/src/liveavatar/useSession.ts` âœ…

### à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š

```bash
# 1. à¸—à¸”à¸ªà¸­à¸šà¸”à¹‰à¸§à¸¢ Postman
POST http://localhost:3000/api/start-session

# 2. à¸—à¸”à¸ªà¸­à¸šà¸”à¹‰à¸§à¸¢ HTML (Optional)
# à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ: public/test-session-lifecycle.html
# à¹€à¸›à¸´à¸”: http://localhost:3000/test-session-lifecycle.html

# 3. à¸—à¸”à¸ªà¸­à¸šà¹ƒà¸™à¹à¸­à¸à¸«à¸¥à¸±à¸
pnpm dev
# à¹€à¸›à¸´à¸” http://localhost:3000 â†’ Start Session
```

---

## PHASE 2: Voice Chat (FULL Mode) âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

**Status:** âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ - à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¹€à¸•à¹‡à¸¡à¸£à¸¹à¸›à¹à¸šà¸š

### à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™

FULL Mode à¹ƒà¸Šà¹‰ HeyGen à¸ˆà¸±à¸”à¸à¸²à¸£ Voice Chat à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”:

1. **Voice Chat Start** - à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™ voice chat à¸à¸£à¹‰à¸­à¸¡ microphone access
2. **Real-time STT** - HeyGen à¹à¸›à¸¥à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡
3. **AI Response** - HeyGen generate à¸„à¸³à¸•à¸­à¸šà¸”à¹‰à¸§à¸¢ built-in AI
4. **TTS & Lip-sync** - HeyGen à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¹à¸¥à¸°à¸—à¸³ lip-sync
5. **Microphone Control** - Mute/Unmute/Stop

### Flow

```
User Speaks â†’ HeyGen STT â†’ HeyGen AI â†’ HeyGen TTS â†’ Avatar Speaks
           (All handled by HeyGen internally)
```

### Files Implemented

- Hook: `apps/demo/src/liveavatar/useVoiceChat.ts` âœ…
- Component: `apps/demo/src/components/LiveAvatarSession.tsx` âœ…

### à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š

```bash
pnpm dev
# à¹€à¸›à¸´à¸” http://localhost:3000
# 1. à¹€à¸¥à¸·à¸­à¸ "FULL Mode"
# 2. à¸à¸” "Start Session"
# 3. à¸à¸” "Start Voice Chat"
# 4. à¸à¸¹à¸”à¸­à¸°à¹„à¸£à¸à¹‡à¹„à¸”à¹‰ â†’ Avatar à¸„à¸§à¸£à¸•à¸­à¸šà¸à¸¥à¸±à¸š
```

---

## PHASE 3: Custom Voice Chat (CUSTOM Mode) âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

**Status:** âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ - à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¹€à¸•à¹‡à¸¡à¸£à¸¹à¸›à¹à¸šà¸š

### à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™

CUSTOM Mode à¹ƒà¸«à¹‰à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸„à¸§à¸šà¸„à¸¸à¸¡ AI à¹à¸¥à¸° TTS à¹€à¸­à¸‡:

1. **Audio Recording** - à¸šà¸±à¸™à¸—à¸¶à¸à¹€à¸ªà¸µà¸¢à¸‡à¸”à¹‰à¸§à¸¢ Web Audio API (AudioWorklet)
2. **Speech-to-Text** - OpenAI Whisper à¹à¸›à¸¥à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ (batch)
3. **AI Chat** - OpenAI GPT-4o-mini generate à¸„à¸³à¸•à¸­à¸š
4. **Text-to-Speech** - ElevenLabs à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¸µà¸¢à¸‡ (PCM 24kHz)
5. **Avatar Lip-sync** - à¸ªà¹ˆà¸‡à¹€à¸ªà¸µà¸¢à¸‡à¹„à¸› HeyGen à¸œà¹ˆà¸²à¸™ WebSocket (chunks 20ms)

### Flow

```
User Speaks â†’ AudioWorklet â†’ Whisper STT â†’ OpenAI Chat â†’ ElevenLabs TTS â†’ Avatar Speaks
                                                                            (WebSocket chunks)
```

### Files Implemented

- Hook: `apps/demo/src/liveavatar/useCustomVoiceChat.ts` âœ…
- Hook: `apps/demo/src/liveavatar/useTextChat.ts` âœ…
- API: `apps/demo/app/api/openai-whisper-stt/route.ts` âœ…
- API: `apps/demo/app/api/openai-chat-complete/route.ts` âœ…
- API: `apps/demo/app/api/elevenlabs-text-to-speech/route.ts` âœ…
- Audio Processor: `apps/demo/public/audio-processor.js` âœ…
- SDK: `packages/js-sdk/src/audio_utils.ts` âœ…

### à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š

```bash
pnpm dev
# à¹€à¸›à¸´à¸” http://localhost:3000
# 1. à¹€à¸¥à¸·à¸­à¸ "CUSTOM Mode"
# 2. à¸à¸” "Start Session"
# 3. à¸à¸” "Start Recording" (Push-to-talk)
# 4. à¸à¸¹à¸”à¸­à¸°à¹„à¸£à¸à¹‡à¹„à¸”à¹‰
# 5. à¸à¸” "Stop Recording"
# 6. à¸£à¸°à¸šà¸šà¸ˆà¸°: STT â†’ AI â†’ TTS â†’ Avatar à¸à¸¹à¸”
```

### API Testing

```bash
# Test Whisper STT
POST http://localhost:3000/api/openai-whisper-stt
Content-Type: multipart/form-data
Body: audio file

# Test OpenAI Chat
POST http://localhost:3000/api/openai-chat-complete
Content-Type: application/json
Body: {"message": "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š"}

# Test ElevenLabs TTS
POST http://localhost:3000/api/elevenlabs-text-to-speech
Content-Type: application/json
Body: {"text": "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š"}
```

---

## PHASE 4: ElevenLabs Realtime Speech-to-Text Integration ğŸ”„ à¸à¸³à¸¥à¸±à¸‡à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£

**Status:** ğŸ”„ **à¸à¸³à¸¥à¸±à¸‡à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£** - TASK 4.1 à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ (33% complete)
**Progress:**
- âœ… TASK 4.1: Single-Use Token API (à¸ªà¸³à¹€à¸£à¹‡à¸ˆ)
- âš ï¸ TASK 4.2: React Hook (à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸—à¸³)
- âš ï¸ TASK 4.3: Integration (à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸—à¸³)

**Estimated Remaining Effort:** 3-4 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡

### à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¸¡à¸µ Phase à¸™à¸µà¹‰?

Phase 3 à¹ƒà¸Šà¹‰ OpenAI Whisper à¹à¸šà¸š **batch** (à¸•à¹‰à¸­à¸‡à¸£à¸­à¸šà¸±à¸™à¸—à¸¶à¸à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸ªà¸£à¹‡à¸ˆà¸à¹ˆà¸­à¸™) à¸—à¸³à¹ƒà¸«à¹‰à¸¡à¸µ latency à¸ªà¸¹à¸‡ (3-5 à¸§à¸´à¸™à¸²à¸—à¸µ)

Phase 4 à¸ˆà¸°à¹ƒà¸Šà¹‰ ElevenLabs Scribe **real-time streaming** à¸—à¸³à¹ƒà¸«à¹‰:
- âœ… à¸¡à¸µ partial transcripts (à¹€à¸«à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹à¸šà¸š real-time à¸‚à¸“à¸°à¸à¸¹à¸”)
- âœ… à¸¥à¸” latency à¹€à¸«à¸¥à¸·à¸­ <500ms
- âœ… à¸›à¸£à¸°à¸ªà¸šà¸à¸²à¸£à¸“à¹Œà¸”à¸µà¸à¸§à¹ˆà¸² (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸­)

### à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸—à¸³

1. âœ… **API Endpoint**: `/api/elevenlabs-stt-token` - **à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§**
   - Generate single-use token à¸ªà¸³à¸«à¸£à¸±à¸š WebSocket authentication
   - Token à¸«à¸¡à¸”à¸­à¸²à¸¢à¸¸à¹ƒà¸™ 15 à¸™à¸²à¸—à¸µ
   - HTML test page: `http://localhost:3000/test-elevenlabs-stt-token.html`

2. âš ï¸ **React Hook**: `apps/demo/src/liveavatar/useElevenLabsRealtimeSTT.ts` - **à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸—à¸³**
   - Connect WebSocket to ElevenLabs Scribe API
   - Stream audio à¸ˆà¸²à¸ microphone
   - Handle partial/final transcripts

3. âš ï¸ **Integration**: à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸à¸±à¸š Avatar à¹à¸¥à¸° OpenAI Chat - **à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸—à¸³**

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Microphone   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (Web Audio API)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AudioWorklet         â”‚
â”‚ (PCM 16kHz)          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (Real-time chunks)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ElevenLabs WebSocket         â”‚ â† wss://api.elevenlabs.io/v1/speech-to-text/realtime
â”‚ (Scribe v2 Realtime)         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â†’ partial_transcript (à¸‚à¸“à¸°à¸à¸¹à¸”)
       â””â”€â†’ committed_transcript (à¸à¸¹à¸”à¹€à¸ªà¸£à¹‡à¸ˆ)
```

### TASK 4.1: à¸ªà¸£à¹‰à¸²à¸‡ API Endpoint à¸ªà¸³à¸«à¸£à¸±à¸š Single-Use Token âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§

**Status:** âœ… **à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§** - API endpoint à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

**à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡:** `apps/demo/app/api/elevenlabs-stt-token/route.ts` âœ…

```typescript
import { NextResponse } from 'next/server';
import { ELEVENLABS_API_KEY } from '../secrets';

export async function POST() {
  try {
    const response = await fetch(
      'https://api.elevenlabs.io/v1/single-use-token/realtime_scribe',
      {
        method: 'POST',
        headers: { 'xi-api-key': ELEVENLABS_API_KEY }
      }
    );

    if (!response.ok) {
      throw new Error(`ElevenLabs API error: ${response.statusText}`);
    }

    const data = await response.json();
    return NextResponse.json({
      token: data.token,
      expires_at: data.expires_at
    });
  } catch (error) {
    console.error('Error generating token:', error);
    return NextResponse.json(
      { error: 'Failed to generate token' },
      { status: 500 }
    );
  }
}
```

**à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š:**

1. **à¸”à¹‰à¸§à¸¢ HTML Test Page (à¹à¸™à¸°à¸™à¸³):**
```bash
# à¸£à¸±à¸™à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„
pnpm dev

# à¹€à¸›à¸´à¸” test page
http://localhost:3000/test-elevenlabs-stt-token.html

# à¸„à¸¥à¸´à¸ "Generate Token" â†’ à¸”à¸¹à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹à¸¥à¸° countdown
```

2. **à¸”à¹‰à¸§à¸¢ Postman:**
```bash
POST http://localhost:3000/api/elevenlabs-stt-token

# Expected Response:
{
  "token": "eyJhbGci...",
  "expires_at": "2025-01-15T10:30:00Z"
}
```

**à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¹„à¸”à¹‰:**
- âœ… API endpoint à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡ single-use token
- âœ… Token à¸«à¸¡à¸”à¸­à¸²à¸¢à¸¸à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¹ƒà¸™ 15 à¸™à¸²à¸—à¸µ
- âœ… HTML test page à¸à¸£à¹‰à¸­à¸¡ countdown timer
- âœ… à¸£à¸±à¸à¸©à¸² API key à¹„à¸§à¹‰à¸šà¸™ backend (à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢)

---

### TASK 4.2: à¸ªà¸£à¹‰à¸²à¸‡ React Hook à¸ªà¸³à¸«à¸£à¸±à¸š Realtime STT

**à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ:** `apps/demo/src/liveavatar/useElevenLabsRealtimeSTT.ts`

```typescript
import { useState, useRef, useCallback } from 'react';

interface RealtimeSTTConfig {
  language?: string;
  sampleRate?: number;
  onPartialTranscript?: (text: string) => void;
  onFinalTranscript?: (text: string) => void;
  onError?: (error: any) => void;
}

export function useElevenLabsRealtimeSTT(config: RealtimeSTTConfig = {}) {
  const [isConnected, setIsConnected] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [partialText, setPartialText] = useState('');
  const [finalText, setFinalText] = useState('');

  const wsRef = useRef<WebSocket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const workletNodeRef = useRef<AudioWorkletNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);

  const connect = useCallback(async () => {
    try {
      // 1. Get token from backend
      const tokenRes = await fetch('/api/elevenlabs-stt-token', {
        method: 'POST'
      });
      const { token } = await tokenRes.json();

      // 2. Build WebSocket URL
      const params = new URLSearchParams({
        model_id: 'scribe_v2_realtime',
        language_code: config.language || 'th',
        audio_format: `pcm_${config.sampleRate || 16000}`,
        commit_strategy: 'vad', // Auto-commit on silence
        vad_silence_threshold_secs: '1.0',
        vad_threshold: '0.5'
      });
      const wsUrl = `wss://api.elevenlabs.io/v1/speech-to-text/realtime?${params}`;

      // 3. Connect WebSocket
      const ws = new WebSocket(wsUrl);
      wsRef.current = ws;

      ws.onopen = () => {
        console.log('ElevenLabs STT connected');
        setIsConnected(true);

        // Send authentication
        ws.send(JSON.stringify({
          message_type: 'auth',
          token: token
        }));
      };

      ws.onmessage = (event) => {
        const message = JSON.parse(event.data);

        switch (message.message_type) {
          case 'session_started':
            console.log('Session started');
            break;

          case 'partial_transcript':
            setPartialText(message.text);
            config.onPartialTranscript?.(message.text);
            break;

          case 'committed_transcript':
            setFinalText(prev => prev + ' ' + message.text);
            config.onFinalTranscript?.(message.text);
            setPartialText('');
            break;

          case 'auth_error':
          case 'transcriber_error':
          case 'input_error':
            console.error('STT Error:', message);
            config.onError?.(message);
            break;
        }
      };

      ws.onerror = (error) => {
        console.error('WebSocket error:', error);
        config.onError?.(error);
      };

      ws.onclose = () => {
        console.log('WebSocket closed');
        setIsConnected(false);
      };

    } catch (error) {
      console.error('Failed to connect:', error);
      config.onError?.(error);
    }
  }, [config]);

  const startRecording = useCallback(async () => {
    if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
      await connect();
    }

    try {
      const sampleRate = config.sampleRate || 16000;

      // Create audio context
      const audioContext = new AudioContext({ sampleRate });
      audioContextRef.current = audioContext;

      // Load audio processor
      await audioContext.audioWorklet.addModule('/audio-processor.js');

      // Create worklet node
      const workletNode = new AudioWorkletNode(
        audioContext,
        'audio-recorder-processor'
      );
      workletNodeRef.current = workletNode;

      // Get microphone
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: sampleRate
        }
      });
      streamRef.current = stream;

      // Connect audio pipeline
      const source = audioContext.createMediaStreamSource(stream);
      source.connect(workletNode);

      // Handle audio chunks - Send to ElevenLabs
      workletNode.port.onmessage = (event) => {
        if (event.data.type === 'audioData' && wsRef.current) {
          const pcmData = new Float32Array(event.data.data);

          // Convert Float32 to Int16
          const int16Data = new Int16Array(pcmData.length);
          for (let i = 0; i < pcmData.length; i++) {
            const s = Math.max(-1, Math.min(1, pcmData[i]));
            int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
          }

          // Convert to base64
          const base64Audio = btoa(
            String.fromCharCode(...new Uint8Array(int16Data.buffer))
          );

          // Send to ElevenLabs
          wsRef.current.send(JSON.stringify({
            message_type: 'input_audio_chunk',
            audio_base_64: base64Audio,
            sample_rate: sampleRate,
            commit: false
          }));
        }
      };

      setIsRecording(true);

    } catch (error) {
      console.error('Failed to start recording:', error);
      config.onError?.(error);
    }
  }, [connect, config]);

  const stopRecording = useCallback(() => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }

    if (workletNodeRef.current) {
      workletNodeRef.current.disconnect();
      workletNodeRef.current = null;
    }

    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    setIsRecording(false);
  }, []);

  const disconnect = useCallback(() => {
    stopRecording();

    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }

    setIsConnected(false);
  }, [stopRecording]);

  return {
    isConnected,
    isRecording,
    partialText,
    finalText,
    connect,
    disconnect,
    startRecording,
    stopRecording
  };
}
```

---

### TASK 4.3: Integration à¸à¸±à¸š Avatar

**à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Hook à¹ƒà¸™ Component:**

```typescript
// à¹ƒà¸™ LiveAvatarSession component

import { useElevenLabsRealtimeSTT } from '../liveavatar/useElevenLabsRealtimeSTT';

function LiveAvatarSession() {
  const stt = useElevenLabsRealtimeSTT({
    language: 'th',
    sampleRate: 16000,

    onPartialTranscript: (text) => {
      // à¹à¸ªà¸”à¸‡ real-time transcript
      console.log('Partial:', text);
    },

    onFinalTranscript: async (text) => {
      console.log('Final:', text);

      // à¸ªà¹ˆà¸‡à¹„à¸›à¸¢à¸±à¸‡ OpenAI Chat
      const chatRes = await fetch('/api/openai-chat-complete', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ message: text })
      });
      const { response } = await chatRes.json();

      // à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™à¹€à¸ªà¸µà¸¢à¸‡à¸”à¹‰à¸§à¸¢ ElevenLabs
      const ttsRes = await fetch('/api/elevenlabs-text-to-speech', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text: response })
      });
      const { audio } = await ttsRes.json();

      // à¸ªà¹ˆà¸‡à¹„à¸›à¸¢à¸±à¸‡ Avatar
      sessionRef.current?.repeatAudio(audio);
    },

    onError: (error) => {
      console.error('STT Error:', error);
    }
  });

  return (
    <div>
      <button onClick={stt.connect}>Connect STT</button>
      <button onClick={stt.startRecording}>Start Recording</button>
      <button onClick={stt.stopRecording}>Stop Recording</button>
      <button onClick={stt.disconnect}>Disconnect</button>

      <div>Partial: {stt.partialText}</div>
      <div>Final: {stt.finalText}</div>
    </div>
  );
}
```

---

### Testing Phase 4

**1. Test Token Generation:**
```bash
# Postman
POST http://localhost:3000/api/elevenlabs-stt-token

# Expected: { "token": "...", "expires_at": "..." }
```

**2. Test WebSocket Connection:**
```bash
# Install wscat
npm install -g wscat

# Get token
curl -X POST http://localhost:3000/api/elevenlabs-stt-token

# Connect
wscat -c "wss://api.elevenlabs.io/v1/speech-to-text/realtime?model_id=scribe_v2_realtime&language_code=th&audio_format=pcm_16000&commit_strategy=vad"

# Send auth
{"message_type":"auth","token":"your_token_here"}

# Expected: {"message_type":"session_started",...}
```

**3. Test Full Integration:**
```bash
pnpm dev
# à¹€à¸›à¸´à¸” http://localhost:3000
# à¹€à¸¥à¸·à¸­à¸ CUSTOM Mode
# à¹ƒà¸Šà¹‰ Realtime STT button
# à¸•à¹‰à¸­à¸‡à¹€à¸«à¹‡à¸™ partial transcripts à¹à¸šà¸š real-time
```

---

## PHASE 5: WebSocket Integration for OpenAI Chat âš ï¸ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸—à¸³

**Status:** âš ï¸ **à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰ Implement** - à¸•à¹‰à¸­à¸‡à¸ªà¸£à¹‰à¸²à¸‡ Custom WebSocket Server
**Estimated Effort:** 5-7 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡

### à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¸¡à¸µ Phase à¸™à¸µà¹‰?

Phase 3 à¹ƒà¸Šà¹‰ OpenAI Chat à¹à¸šà¸š **REST API** (request/response à¹à¸¢à¸à¸à¸±à¸™) à¸—à¸³à¹ƒà¸«à¹‰:
- âŒ à¸•à¹‰à¸­à¸‡ establish connection à¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡ (overhead)
- âŒ à¹„à¸¡à¹ˆà¹€à¸à¹‡à¸š conversation history à¸šà¸™ server
- âŒ Latency à¸ªà¸¹à¸‡à¸à¸§à¹ˆà¸² WebSocket

Phase 5 à¸ˆà¸°à¹ƒà¸Šà¹‰ **WebSocket** à¸—à¸³à¹ƒà¸«à¹‰:
- âœ… Connection à¸„à¸‡à¸­à¸¢à¸¹à¹ˆà¸•à¸¥à¸­à¸” (persistent connection)
- âœ… à¸¥à¸” latency (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ handshake à¸‹à¹‰à¸³)
- âœ… Server à¸ˆà¸±à¸”à¸à¸²à¸£ conversation history

### à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¸•à¹‰à¸­à¸‡à¸ªà¸£à¹‰à¸²à¸‡

1. âŒ **Custom WebSocket Server**: `apps/demo/server/websocket-server.ts`
2. âŒ **React Hook**: `apps/demo/src/liveavatar/useWebSocketChat.ts`
3. âŒ **Package Scripts**: à¸­à¸±à¸à¹€à¸”à¸• `package.json` à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸±à¸™ WebSocket server

**à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸:** Next.js à¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š WebSocket natively - à¸•à¹‰à¸­à¸‡à¸ªà¸£à¹‰à¸²à¸‡ custom server à¹à¸¢à¸

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ React App   â”‚
â”‚ (Port 3000) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (WebSocket)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Custom WS Server     â”‚ â† ws://localhost:3001
â”‚ (Port 3001)          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (HTTP)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI API           â”‚
â”‚ (Chat Completions)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### TASK 5.1: à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ Dependencies

```bash
pnpm add -D ws @types/ws tsx concurrently
```

---

### TASK 5.2: à¸ªà¸£à¹‰à¸²à¸‡ Custom WebSocket Server

**à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ:** `apps/demo/server/websocket-server.ts`

```typescript
import { WebSocketServer } from 'ws';
import { createServer } from 'http';

const server = createServer();
const wss = new WebSocketServer({ server });

wss.on('connection', (ws) => {
  console.log('Client connected to OpenAI Chat WebSocket');

  let conversationHistory: Array<{role: string, content: string}> = [];

  ws.on('message', async (data) => {
    try {
      const message = JSON.parse(data.toString());

      switch (message.type) {
        case 'chat':
          // Add user message to history
          conversationHistory.push({
            role: 'user',
            content: message.text
          });

          // Call OpenAI
          const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
            },
            body: JSON.stringify({
              model: 'gpt-4o-mini',
              messages: [
                {
                  role: 'system',
                  content: message.system_prompt || 'You are a helpful assistant.'
                },
                ...conversationHistory
              ]
            })
          });

          const data = await response.json();
          const assistantMessage = data.choices[0].message.content;

          // Add to history
          conversationHistory.push({
            role: 'assistant',
            content: assistantMessage
          });

          // Send response
          ws.send(JSON.stringify({
            type: 'chat_response',
            text: assistantMessage
          }));
          break;

        case 'reset':
          conversationHistory = [];
          ws.send(JSON.stringify({
            type: 'reset_confirmed'
          }));
          break;
      }

    } catch (error) {
      ws.send(JSON.stringify({
        type: 'error',
        error: error.message
      }));
    }
  });

  ws.on('close', () => {
    console.log('Client disconnected');
  });
});

server.listen(3001, () => {
  console.log('WebSocket server running on port 3001');
});
```

---

### TASK 5.3: à¸­à¸±à¸à¹€à¸”à¸• package.json

**à¹à¸à¹‰à¹„à¸‚:** `apps/demo/package.json`

```json
{
  "scripts": {
    "dev": "next dev",
    "ws-server": "tsx server/websocket-server.ts",
    "dev:full": "concurrently \"pnpm dev\" \"pnpm ws-server\""
  }
}
```

**à¸£à¸±à¸™:**
```bash
# Terminal 1: Next.js
pnpm dev

# Terminal 2: WebSocket server
pnpm ws-server

# à¸«à¸£à¸·à¸­à¸£à¸±à¸™à¸à¸£à¹‰à¸­à¸¡à¸à¸±à¸™
pnpm dev:full
```

---

### TASK 5.4: à¸ªà¸£à¹‰à¸²à¸‡ React Hook

**à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ:** `apps/demo/src/liveavatar/useWebSocketChat.ts`

```typescript
import { useState, useRef, useCallback, useEffect } from 'react';

interface ChatMessage {
  role: 'user' | 'assistant';
  content: string;
  timestamp: number;
}

export function useWebSocketChat(wsUrl: string = 'ws://localhost:3001') {
  const [isConnected, setIsConnected] = useState(false);
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const wsRef = useRef<WebSocket | null>(null);

  const connect = useCallback(() => {
    const ws = new WebSocket(wsUrl);
    wsRef.current = ws;

    ws.onopen = () => {
      console.log('Connected to chat WebSocket');
      setIsConnected(true);
    };

    ws.onmessage = (event) => {
      const message = JSON.parse(event.data);

      switch (message.type) {
        case 'chat_response':
          setMessages(prev => [...prev, {
            role: 'assistant',
            content: message.text,
            timestamp: Date.now()
          }]);
          break;

        case 'error':
          console.error('Chat error:', message.error);
          break;
      }
    };

    ws.onerror = (error) => {
      console.error('WebSocket error:', error);
    };

    ws.onclose = () => {
      console.log('Disconnected from chat');
      setIsConnected(false);
    };
  }, [wsUrl]);

  const disconnect = useCallback(() => {
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }
  }, []);

  const sendMessage = useCallback((text: string, systemPrompt?: string) => {
    if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
      console.error('WebSocket not connected');
      return;
    }

    // Add user message to UI
    setMessages(prev => [...prev, {
      role: 'user',
      content: text,
      timestamp: Date.now()
    }]);

    // Send to server
    wsRef.current.send(JSON.stringify({
      type: 'chat',
      text,
      system_prompt: systemPrompt
    }));
  }, []);

  const reset = useCallback(() => {
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({
        type: 'reset'
      }));
      setMessages([]);
    }
  }, []);

  // Auto-connect on mount
  useEffect(() => {
    connect();
    return () => disconnect();
  }, [connect, disconnect]);

  return {
    isConnected,
    messages,
    connect,
    disconnect,
    sendMessage,
    reset
  };
}
```

**à¹ƒà¸Šà¹‰à¸‡à¸²à¸™:**

```typescript
import { useWebSocketChat } from '../liveavatar/useWebSocketChat';

function ChatInterface() {
  const { isConnected, messages, sendMessage, reset } = useWebSocketChat();
  const [input, setInput] = useState('');

  return (
    <div>
      <div>Status: {isConnected ? 'Connected' : 'Disconnected'}</div>

      {messages.map((msg, i) => (
        <div key={i}>
          <strong>{msg.role}:</strong> {msg.content}
        </div>
      ))}

      <input value={input} onChange={e => setInput(e.target.value)} />
      <button onClick={() => sendMessage(input)}>Send</button>
      <button onClick={reset}>Reset</button>
    </div>
  );
}
```

---

### Testing Phase 5

**1. Test WebSocket Server:**
```bash
# Install wscat
npm install -g wscat

# Start servers
pnpm dev:full

# Connect
wscat -c ws://localhost:3001

# Send message
{"type":"chat","text":"à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š","system_prompt":"You are helpful."}

# Expected: {"type":"chat_response","text":"à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š..."}
```

**2. Test in App:**
```bash
pnpm dev:full
# à¹€à¸›à¸´à¸” http://localhost:3000
# à¹ƒà¸Šà¹‰ WebSocket Chat feature
# à¸„à¸§à¸£à¹€à¸«à¹‡à¸™à¸à¸²à¸£à¸ªà¸™à¸—à¸™à¸²à¹à¸šà¸š real-time à¸à¸£à¹‰à¸­à¸¡ history
```

---

## PHASE 6: WebSocket Integration for ElevenLabs TTS âš ï¸ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸—à¸³

**Status:** âš ï¸ **à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰ Implement** - à¸•à¹‰à¸­à¸‡à¹€à¸à¸´à¹ˆà¸¡ TTS endpoint à¹ƒà¸™ WebSocket Server
**Estimated Effort:** 5-7 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡

### à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¸¡à¸µ Phase à¸™à¸µà¹‰?

Phase 3 à¹ƒà¸Šà¹‰ ElevenLabs TTS à¹à¸šà¸š **REST API** (à¸£à¸­à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸à¹ˆà¸­à¸™à¸ªà¹ˆà¸‡) à¸—à¸³à¹ƒà¸«à¹‰:
- âŒ à¸•à¹‰à¸­à¸‡à¸£à¸­à¹ƒà¸«à¹‰ TTS à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹€à¸ªà¸£à¹‡à¸ˆà¸à¹ˆà¸­à¸™
- âŒ Avatar à¹€à¸£à¸´à¹ˆà¸¡à¸à¸¹à¸”à¸Šà¹‰à¸² (user à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸§à¹ˆà¸² lag)
- âŒ Latency à¸ªà¸¹à¸‡ (1-3 à¸§à¸´à¸™à¸²à¸—à¸µ)

Phase 6 à¸ˆà¸°à¹ƒà¸Šà¹‰ **WebSocket Streaming TTS** à¸—à¸³à¹ƒà¸«à¹‰:
- âœ… Avatar à¹€à¸£à¸´à¹ˆà¸¡à¸à¸¹à¸”à¹„à¸”à¹‰à¸—à¸±à¸™à¸—à¸µà¸—à¸µà¹ˆà¹„à¸”à¹‰ audio chunk à¹à¸£à¸
- âœ… à¸¥à¸” perceived latency (à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸§à¹ˆà¸²à¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™)
- âœ… Smooth playback

### à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¸•à¹‰à¸­à¸‡à¸ªà¸£à¹‰à¸²à¸‡

1. âŒ **à¹€à¸à¸´à¹ˆà¸¡ TTS WebSocket Endpoint** à¹ƒà¸™ `apps/demo/server/websocket-server.ts`
2. âŒ **React Hook**: `apps/demo/src/liveavatar/useWebSocketTTS.ts`
3. âŒ **Complete Integration Hook**: `apps/demo/src/liveavatar/useCompleteVoiceChat.ts`

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Text Input  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WS TTS Server        â”‚ â† ws://localhost:3001/ws-tts
â”‚ (Port 3001)          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (HTTP Streaming)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ElevenLabs API       â”‚
â”‚ (TTS Streaming)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (Audio Chunks)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HeyGen Avatar        â”‚ â† Send chunks à¸—à¸±à¸™à¸—à¸µ
â”‚ (Lip-sync)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### TASK 6.1: à¹€à¸à¸´à¹ˆà¸¡ TTS WebSocket Endpoint

**à¹à¸à¹‰à¹„à¸‚:** `apps/demo/server/websocket-server.ts`

```typescript
import { WebSocketServer } from 'ws';
import { createServer } from 'http';

const server = createServer();

// Chat WebSocket (existing)
const chatWss = new WebSocketServer({ noServer: true });
// ... existing chat code ...

// TTS WebSocket (NEW)
const ttsWss = new WebSocketServer({ noServer: true });

ttsWss.on('connection', (ws) => {
  console.log('Client connected to TTS WebSocket');

  ws.on('message', async (data) => {
    try {
      const message = JSON.parse(data.toString());

      if (message.type === 'synthesize') {
        // Call ElevenLabs streaming TTS
        const response = await fetch(
          `https://api.elevenlabs.io/v1/text-to-speech/${message.voice_id}/stream`,
          {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'xi-api-key': process.env.ELEVENLABS_API_KEY
            },
            body: JSON.stringify({
              text: message.text,
              model_id: message.model_id || 'eleven_v3',
              output_format: 'pcm_24000'
            })
          }
        );

        if (!response.body) {
          throw new Error('No response body');
        }

        // Stream audio chunks
        const reader = response.body.getReader();
        let chunkIndex = 0;

        while (true) {
          const { done, value } = await reader.read();

          if (done) {
            // Send completion signal
            ws.send(JSON.stringify({
              type: 'synthesis_complete'
            }));
            break;
          }

          // Send audio chunk to client
          const base64Chunk = Buffer.from(value).toString('base64');
          ws.send(JSON.stringify({
            type: 'audio_chunk',
            chunk_index: chunkIndex++,
            audio: base64Chunk
          }));
        }
      }

    } catch (error) {
      ws.send(JSON.stringify({
        type: 'error',
        error: error.message
      }));
    }
  });
});

// Upgrade handler (handle multiple paths)
server.on('upgrade', (request, socket, head) => {
  const pathname = new URL(request.url, 'http://localhost').pathname;

  if (pathname === '/ws-chat') {
    chatWss.handleUpgrade(request, socket, head, (ws) => {
      chatWss.emit('connection', ws, request);
    });
  } else if (pathname === '/ws-tts') {
    ttsWss.handleUpgrade(request, socket, head, (ws) => {
      ttsWss.emit('connection', ws, request);
    });
  } else {
    socket.destroy();
  }
});

server.listen(3001, () => {
  console.log('WebSocket server running on port 3001');
  console.log('  /ws-chat - OpenAI Chat');
  console.log('  /ws-tts  - ElevenLabs TTS');
});
```

---

### TASK 6.2: à¸ªà¸£à¹‰à¸²à¸‡ React Hook à¸ªà¸³à¸«à¸£à¸±à¸š Streaming TTS

**à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ:** `apps/demo/src/liveavatar/useWebSocketTTS.ts`

```typescript
import { useState, useRef, useCallback } from 'react';

interface TTSConfig {
  voiceId?: string;
  modelId?: string;
  onAudioChunk?: (chunk: string, index: number) => void;
  onComplete?: () => void;
  onError?: (error: any) => void;
}

export function useWebSocketTTS(
  wsUrl: string = 'ws://localhost:3001/ws-tts',
  config: TTSConfig = {}
) {
  const [isConnected, setIsConnected] = useState(false);
  const [isSynthesizing, setIsSynthesizing] = useState(false);
  const wsRef = useRef<WebSocket | null>(null);
  const audioChunksRef = useRef<string[]>([]);

  const connect = useCallback(() => {
    const ws = new WebSocket(wsUrl);
    wsRef.current = ws;

    ws.onopen = () => {
      console.log('Connected to TTS WebSocket');
      setIsConnected(true);
    };

    ws.onmessage = (event) => {
      const message = JSON.parse(event.data);

      switch (message.type) {
        case 'audio_chunk':
          audioChunksRef.current.push(message.audio);
          config.onAudioChunk?.(message.audio, message.chunk_index);
          break;

        case 'synthesis_complete':
          setIsSynthesizing(false);
          config.onComplete?.();
          break;

        case 'error':
          console.error('TTS error:', message.error);
          setIsSynthesizing(false);
          config.onError?.(message.error);
          break;
      }
    };

    ws.onerror = (error) => {
      console.error('WebSocket error:', error);
      config.onError?.(error);
    };

    ws.onclose = () => {
      console.log('Disconnected from TTS');
      setIsConnected(false);
    };
  }, [wsUrl, config]);

  const disconnect = useCallback(() => {
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }
  }, []);

  const synthesize = useCallback((text: string) => {
    if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
      console.error('WebSocket not connected');
      return;
    }

    audioChunksRef.current = [];
    setIsSynthesizing(true);

    wsRef.current.send(JSON.stringify({
      type: 'synthesize',
      text,
      voice_id: config.voiceId || 'pqHfZKP75CvOlQylNhV4',
      model_id: config.modelId || 'eleven_v3'
    }));
  }, [config.voiceId, config.modelId]);

  const getAudio = useCallback(() => {
    return audioChunksRef.current.join('');
  }, []);

  return {
    isConnected,
    isSynthesizing,
    connect,
    disconnect,
    synthesize,
    getAudio
  };
}
```

---

### TASK 6.3: Complete Voice Chat Integration

**à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ:** `apps/demo/src/liveavatar/useCompleteVoiceChat.ts`

```typescript
import { useState, useEffect, useCallback } from 'react';
import { useElevenLabsRealtimeSTT } from './useElevenLabsRealtimeSTT';
import { useWebSocketChat } from './useWebSocketChat';
import { useWebSocketTTS } from './useWebSocketTTS';
import { LiveAvatarSession } from '@heygen/liveavatar-web-sdk';

export function useCompleteVoiceChat(session: LiveAvatarSession) {
  const [isActive, setIsActive] = useState(false);

  // WebSocket Chat
  const chat = useWebSocketChat('ws://localhost:3001/ws-chat');

  // WebSocket TTS with Avatar integration
  const tts = useWebSocketTTS('ws://localhost:3001/ws-tts', {
    onAudioChunk: (chunk) => {
      // Send chunk to avatar immediately (streaming)
      session.sendCommand({
        type: 'agent.speak',
        event_id: 'voice-chat',
        audio: chunk
      });
    },
    onComplete: () => {
      // Signal end of speech
      session.sendCommand({
        type: 'agent.speak_end',
        event_id: 'voice-chat'
      });
    }
  });

  // Realtime STT
  const stt = useElevenLabsRealtimeSTT({
    language: 'th',
    sampleRate: 16000,

    onFinalTranscript: async (userText) => {
      console.log('User said:', userText);
      // Send to chat WebSocket
      chat.sendMessage(userText);
    }
  });

  // Listen to chat responses â†’ TTS
  useEffect(() => {
    if (chat.messages.length > 0) {
      const lastMessage = chat.messages[chat.messages.length - 1];

      if (lastMessage.role === 'assistant') {
        // Convert to speech via TTS WebSocket (streaming)
        tts.synthesize(lastMessage.content);
      }
    }
  }, [chat.messages, tts]);

  // Start complete voice chat
  const start = useCallback(async () => {
    await stt.connect();
    await chat.connect();
    await tts.connect();
    await stt.startRecording();
    setIsActive(true);
  }, [stt, chat, tts]);

  // Stop voice chat
  const stop = useCallback(() => {
    stt.stopRecording();
    stt.disconnect();
    chat.disconnect();
    tts.disconnect();
    setIsActive(false);
  }, [stt, chat, tts]);

  return {
    isActive,
    start,
    stop,
    messages: chat.messages,
    partialText: stt.partialText,
    isSpeaking: tts.isSynthesizing
  };
}
```

**à¹ƒà¸Šà¹‰à¸‡à¸²à¸™:**

```typescript
function CompleteVoiceChat({ session }: { session: LiveAvatarSession }) {
  const {
    isActive,
    start,
    stop,
    messages,
    partialText,
    isSpeaking
  } = useCompleteVoiceChat(session);

  return (
    <div>
      {!isActive ? (
        <button onClick={start}>ğŸš€ Start Real-time Voice Chat</button>
      ) : (
        <button onClick={stop}>ğŸ›‘ Stop Voice Chat</button>
      )}

      <div>
        <div>Active: {isActive ? 'Yes' : 'No'}</div>
        <div>Avatar Speaking: {isSpeaking ? 'Yes' : 'No'}</div>
        {partialText && <div>Listening: {partialText}</div>}
      </div>

      <div>
        {messages.map((msg, i) => (
          <div key={i}>
            <strong>{msg.role === 'user' ? 'You' : 'Avatar'}:</strong>
            {msg.content}
          </div>
        ))}
      </div>
    </div>
  );
}
```

---

### Testing Phase 6

**1. Test TTS WebSocket:**
```bash
# Start servers
pnpm dev:full

# Test with wscat
wscat -c ws://localhost:3001/ws-tts

# Send
{"type":"synthesize","text":"à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š","voice_id":"pqHfZKP75CvOlQylNhV4"}

# Expected: Multiple audio_chunk messages + synthesis_complete
```

**2. Test Complete Integration:**
```bash
pnpm dev:full
# à¹€à¸›à¸´à¸” http://localhost:3000
# à¹€à¸¥à¸·à¸­à¸ CUSTOM Mode
# à¸à¸” "Start Real-time Voice Chat"
# à¸à¸¹à¸” â†’ à¸•à¹‰à¸­à¸‡à¹€à¸«à¹‡à¸™:
#   1. Partial transcripts à¹à¸šà¸š real-time
#   2. AI response
#   3. Avatar à¹€à¸£à¸´à¹ˆà¸¡à¸à¸¹à¸”à¹€à¸£à¹‡à¸§à¸à¸§à¹ˆà¸²à¹€à¸”à¸´à¸¡ (streaming)
```

---

## à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸—à¸±à¹‰à¸‡à¸£à¸°à¸šà¸š

### Flow Diagram: Complete Real-time V2V

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User speaks    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ElevenLabs Realtime STT  â”‚ â† WebSocket streaming âš ï¸ Phase 4
â”‚ (Scribe v2)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Transcript
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI GPT-4o            â”‚ â† WebSocket chat âš ï¸ Phase 5
â”‚ (Chat Completion)        â”‚    (à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™à¹ƒà¸Šà¹‰ REST API âœ…)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Response text
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ElevenLabs TTS           â”‚ â† WebSocket streaming âš ï¸ Phase 6
â”‚ (Text-to-Speech)         â”‚    (à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™à¹ƒà¸Šà¹‰ REST API âœ…)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Audio chunks (PCM 24kHz)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HeyGen Avatar            â”‚ â† WebSocket commands âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™
â”‚ (Lip-sync + Video)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Video stream (LiveKit)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User sees/hears Avatar   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### à¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¹‚à¸«à¸¡à¸”

| Feature | FULL Mode âœ… | CUSTOM Mode âœ… | CUSTOM + WebSocket âš ï¸ |
|---------|-----------|-------------|-------------------|
| **STT** | HeyGen built-in | OpenAI Whisper (batch) | ElevenLabs Scribe (realtime) |
| **AI** | HeyGen built-in | OpenAI (REST API) | OpenAI (WebSocket) |
| **TTS** | HeyGen built-in | ElevenLabs (REST API) | ElevenLabs (WebSocket streaming) |
| **Latency** | Low (1-2s) | Medium (3-5s) | Lowest (<1s) |
| **Customization** | Limited | Full | Full |
| **Complexity** | Simple | Medium | Advanced |
| **Implementation** | âœ… Done | âœ… Done | âš ï¸ Need Phase 4-6 |
| **Ready** | âœ… YES | âœ… YES | âŒ NO |

---

## ğŸ“‹ TODO List à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸à¸±à¸’à¸™à¸²à¸•à¹ˆà¸­

### High Priority (à¸ªà¸³à¸«à¸£à¸±à¸š Real-time Performance)

- [ ] **Phase 4.1**: à¸ªà¸£à¹‰à¸²à¸‡ `/api/elevenlabs-stt-token` endpoint (1-2 à¸Šà¸¡.)
- [ ] **Phase 4.2**: à¸ªà¸£à¹‰à¸²à¸‡ `useElevenLabsRealtimeSTT.ts` hook (3-4 à¸Šà¸¡.)
- [ ] **Phase 4.3**: Integration testing (1 à¸Šà¸¡.)

### Medium Priority (à¸ªà¸³à¸«à¸£à¸±à¸š Lower Latency)

- [ ] **Phase 5.1**: à¸ªà¸£à¹‰à¸²à¸‡ Custom WebSocket Server (2-3 à¸Šà¸¡.)
- [ ] **Phase 5.2**: à¸ªà¸£à¹‰à¸²à¸‡ `useWebSocketChat.ts` hook (2-3 à¸Šà¸¡.)
- [ ] **Phase 5.3**: Integration testing (1 à¸Šà¸¡.)

### Advanced (Complete Integration)

- [ ] **Phase 6.1**: à¹€à¸à¸´à¹ˆà¸¡ TTS WebSocket endpoint (2-3 à¸Šà¸¡.)
- [ ] **Phase 6.2**: à¸ªà¸£à¹‰à¸²à¸‡ `useWebSocketTTS.ts` hook (2-3 à¸Šà¸¡.)
- [ ] **Phase 6.3**: à¸ªà¸£à¹‰à¸²à¸‡ `useCompleteVoiceChat.ts` (2-3 à¸Šà¸¡.)
- [ ] **Phase 6.4**: Full system integration testing (2 à¸Šà¸¡.)

**Total Estimated Effort: 18-25 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡**

---

## à¸‚à¹‰à¸­à¸„à¸§à¸£à¸£à¸°à¸§à¸±à¸‡

1. **Token Expiration**: ElevenLabs single-use token à¸«à¸¡à¸”à¸­à¸²à¸¢à¸¸à¹ƒà¸™ 15 à¸™à¸²à¸—à¸µ - à¸•à¹‰à¸­à¸‡ refresh
2. **WebSocket Reconnection**: à¸•à¹‰à¸­à¸‡à¸¡à¸µ retry logic à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£ reconnect
3. **Audio Format**: à¸•à¹‰à¸­à¸‡à¹à¸™à¹ˆà¹ƒà¸ˆà¸§à¹ˆà¸²à¹ƒà¸Šà¹‰ PCM 24kHz à¸ªà¸³à¸«à¸£à¸±à¸š Avatar
4. **Chunk Size**: à¸ªà¹ˆà¸‡ audio à¹€à¸›à¹‡à¸™ chunks à¹† à¸¥à¸° 20ms (960 bytes)
5. **Error Handling**: à¸•à¹‰à¸­à¸‡à¸ˆà¸±à¸”à¸à¸²à¸£ error à¸—à¸¸à¸ phase
6. **Rate Limiting**: à¸£à¸°à¸§à¸±à¸‡ API rate limits à¸‚à¸­à¸‡à¸—à¸¸à¸à¸šà¸£à¸´à¸à¸²à¸£
7. **Cost**: à¸£à¸°à¸šà¸šà¸™à¸µà¹‰à¹ƒà¸Šà¹‰ 3 à¸šà¸£à¸´à¸à¸²à¸£à¸à¸£à¹‰à¸­à¸¡à¸à¸±à¸™ - à¸•à¹‰à¸­à¸‡à¸„à¸³à¸™à¸§à¸“ cost

---

## à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡

- [HeyGen LiveAvatar Docs](https://docs.heygen.com/docs/liveavatar)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [ElevenLabs Docs](https://elevenlabs.io/docs)
- [ElevenLabs Realtime STT](https://elevenlabs.io/docs/cookbooks/speech-to-text/streaming)
- [LiveKit Docs](https://docs.livekit.io)
- [WebSocket API (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [Testing Documentation](./TEST_V2V_PROCESS.md)
