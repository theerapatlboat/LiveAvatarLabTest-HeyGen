# Voice-to-Voice Real-time Communication System
**HeyGen LiveAvatar + OpenAI + ElevenLabs Integration**

---

## ğŸ“Š IMPLEMENTATION STATUS SUMMARY

### à¸£à¸°à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¸à¸£à¹‰à¸­à¸¡: **84% à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Production** âœ…âš ï¸

| Phase | Status | Progress | Ready for Production |
|-------|--------|----------|---------------------|
| **Phase 1**: Session Management | âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 100% | âœ… YES |
| **Phase 2**: Voice Chat (FULL) | âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 100% | âœ… YES |
| **Phase 3**: Custom Voice Chat | âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 100% | âœ… YES |
| **Phase 4**: Realtime STT (Full V2V) | âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 100% | âœ… YES |
| **Phase 5**: WebSocket TTS | ğŸš§ à¸à¸³à¸¥à¸±à¸‡à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£ | 60% | âŒ NO (Tasks 1-3/5 à¹€à¸ªà¸£à¹‡à¸ˆ, Tasks 4-5 à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹€à¸ªà¸£à¹‡à¸ˆ) |
| **Phase 6**: WebSocket Chat | âŒ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸£à¸´à¹ˆà¸¡ | 0% | âŒ NO |

### à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ (Production Ready)

âœ… **à¹‚à¸«à¸¡à¸” FULL** - Voice-to-Voice à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¸”à¹‰à¸§à¸¢ HeyGen built-in AI
- Latency: ~1-2 à¸§à¸´à¸™à¸²à¸—à¸µ
- à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¸—à¸±à¸™à¸—à¸µ

âœ… **à¹‚à¸«à¸¡à¸” CUSTOM + REST APIs** - Voice-to-Voice à¹à¸šà¸šà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹„à¸”à¹‰
- Pipeline: User Speech â†’ Whisper STT â†’ OpenAI Chat â†’ ElevenLabs TTS â†’ Avatar
- Latency: ~3-5 à¸§à¸´à¸™à¸²à¸—à¸µ
- à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡ AI à¹à¸¥à¸°à¹€à¸ªà¸µà¸¢à¸‡à¹„à¸”à¹‰à¹€à¸•à¹‡à¸¡à¸—à¸µà¹ˆ

âœ… **à¹‚à¸«à¸¡à¸” CUSTOM + ElevenLabs Realtime STT (Full V2V)** - Voice-to-Voice à¹à¸šà¸š Continuous Streaming
- Pipeline: User Speech â†’ ElevenLabs Realtime STT â†’ OpenAI Chat â†’ ElevenLabs REST TTS â†’ Avatar
- Latency: ~3-5 à¸§à¸´à¸™à¸²à¸—à¸µ (à¹€à¸£à¹‡à¸§à¸à¸§à¹ˆà¸² Whisper à¹à¸•à¹ˆà¸¢à¸±à¸‡à¹ƒà¸Šà¹‰ REST API à¸ªà¸³à¸«à¸£à¸±à¸š TTS)
- **à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹à¸¥à¹‰à¸§ - à¹ƒà¸Šà¹‰ REST TTS API**
- à¸•à¹‰à¸­à¸‡à¸¡à¸µ OpenAI API key à¹à¸¥à¸° ElevenLabs API key

### à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¸•à¹‰à¸­à¸‡à¸à¸±à¸’à¸™à¸² (Need Implementation)

ğŸš§ **Phase 5**: WebSocket TTS (60% - à¸à¸³à¸¥à¸±à¸‡à¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£) - **à¸­à¸±à¸à¹€à¸”à¸• 2025-11-14**
- âœ… **Task 1: Setup Project Structure à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§** (à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ, dependencies, npm script)
- âœ… **Task 2: Implement WebSocket Server à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§** (à¹„à¸Ÿà¸¥à¹Œ `server/websocket-tts-server.ts` - 333 à¸šà¸£à¸£à¸—à¸±à¸”)
  - âœ… **Text chunking à¹à¸šà¹ˆà¸‡à¹€à¸‰à¸à¸²à¸°à¸•à¸²à¸¡ delimiters:** `,` `!` `?` `:` `;` `.`
    - **à¹„à¸¡à¹ˆà¸¡à¸µ maxChunkSize** - à¹à¸šà¹ˆà¸‡ chunk à¹€à¸‰à¸à¸²à¸°à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸ˆà¸­ delimiter à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
    - **à¹„à¸¡à¹ˆà¸ˆà¸³à¸à¸±à¸”à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§** - chunk à¸­à¸²à¸ˆà¸¢à¸²à¸§à¸«à¸£à¸·à¸­à¸ªà¸±à¹‰à¸™à¸•à¸²à¸¡à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡ delimiter
    - à¹à¸•à¹ˆà¸¥à¸° delimiter à¸ªà¸£à¹‰à¸²à¸‡ chunk à¹ƒà¸«à¸¡à¹ˆà¸—à¸±à¸™à¸—à¸µ
  - âœ… ElevenLabs REST API integration
  - âœ… WebSocket message handling (tts, stop, ping)
  - âœ… Comprehensive logging with emojis
  - âœ… Error handling and graceful shutdown
- âœ… **Task 3: React Hook à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§** (à¹„à¸Ÿà¸¥à¹Œ `src/liveavatar/useWebSocketTTS.ts` - 492 à¸šà¸£à¸£à¸—à¸±à¸”)
  - âœ… WebSocket connection management
  - âœ… Web Audio API integration (AudioContext, sequential audio queue)
  - âœ… State management (isConnected, isSynthesizing, progress)
- âŒ **Task 4: Integration à¸à¸±à¸š LiveAvatarSession** (à¹€à¸”à¸´à¸¡ Task 5)
- âŒ **Task 5: Testing & Documentation** (à¹€à¸”à¸´à¸¡ Task 6)

âš ï¸ **Phase 6**: WebSocket Chat (à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸£à¸´à¹ˆà¸¡)
- WebSocket Chat Server à¸ªà¸³à¸«à¸£à¸±à¸š OpenAI
- Conversation history management
- Total Effort: ~5-7 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡

### à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™

**à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸«à¸¡à¸” CUSTOM + ElevenLabs Realtime STT (à¹à¸™à¸°à¸™à¸³):**
```bash
# Start Next.js app
pnpm dev

# à¹€à¸›à¸´à¸” http://localhost:3012
# à¹€à¸¥à¸·à¸­à¸ CUSTOM mode â†’ Start Realtime Voice Chat â†’ à¸à¸¹à¸” â†’ Stop & Process with Avatar
```

**Latency:** ~3-5 à¸§à¸´à¸™à¸²à¸—à¸µ (à¹ƒà¸Šà¹‰ REST API à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸±à¹‰à¸‡ OpenAI Chat à¹à¸¥à¸° ElevenLabs TTS)

**à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸«à¸¡à¸” FULL:**
```bash
pnpm dev
# à¹€à¸›à¸´à¸” http://localhost:3012
# à¹€à¸¥à¸·à¸­à¸ FULL mode â†’ à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¹€à¸¥à¸¢ (HeyGen à¸ˆà¸±à¸”à¸à¸²à¸£à¸—à¸¸à¸à¸­à¸¢à¹ˆà¸²à¸‡)
```

**Latency:** ~1-2 à¸§à¸´à¸™à¸²à¸—à¸µ

---

## à¸ªà¸£à¸¸à¸›à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™

à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„à¸™à¸µà¹‰à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸šà¸ªà¸™à¸—à¸™à¸² Voice-to-Voice à¹à¸šà¸š Real-time à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ HeyGen LiveAvatar à¹€à¸›à¹‡à¸™ Avatar à¸«à¸¥à¸±à¸ à¹‚à¸”à¸¢à¸£à¸­à¸‡à¸£à¸±à¸š 2 à¹‚à¸«à¸¡à¸”:

### à¹‚à¸«à¸¡à¸” FULL âœ… (à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™)
- HeyGen à¸ˆà¸±à¸”à¸à¸²à¸£à¸—à¸¸à¸à¸­à¸¢à¹ˆà¸²à¸‡ (STT, AI, TTS, Lip-sync)
- à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸„à¸§à¸²à¸¡à¸‡à¹ˆà¸²à¸¢à¹à¸¥à¸°à¸£à¸§à¸”à¹€à¸£à¹‡à¸§
- Latency: 1-2 à¸§à¸´à¸™à¸²à¸—à¸µ

### à¹‚à¸«à¸¡à¸” CUSTOM âœ… (à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™)
- à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸„à¸§à¸šà¸„à¸¸à¸¡ AI (OpenAI GPT) à¹à¸¥à¸° TTS (ElevenLabs)
- HeyGen à¸—à¸³à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆà¹à¸„à¹ˆ Video Streaming à¹à¸¥à¸° Lip-sync
- à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸šà¸¸à¸„à¸¥à¸´à¸à¸ à¸²à¸à¹à¸¥à¸°à¹€à¸ªà¸µà¸¢à¸‡à¸‚à¸­à¸‡ Avatar
- Latency: 3-5 à¸§à¸´à¸™à¸²à¸—à¸µ (REST APIs)

### à¹‚à¸«à¸¡à¸” CUSTOM + WebSocket âš ï¸ (à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸à¸£à¹‰à¸­à¸¡ - à¸•à¹‰à¸­à¸‡à¸à¸±à¸’à¸™à¸² Phase 5-6)
- Phase 4 (Realtime STT) à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ âœ…
- Phase 5 (WebSocket TTS) à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹€à¸£à¸´à¹ˆà¸¡ âŒ (à¸¡à¸µà¹€à¸‰à¸à¸²à¸° design doc)
- Phase 6 (WebSocket Chat) à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹€à¸£à¸´à¹ˆà¸¡ âŒ
- à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸ªà¸£à¹‡à¸ˆà¸ˆà¸°à¹ƒà¸Šà¹‰ WebSocket à¹à¸—à¸™ REST APIs
- Target Latency: ~1-2 à¸§à¸´à¸™à¸²à¸—à¸µ (Real-time streaming)
- à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ Custom WebSocket Server à¸ªà¸³à¸«à¸£à¸±à¸š TTS à¹à¸¥à¸° Chat

## à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸«à¸¥à¸±à¸à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰

| à¸šà¸£à¸´à¸à¸²à¸£ | à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ | Implementation Status | à¹€à¸­à¸à¸ªà¸²à¸£ |
|--------|---------|---------------------|---------|
| **HeyGen LiveAvatar** | Video Streaming, Lip-sync Animation | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://api.liveavatar.com |
| **OpenAI Whisper** | Speech-to-Text (CUSTOM mode) | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://platform.openai.com/docs/guides/speech-to-text |
| **OpenAI GPT-4** | AI Conversation (CUSTOM mode) | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://platform.openai.com/docs/guides/chat |
| **ElevenLabs** | Text-to-Speech (CUSTOM mode) | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://elevenlabs.io/docs |
| **ElevenLabs Scribe** | Real-time Speech-to-Text | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ (Phase 4) | https://elevenlabs.io/docs/cookbooks/speech-to-text/streaming |
| **LiveKit** | WebRTC Video Streaming | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://docs.livekit.io |
| **WebSocket** | Real-time Command/Event Communication | âš ï¸ à¹ƒà¸Šà¹‰à¸šà¸²à¸‡à¸ªà¹ˆà¸§à¸™ (HeyGen) | - |

## à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸£à¸±à¸™à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„

### 1. à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ Dependencies

```bash
# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ pnpm (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ)
npm install -g pnpm@9.0.0

# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ dependencies
pnpm install
```

### 2. à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Environment Variables

à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ `.env.local` à¹ƒà¸™ `apps/demo/`:

```env
# HeyGen LiveAvatar (à¸ˆà¸³à¹€à¸›à¹‡à¸™)
LIVEAVATAR_API_KEY=your_heygen_api_key
LIVEAVATAR_AVATAR_ID=dd73ea75-1218-4ef3-92ce-606d5f7fbc0a

# à¸ªà¸³à¸«à¸£à¸±à¸š FULL mode (optional)
LIVEAVATAR_VOICE_ID=your_voice_id
LIVEAVATAR_CONTEXT_ID=your_context_id
LIVEAVATAR_LANGUAGE=en

# à¸ªà¸³à¸«à¸£à¸±à¸š CUSTOM mode (à¸ˆà¸³à¹€à¸›à¹‡à¸™)
OPENAI_API_KEY=your_openai_api_key
ELEVENLABS_API_KEY=your_elevenlabs_api_key
ELEVENLABS_VOICE_ID=pqHfZKP75CvOlQylNhV4
ELEVENLABS_MODEL=eleven_v3
```

### 3. à¸£à¸±à¸™à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„

```bash
# à¸£à¸±à¸™ Demo application
pnpm demo

# à¸«à¸£à¸·à¸­à¸£à¸±à¸™ Development mode
pnpm dev

# Build à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„
pnpm build
```

à¹€à¸›à¸´à¸”à¹€à¸šà¸£à¸²à¸§à¹Œà¹€à¸‹à¸­à¸£à¹Œà¸—à¸µà¹ˆ http://localhost:3000

---

# IMPLEMENTATION FLOW

## PHASE 1: Session Management âœ…

### à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ
à¸ˆà¸±à¸”à¸à¸²à¸£ Session lifecycle à¸‚à¸­à¸‡ HeyGen LiveAvatar (à¸ªà¸£à¹‰à¸²à¸‡, à¸•à¹ˆà¸­à¸­à¸²à¸¢à¸¸, à¸›à¸´à¸” session)

### à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™
- **FULL mode**: HeyGen à¸ˆà¸±à¸”à¸à¸²à¸£ STT, AI, TTS à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
- **CUSTOM mode**: à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸„à¸§à¸šà¸„à¸¸à¸¡ AI à¹à¸¥à¸° TTS à¹€à¸­à¸‡, HeyGen à¸—à¸³ video streaming à¹à¸¥à¸° lip-sync
- **Keep Alive**: à¸•à¹ˆà¸­à¸­à¸²à¸¢à¸¸ session à¸—à¸¸à¸ 5 à¸™à¸²à¸—à¸µ

### Implementation
- APIs: [start-session](../apps/demo/app/api/start-session/route.ts), [start-custom-session](../apps/demo/app/api/start-custom-session/route.ts), [keep-session-alive](../apps/demo/app/api/keep-session-alive/route.ts), [stop-session](../apps/demo/app/api/stop-session/route.ts)
- Hook: [useSession.ts](../apps/demo/src/liveavatar/useSession.ts)

### à¸§à¸´à¸˜à¸µà¸—à¸”à¸ªà¸­à¸š
```bash
pnpm dev
# à¹€à¸›à¸´à¸” http://localhost:3012
# à¹€à¸¥à¸·à¸­à¸ FULL à¸«à¸£à¸·à¸­ CUSTOM mode â†’ session à¹€à¸£à¸´à¹ˆà¸¡à¸—à¸³à¸‡à¸²à¸™à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
```

---

## PHASE 2: Voice Chat (FULL Mode) âœ…

### à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ
Voice Chat à¹à¸šà¸š end-to-end à¸—à¸µà¹ˆ HeyGen à¸ˆà¸±à¸”à¸à¸²à¸£à¸—à¸¸à¸à¸­à¸¢à¹ˆà¸²à¸‡à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´ (STT â†’ AI â†’ TTS â†’ Lip-sync)

### à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™
HeyGen à¸—à¸³à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ all-in-one solution à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ voice chat à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ external APIs

### Implementation
- Hook: [useVoiceChat.ts](../apps/demo/src/liveavatar/useVoiceChat.ts)
- Flow: User Speech â†’ HeyGen Built-in STT â†’ HeyGen AI â†’ HeyGen TTS â†’ Avatar

### à¸§à¸´à¸˜à¸µà¸—à¸”à¸ªà¸­à¸š
```bash
pnpm dev
# à¹€à¸¥à¸·à¸­à¸ FULL mode â†’ à¸à¸” "Start Voice Chat" â†’ à¸à¸¹à¸” â†’ Avatar à¸•à¸­à¸šà¸à¸¥à¸±à¸š
# Latency: ~1-2 à¸§à¸´à¸™à¸²à¸—à¸µ
```

---

## PHASE 3: Custom Voice Chat âœ…

### à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ
Voice Chat à¹à¸šà¸šà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹„à¸”à¹‰à¸”à¹‰à¸§à¸¢ OpenAI (Whisper + GPT-4) à¹à¸¥à¸° ElevenLabs TTS

### à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™
à¹ƒà¸Šà¹‰ REST APIs à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ external services à¸à¸£à¹‰à¸­à¸¡à¸„à¸§à¸šà¸„à¸¸à¸¡ AI model à¹à¸¥à¸° voice à¹„à¸”à¹‰à¹€à¸•à¹‡à¸¡à¸£à¸¹à¸›à¹à¸šà¸š

### Implementation
- Hook: [useCustomVoiceChat.ts](../apps/demo/src/liveavatar/useCustomVoiceChat.ts)
- APIs: [openai-whisper-stt](../apps/demo/app/api/openai-whisper-stt/route.ts), [openai-chat-complete](../apps/demo/app/api/openai-chat-complete/route.ts), [elevenlabs-text-to-speech](../apps/demo/app/api/elevenlabs-text-to-speech/route.ts)
- Flow: User Speech â†’ Whisper STT â†’ OpenAI Chat â†’ ElevenLabs TTS â†’ Avatar

### à¸§à¸´à¸˜à¸µà¸—à¸”à¸ªà¸­à¸š
```bash
# à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² .env.local:
# OPENAI_API_KEY=sk-xxx
# ELEVENLABS_API_KEY=sk_xxx

pnpm dev
# à¹€à¸¥à¸·à¸­à¸ CUSTOM mode â†’ Hold to Talk â†’ à¸à¸¹à¸” â†’ à¸›à¸¥à¹ˆà¸­à¸¢ â†’ Avatar à¸•à¸­à¸š
# Latency: ~3-5 à¸§à¸´à¸™à¸²à¸—à¸µ
```

---

## PHASE 4: ElevenLabs Realtime STT âœ…

### à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ
Real-time Speech-to-Text streaming à¸à¸£à¹‰à¸­à¸¡ Voice-to-Voice flow à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ ElevenLabs Scribe v2

### à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™
- Continuous streaming (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸à¸” Hold to Talk)
- Partial transcripts (real-time feedback) + Final transcripts (VAD-based)
- Combined transcript à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¹ˆà¸‡à¹„à¸›à¸¢à¸±à¸‡ OpenAI Chat

### Implementation
- API: [elevenlabs-stt-token](../apps/demo/app/api/elevenlabs-stt-token/route.ts)
- Hook: [useElevenLabsRealtimeSTT.ts](../apps/demo/src/liveavatar/useElevenLabsRealtimeSTT.ts)
- Component: [LiveAvatarSession.tsx](../apps/demo/src/components/LiveAvatarSession.tsx) (lines 239-285)
- Flow: User Speech â†’ ElevenLabs Scribe (WebSocket) â†’ Combined Transcript â†’ OpenAI Chat â†’ ElevenLabs REST TTS â†’ Avatar

### à¸§à¸´à¸˜à¸µà¸—à¸”à¸ªà¸­à¸š
```bash
# à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² .env.local:
# ELEVENLABS_API_KEY=sk_xxx
# OPENAI_API_KEY=sk-xxx

pnpm dev
# à¹€à¸¥à¸·à¸­à¸ CUSTOM mode â†’ Start Realtime Voice Chat â†’ à¸à¸¹à¸”à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡ â†’ Stop & Process with Avatar
# STT Latency: <500ms, Total V2V Latency: ~3-5 à¸§à¸´à¸™à¸²à¸—à¸µ
```

---

## PHASE 5: WebSocket TTS Integration ğŸš§

**Status:** ğŸš§ **60% à¹€à¸ªà¸£à¹‡à¸ˆ** (Tasks 1-3/5 à¸ªà¸³à¹€à¸£à¹‡à¸ˆ)
**Estimated Remaining Effort:** ~2-3 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡ (Tasks 4-5)

### ğŸ“‹ à¸ªà¸–à¸²à¸™à¸°à¸à¸²à¸£ Implement

**à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ âœ…:**
- âœ… **Task 1**: Project structure, dependencies (ws@8.18.3, @types/ws@8.18.1, tsx@4.20.6), npm script
- âœ… **Task 2**: WebSocket Server [websocket-tts-server.ts](../apps/demo/server/websocket-tts-server.ts) - 333 lines
  - **Text chunking à¹à¸šà¹ˆà¸‡à¹€à¸‰à¸à¸²à¸°à¸•à¸²à¸¡ delimiters:** `,` `!` `?` `:` `;` `.` (à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¸™à¸²à¸” limit)
  - ElevenLabs REST API integration
  - Message handling (tts, stop, ping)
  - Comprehensive logging
- âœ… **Task 3**: React Hook [useWebSocketTTS.ts](../apps/demo/src/liveavatar/useWebSocketTTS.ts) - 492 lines
  - WebSocket connection management
  - Audio queue & sequential playback
  - Progress tracking

**à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¸•à¹‰à¸­à¸‡à¸—à¸³ âŒ:**
- âŒ **Task 4**: Integration à¸à¸±à¸š LiveAvatarSession (~1.5-2 hours)
- âŒ **Task 5**: Testing & Documentation (~1-1.5 hours)

### à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™

**WebSocket Middleware Pattern:**
```
Client â†” WebSocket â†” Custom Server â†” ElevenLabs REST API
```

**à¹€à¸«à¸•à¸¸à¸œà¸¥:** eleven_v3 à¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š native WebSocket streaming

**Solution:**
- Server à¹à¸šà¹ˆà¸‡ text à¹€à¸›à¹‡à¸™ chunks **à¹€à¸‰à¸à¸²à¸°à¸•à¸²à¸¡ delimiters:** `,` `!` `?` `:` `;` `.` (à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¸™à¸²à¸” limit)
- à¹€à¸£à¸µà¸¢à¸ ElevenLabs REST API à¹à¸•à¹ˆà¸¥à¸° chunk à¹à¸¢à¸à¸à¸±à¸™
- Stream audio chunks à¸à¸¥à¸±à¸š client à¸œà¹ˆà¸²à¸™ WebSocket
- Client à¹€à¸¥à¹ˆà¸™ audio à¹à¸šà¸š sequential queue

**à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œ:**
- à¹ƒà¸Šà¹‰ eleven_v3 à¹„à¸”à¹‰ (à¸„à¸¸à¸“à¸ à¸²à¸à¸ªà¸¹à¸‡à¸ªà¸¸à¸”)
- Progressive playback (à¹€à¸¥à¹ˆà¸™à¹„à¸”à¹‰à¸—à¸±à¸™à¸—à¸µà¸—à¸µà¹ˆà¹„à¸”à¹‰ chunk à¹à¸£à¸)
- à¸¥à¸” latency à¸ˆà¸²à¸ ~3-5s â†’ ~1.5-2.5s (40-50% à¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™)
- à¸£à¸­à¸‡à¸£à¸±à¸šà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§

### Implementation Details

**Text Chunking (Task 2 - à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§):**
- **à¹à¸šà¹ˆà¸‡ chunk à¹€à¸‰à¸à¸²à¸°à¸•à¸²à¸¡ delimiters:** `,` `!` `?` `:` `;` `.`
- **à¹„à¸¡à¹ˆà¸¡à¸µ maxChunkSize** - à¹à¸šà¹ˆà¸‡à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸ˆà¸­ delimiter à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
- **à¹„à¸¡à¹ˆà¸ˆà¸³à¸à¸±à¸”à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§ chunk** - à¸‚à¸¶à¹‰à¸™à¸à¸±à¸šà¸•à¸³à¹à¸«à¸™à¹ˆà¸‡ delimiter à¹ƒà¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡
- à¹à¸•à¹ˆà¸¥à¸° delimiter à¸ªà¸£à¹‰à¸²à¸‡ chunk à¹ƒà¸«à¸¡à¹ˆà¸—à¸±à¸™à¸—à¸µ (natural speech breaks)
- à¸”à¸¹ [websocket-tts-server.ts:85-145](../apps/demo/server/websocket-tts-server.ts)

**Sequential Audio Playback (Task 3 - à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§):**
1. à¸£à¸±à¸š audio chunk à¸ˆà¸²à¸ WebSocket
2. à¹ƒà¸ªà¹ˆà¹€à¸‚à¹‰à¸² queue
3. Decode à¹€à¸›à¹‡à¸™ AudioBuffer
4. à¹€à¸¥à¹ˆà¸™à¹à¸šà¸š sequential (auto-play next chunk)
- à¸”à¸¹ [useWebSocketTTS.ts](../apps/demo/src/liveavatar/useWebSocketTTS.ts)

### à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸£à¸±à¸™ WebSocket Server

```bash
# Terminal 1: Start WebSocket TTS server
cd apps/demo
pnpm ws-tts

# Terminal 2: Start Next.js app
pnpm dev
```

**WebSocket Server Details:**
- Port: 3013
- Path: `/ws/elevenlabs-tts`
- à¸”à¸¹ [websocket-tts-server.ts](../apps/demo/server/websocket-tts-server.ts)

**API Message Formats:**
```json
// Request
{
  "type": "tts",
  "text": "à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹à¸›à¸¥à¸‡",
  "voice_id": "21m00Tcm4TlvDq8ikWAM",
  "model_id": "eleven_v3"
}

// Response
{
  "type": "audio_chunk",
  "chunk_index": 0,
  "total_chunks": 5,
  "audio_data": "base64_encoded_pcm...",
  "format": "pcm_24000"
}
```

### à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ React Hook

```typescript
import { useWebSocketTTS } from '@/liveavatar/useWebSocketTTS';

const { isConnected, isSynthesizing, progress, connect, synthesize } = useWebSocketTTS({
  voiceId: '21m00Tcm4TlvDq8ikWAM',
  modelId: 'eleven_v3',
  onComplete: (total) => console.log(`Completed ${total} chunks`)
});

// Connect on mount
useEffect(() => {
  connect();
  return () => disconnect();
}, []);

// Synthesize text
synthesize('à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸¢à¸´à¸™à¸”à¸µà¸•à¹‰à¸­à¸™à¸£à¸±à¸š');
```

à¸”à¸¹à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡à¹ƒà¸™ [useWebSocketTTS.ts](../apps/demo/src/liveavatar/useWebSocketTTS.ts)

### Integration à¸à¸±à¸š Voice-to-Voice Flow (à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸—à¸³)

**à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸£à¹ˆà¸§à¸¡à¸à¸±à¸š Phase 4 à¸—à¸µà¹ˆà¸§à¸²à¸‡à¹à¸œà¸™à¹„à¸§à¹‰:**

```typescript
// In LiveAvatarSession.tsx
import { useElevenLabsRealtimeSTT } from '../liveavatar/useElevenLabsRealtimeSTT';
import { useWebSocketTTS } from '../liveavatar/useWebSocketTTS';

const MyComponent = () => {
  // Phase 4: Realtime STT
  const {
    isConnected: isSTTConnected,
    finalText,
    connect: connectSTT,
    disconnect: disconnectSTT,
    getCombinedTranscript
  } = useElevenLabsRealtimeSTT({
    languageCode: 'th',
    onFinalTranscript: async (text) => {
      console.log('âœ… Final transcript:', text);
    }
  });

  // Phase 5: WebSocket TTS
  const {
    isConnected: isTTSConnected,
    isSynthesizing,
    progress,
    connect: connectTTS,
    synthesize
  } = useWebSocketTTS({
    voiceId: '21m00Tcm4TlvDq8ikWAM',
    modelId: 'eleven_v3',
    onComplete: (totalChunks) => {
      console.log(`âœ… TTS completed with ${totalChunks} chunks`);
    }
  });

  // Complete Voice-to-Voice Flow
  const handleVoiceToVoice = useCallback(async () => {
    try {
      // 1. Get combined transcript from STT
      const userInput = getCombinedTranscript();
      console.log('ğŸ“ User said:', userInput);

      // 2. Send to OpenAI Chat
      const chatRes = await fetch('/api/openai-chat-complete', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ message: userInput })
      });
      const { response: aiResponse } = await chatRes.json();
      console.log('ğŸ¤– AI Response:', aiResponse);

      // 3. Convert to speech using WebSocket TTS
      synthesize(aiResponse);
      console.log('ğŸ”Š TTS started');

      // Audio will play automatically via queue-based playback

    } catch (error) {
      console.error('âŒ V2V Error:', error);
    }
  }, [getCombinedTranscript, synthesize]);

  // UI
  return (
    <div>
      {/* STT Controls */}
      <button onClick={isSTTConnected ? disconnectSTT : connectSTT}>
        {isSTTConnected ? 'Stop Voice Chat' : 'Start Voice Chat'}
      </button>

      {/* Complete V2V Flow */}
      <button
        onClick={handleVoiceToVoice}
        disabled={isSynthesizing}
      >
        Stop & Process with Avatar
      </button>

      {/* TTS Progress */}
      {isSynthesizing && (
        <div>
          Speaking: {progress.current}/{progress.total} chunks
        </div>
      )}
    </div>
  );
};
```

**Complete Flow:**
```
User Speaks
    â†“
[Phase 4] ElevenLabs Realtime STT (streaming)
    â†“
Combined Transcript
    â†“
[Phase 6] OpenAI Chat API (REST)
    â†“
AI Response Text
    â†“
[Phase 5] WebSocket TTS (chunked streaming)
    â†“
Audio Playback (sequential)
    â†“
Avatar Lip-sync
```

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Speaks       â”‚ (continuous)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ElevenLabs Realtime â”‚ (Phase 4)
â”‚ STT (Scribe v2)     â”‚ ws://api.elevenlabs.io/...
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ (transcript streaming)
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ getCombinedTranscript()
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI Chat API     â”‚ (Phase 6 - REST)
â”‚ (GPT-4)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ (AI response)
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Custom WS Server    â”‚ ws://localhost:3013/ws/elevenlabs-tts
â”‚ (Port 3013)         â”‚
â”‚ - Text Chunking     â”‚ delimiters: , ! ? space
â”‚ - REST API Calls    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ (per chunk)
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ElevenLabs REST API â”‚ (Phase 5)
â”‚ (eleven_v3)         â”‚ POST /v1/text-to-speech/{voice_id}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ (audio base64)
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WebSocket           â”‚
â”‚ (to client)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ (audio chunks)
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Web Audio API       â”‚
â”‚ Queue Playback      â”‚ sequential streaming
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HeyGen Avatar       â”‚
â”‚ (Lip-sync)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance & Latency

**Phase 3 (REST TTS):**
- Total latency: 3-5 à¸§à¸´à¸™à¸²à¸—à¸µ
- à¸•à¹‰à¸­à¸‡à¸£à¸­à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”

**Phase 5 (WebSocket TTS Middleware):**
- First chunk latency: ~1-2 à¸§à¸´à¸™à¸²à¸—à¸µ
- Subsequent chunks: streaming (<500ms)
- Total perceived latency: ~1.5-2.5 à¸§à¸´à¸™à¸²à¸—à¸µ
- âœ… à¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™ 40-50%

### à¸‚à¹‰à¸­à¸”à¸µ (Advantages)

1. âœ… **à¹ƒà¸Šà¹‰ eleven_v3 à¹„à¸”à¹‰** - à¸„à¸¸à¸“à¸ à¸²à¸à¹€à¸ªà¸µà¸¢à¸‡à¸ªà¸¹à¸‡à¸ªà¸¸à¸” à¹à¸¡à¹‰à¹„à¸¡à¹ˆà¸¡à¸µ native WebSocket
2. âœ… **Progressive Playback** - à¹€à¸¥à¹ˆà¸™à¹€à¸ªà¸µà¸¢à¸‡à¹„à¸”à¹‰à¸—à¸±à¸™à¸—à¸µà¸—à¸µà¹ˆà¹„à¸”à¹‰ chunk à¹à¸£à¸
3. âœ… **Natural Speech** - Text chunking à¸ªà¸£à¹‰à¸²à¸‡ natural pauses
4. âœ… **à¸£à¸­à¸‡à¸£à¸±à¸šà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§** - à¹à¸šà¹ˆà¸‡à¹€à¸›à¹‡à¸™ chunks à¹à¸¥à¹‰à¸§à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥
5. âœ… **Detailed Logging** - à¸•à¸´à¸”à¸•à¸²à¸¡à¸—à¸¸à¸ operation
6. âœ… **Easy Integration** - React Hook à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰

### à¸‚à¹‰à¸­à¸ˆà¸³à¸à¸±à¸” (Limitations)

1. âš ï¸ **à¸•à¹‰à¸­à¸‡à¸£à¸±à¸™ Custom Server** - à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰ Next.js App Router à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸”à¸µà¸¢à¸§
2. âš ï¸ **à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ True Streaming** - à¹€à¸›à¹‡à¸™ chunked REST API calls
3. âš ï¸ **Latency à¸ªà¸¹à¸‡à¸à¸§à¹ˆà¸² native WebSocket** - à¹à¸•à¹ˆà¸”à¸µà¸à¸§à¹ˆà¸² REST API à¸˜à¸£à¸£à¸¡à¸”à¸²

### à¸—à¸²à¸‡à¹€à¸¥à¸·à¸­à¸à¸­à¸·à¹ˆà¸™ (Alternatives)

à¸«à¸²à¸à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ **true real-time streaming** à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰:

#### **Option A: eleven_turbo_v2_5** (à¹à¸™à¸°à¸™à¸³à¸ªà¸³à¸«à¸£à¸±à¸š production)
- âœ… Native WebSocket streaming support
- âœ… Lower latency (<1 à¸§à¸´à¸™à¸²à¸—à¸µ)
- âš ï¸ à¸„à¸¸à¸“à¸ à¸²à¸à¹€à¸ªà¸µà¸¢à¸‡à¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² eleven_v3 à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢

**WebSocket Endpoint:**
```
wss://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream-input?model_id=eleven_turbo_v2_5
```

#### **Option B: eleven_flash_v2_5** (à¹€à¸£à¹‡à¸§à¸—à¸µà¹ˆà¸ªà¸¸à¸”)
- âœ… Native WebSocket streaming support
- âœ… Fastest response
- âš ï¸ à¸„à¸¸à¸“à¸ à¸²à¸à¹€à¸ªà¸µà¸¢à¸‡à¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² turbo

**WebSocket Endpoint:**
```
wss://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream-input?model_id=eleven_flash_v2_5
```

### à¸„à¸³à¹à¸™à¸°à¸™à¸³à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

| Use Case | Recommended Solution | à¹€à¸«à¸•à¸¸à¸œà¸¥ |
|----------|---------------------|--------|
| à¸„à¸¸à¸“à¸ à¸²à¸à¹€à¸ªà¸µà¸¢à¸‡à¸ªà¸³à¸„à¸±à¸à¸ªà¸¸à¸” | Phase 5 (eleven_v3 + middleware) | à¸„à¸¸à¸“à¸ à¸²à¸à¸ªà¸¹à¸‡à¸ªà¸¸à¸” |
| Real-time Voice Chat | eleven_turbo_v2_5 (native WS) | à¸ªà¸¡à¸”à¸¸à¸¥à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸„à¸¸à¸“à¸ à¸²à¸à¹à¸¥à¸° latency |
| Ultra-low Latency | eleven_flash_v2_5 (native WS) | à¹€à¸£à¹‡à¸§à¸—à¸µà¹ˆà¸ªà¸¸à¸” |
| Production V2V | Phase 5 à¸«à¸£à¸·à¸­ turbo_v2_5 | à¸‚à¸¶à¹‰à¸™à¸­à¸¢à¸¹à¹ˆà¸à¸±à¸šà¸„à¸§à¸²à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ |

### Testing & Debugging

**1. à¸—à¸”à¸ªà¸­à¸š WebSocket Server:**
```bash
# Terminal 1: Start WebSocket server
pnpm ws-tts

# Terminal 2: Start Next.js app
pnpm dev

# à¹€à¸›à¸´à¸”à¹€à¸šà¸£à¸²à¸§à¹Œà¹€à¸‹à¸­à¸£à¹Œ: http://localhost:3012
# à¸—à¸”à¸ªà¸­à¸š V2V flow à¸”à¹‰à¸§à¸¢ CUSTOM mode
```

**2. Debug Logs:**
```
ğŸ”ª [CHUNKING] - Text chunking operations
ğŸ“ [TTS] - ElevenLabs API calls
ğŸ“¦ [TTS] - Chunk processing
âœ… [TTS] - Success messages
âŒ [TTS] - Error messages
ğŸ”Š [WS TTS] - Audio playback
```

**3. Common Issues:**

**Issue:** WebSocket connection failed
```
âŒ Error: connect ECONNREFUSED 127.0.0.1:3013
```
**Solution:** à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸£à¸±à¸™ `pnpm ws-tts` à¹à¸¥à¹‰à¸§

**Issue:** No audio playback
```
âŒ Audio decode error: EncodingError
```
**Solution:** à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š audio format (à¸•à¹‰à¸­à¸‡à¹€à¸›à¹‡à¸™ PCM_24000)

**Issue:** Chunks playing out of order
**Solution:** à¹ƒà¸Šà¹‰ queue-based sequential playback (à¸”à¸¹ code à¸”à¹‰à¸²à¸™à¸šà¸™)

### à¸ªà¸–à¸²à¸™à¸°à¸à¸²à¸£à¸à¸±à¸’à¸™à¸²

âœ… **Tasks à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ (60%):**
- Task 1: Project structure setup
- Task 2: WebSocket server implementation (à¸£à¸­à¸‡à¸£à¸±à¸š delimiters à¸„à¸£à¸š: `,` `!` `?` `:` `;` `.`)
- Task 3: React hook implementation

âŒ **Tasks à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¸•à¹‰à¸­à¸‡à¸—à¸³ (40%):**
- Task 4: Integration à¸à¸±à¸š LiveAvatarSession (~1.5-2 hours)
- Task 5: Testing & Documentation (~1-1.5 hours)

**Status:** ğŸš§ Not production ready - à¸•à¹‰à¸­à¸‡ complete Tasks 4-5

### ğŸ“‹ Tasks à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¸•à¹‰à¸­à¸‡à¸—à¸³ (4-5)

#### **Task 4: Integration with Voice-to-Voice Flow** âŒ (Estimated: 1.5-2 hours)

**Goal:** à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ WebSocket TTS à¹€à¸‚à¹‰à¸²à¸à¸±à¸š V2V flow à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ LiveAvatarSession component à¹€à¸à¸·à¹ˆà¸­à¹à¸—à¸™à¸—à¸µà¹ˆ REST API TTS à¸”à¹‰à¸§à¸¢ WebSocket TTS à¹à¸šà¸š progressive playback

---

**Step 4.1: Import à¹à¸¥à¸° Setup WebSocket TTS Hook** (15-20 à¸™à¸²à¸—à¸µ)

**à¹„à¸Ÿà¸¥à¹Œ:** `apps/demo/src/components/LiveAvatarSession.tsx`

**4.1.1: à¹€à¸à¸´à¹ˆà¸¡ Import Statement**
```typescript
// à¹€à¸à¸´à¹ˆà¸¡à¹ƒà¸™ imports section (à¸šà¸£à¸£à¸—à¸±à¸” 1-13)
import { useWebSocketTTS } from "../liveavatar/useWebSocketTTS";
```

**4.1.2: Initialize useWebSocketTTS Hook**
```typescript
// à¹€à¸à¸´à¹ˆà¸¡à¸«à¸¥à¸±à¸‡ useElevenLabsRealtimeSTT hook (à¸«à¸¥à¸±à¸‡à¸šà¸£à¸£à¸—à¸±à¸” 104)
const {
  isConnected: isWSTTSConnected,
  isSynthesizing: isWSTTSSynthesizing,
  progress: wsTTSProgress,
  connect: connectWSTTS,
  disconnect: disconnectWSTTS,
  synthesize: synthesizeWSTTS,
} = useWebSocketTTS({
  wsUrl: 'ws://localhost:3013/ws/elevenlabs-tts',
  voiceId: 'moBQ5vcoHD68Es6NqdGR', // George (English) - à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹„à¸”à¹‰à¸•à¸²à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£
  modelId: 'eleven_v3',
  autoConnect: false, // à¸ˆà¸° connect manual à¹ƒà¸™ useEffect
  onAudioChunk: (chunkIndex, totalChunks, text) => {
    console.log(`ğŸ”Š [WS-TTS] Chunk ${chunkIndex + 1}/${totalChunks}: "${text}"`);
  },
  onComplete: (totalChunks) => {
    console.log(`âœ… [WS-TTS] Completed - Total ${totalChunks} chunks`);
  },
  onError: (error) => {
    console.error('âŒ [WS-TTS] Error:', error);
  },
  onConnectionChange: (connected) => {
    console.log(`ğŸ”Œ [WS-TTS] Connection status: ${connected ? 'connected' : 'disconnected'}`);
  }
});
```

**4.1.3: à¹€à¸à¸´à¹ˆà¸¡ useEffect à¸ªà¸³à¸«à¸£à¸±à¸š Auto-Connect/Disconnect**
```typescript
// à¹€à¸à¸´à¹ˆà¸¡à¸«à¸¥à¸±à¸‡ useEffect à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆ (à¸«à¸¥à¸±à¸‡à¸šà¸£à¸£à¸—à¸±à¸” 171)
useEffect(() => {
  // Auto-connect to WebSocket TTS when component mounts (CUSTOM mode only)
  if (mode === 'CUSTOM') {
    console.log('ğŸ”Œ [WS-TTS] Connecting to WebSocket TTS server...');
    connectWSTTS();
  }

  // Cleanup: disconnect when component unmounts
  return () => {
    if (mode === 'CUSTOM') {
      console.log('ğŸ”Œ [WS-TTS] Disconnecting from WebSocket TTS server...');
      disconnectWSTTS();
    }
  };
}, [mode, connectWSTTS, disconnectWSTTS]);
```

---

**Step 4.2: à¹à¸à¹‰à¹„à¸‚ handleVoiceToVoice() à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸Šà¹‰ Progressive Lip-sync à¸à¸±à¸š Avatar** (1-1.5 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)

**à¹„à¸Ÿà¸¥à¹Œ:** `apps/demo/src/components/LiveAvatarSession.tsx`

**ğŸ¯ à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢:** à¸ªà¹ˆà¸‡ audio chunks à¹„à¸›à¸¢à¸±à¸‡ HeyGen Avatar `repeatAudio()` à¹à¸šà¸š Progressive (à¸—à¸µà¸¥à¸° chunk) à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰ Avatar lip-sync à¹à¸šà¸š real-time à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸­à¹ƒà¸«à¹‰ synthesis à¹€à¸ªà¸£à¹‡à¸ˆà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”

---

**ğŸ“‹ à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™ (Progressive Lip-sync Flow):**

```
WebSocket TTS Server â†’ Audio Chunks â†’ Queue â†’ Sequential Processing â†’ Avatar Lip-sync

Step 1: User Speech â†’ OpenAI Chat â†’ AI Response
Step 2: Send AI Response â†’ WebSocket TTS â†’ Text Chunking (delimiter-based)
Step 3: Each Chunk â†’ ElevenLabs TTS â†’ Audio Chunk (base64 MP3)
Step 4: Receive Chunk â†’ Add to Queue â†’ Process Immediately
Step 5: Send to repeatAudio() â†’ Wait for Duration â†’ Next Chunk
Step 6: Repeat until all chunks complete â†’ Avatar finishes speaking
```

**ğŸ”‘ Key Concepts:**

1. **Non-blocking Synthesis:** WebSocket TTS à¸ªà¹ˆà¸‡ chunks à¸¡à¸²à¸—à¸µà¸¥à¸°à¸ªà¹ˆà¸§à¸™ (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸­à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”)
2. **Sequential Queue:** Chunks à¸–à¸¹à¸à¹€à¸à¹‡à¸šà¹ƒà¸™ queue à¹à¸¥à¸°à¹€à¸¥à¹ˆà¸™à¸•à¸²à¸¡à¸¥à¸³à¸”à¸±à¸š
3. **Progressive Playback:** Chunk à¹à¸£à¸à¹€à¸£à¸´à¹ˆà¸¡à¹€à¸¥à¹ˆà¸™à¸—à¸±à¸™à¸—à¸µà¸—à¸µà¹ˆà¹„à¸”à¹‰à¸£à¸±à¸š (à¸¥à¸” latency ~40-50%)
4. **Event-based Timing:** à¹ƒà¸Šà¹‰ `AVATAR_SPEAK_ENDED` event à¹€à¸à¸·à¹ˆà¸­à¸£à¸±à¸šà¸ªà¸±à¸à¸à¸²à¸“à¹€à¸¡à¸·à¹ˆà¸­ Avatar à¸à¸¹à¸”à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸•à¹ˆà¸¥à¸° chunk

---

**ğŸ”§ Implementation à¹à¸šà¸šà¸¥à¸°à¹€à¸­à¸µà¸¢à¸”:**

**Step 4.2.1: à¹€à¸à¸´à¹ˆà¸¡ Helper Function à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸™à¸§à¸“ Audio Duration** (5-10 à¸™à¸²à¸—à¸µ)

**à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡:** à¹€à¸à¸´à¹ˆà¸¡à¸à¹ˆà¸­à¸™à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ `LiveAvatarSessionComponent` (à¸šà¸£à¸£à¸—à¸±à¸” ~40)

```typescript
/**
 * à¸„à¸³à¸™à¸§à¸“ duration à¸‚à¸­à¸‡ audio data (base64 MP3)
 * à¹ƒà¸Šà¹‰à¸ªà¸³à¸«à¸£à¸±à¸š wait time à¹ƒà¸™à¸à¸²à¸£à¹€à¸¥à¹ˆà¸™ chunk à¹à¸šà¸š sequential
 *
 * @param base64Audio - base64 encoded audio (mp3_44100_128 format)
 * @returns duration in seconds (approximate)
 */
async function getAudioDuration(base64Audio: string): Promise<number> {
  try {
    // Step 1: Decode base64 to ArrayBuffer
    const binaryString = atob(base64Audio);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    const audioBuffer = bytes.buffer;

    // Step 2: Create audio context and decode
    const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
    const decodedBuffer = await audioContext.decodeAudioData(audioBuffer);

    // Step 3: Get duration from decoded buffer
    const duration = decodedBuffer.duration;
    console.log(`â±ï¸ [Audio Duration] Calculated: ${duration.toFixed(2)}s`);

    // Step 4: Close audio context to prevent memory leaks
    await audioContext.close();

    return duration;
  } catch (error) {
    console.error('âŒ [Audio Duration] Error calculating duration:', error);

    // Fallback: estimate based on file size
    // MP3 128kbps â‰ˆ 16KB/s, base64 encoding adds ~33% overhead
    const estimatedDuration = (base64Audio.length * 0.75) / (16 * 1024);
    console.warn(`âš ï¸ [Audio Duration] Using estimated duration: ${estimatedDuration.toFixed(2)}s`);

    return estimatedDuration;
  }
}
```

**à¹€à¸«à¸•à¸¸à¸œà¸¥:**
- à¸•à¹‰à¸­à¸‡à¸£à¸¹à¹‰ duration à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸° chunk à¹€à¸à¸·à¹ˆà¸­à¸£à¸­à¹ƒà¸«à¹‰à¹€à¸¥à¹ˆà¸™à¹€à¸ªà¸£à¹‡à¸ˆà¸à¹ˆà¸­à¸™à¸ªà¹ˆà¸‡ chunk à¸–à¸±à¸”à¹„à¸›
- à¹ƒà¸Šà¹‰ Web Audio API `decodeAudioData()` à¹€à¸à¸·à¹ˆà¸­à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³
- à¸¡à¸µ fallback calculation à¸–à¹‰à¸² decode à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ

---

**Step 4.2.2: à¹€à¸à¸´à¹ˆà¸¡ State à¹à¸¥à¸° Refs à¸ªà¸³à¸«à¸£à¸±à¸š Progressive Lip-sync** (5-10 à¸™à¸²à¸—à¸µ)

**à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡:** à¹ƒà¸™ `LiveAvatarSessionComponent` component (à¸«à¸¥à¸±à¸‡à¸šà¸£à¸£à¸—à¸±à¸” 80)

```typescript
// à¹€à¸à¸´à¹ˆà¸¡à¸«à¸¥à¸±à¸‡: const { sessionRef } = useLiveAvatarContext();

// State à¸ªà¸³à¸«à¸£à¸±à¸š Progressive Lip-sync
const audioChunksQueueRef = useRef<Array<{ audio: string; text: string }>>([]);
const isProcessingChunkRef = useRef(false);
```

**à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢:**
- `audioChunksQueueRef`: à¹€à¸à¹‡à¸š queue à¸‚à¸­à¸‡ audio chunks à¸—à¸µà¹ˆà¸£à¸­à¸ªà¹ˆà¸‡à¹„à¸›à¸¢à¸±à¸‡ Avatar
- `isProcessingChunkRef`: flag à¸›à¹‰à¸­à¸‡à¸à¸±à¸™à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ chunk à¸«à¸¥à¸²à¸¢à¸•à¸±à¸§à¸à¸£à¹‰à¸­à¸¡à¸à¸±à¸™

---

**Step 4.2.3: à¸ªà¸£à¹‰à¸²à¸‡à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ processNextAudioChunk()** (15-20 à¸™à¸²à¸—à¸µ)

**à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡:** à¹€à¸à¸´à¹ˆà¸¡à¸«à¸¥à¸±à¸‡ `handleVoiceToVoice` function (à¸šà¸£à¸£à¸—à¸±à¸” ~152)

```typescript
/**
 * à¸ªà¹ˆà¸‡ audio chunk à¹„à¸›à¸¢à¸±à¸‡ Avatar à¹à¸šà¸š sequential
 * à¸—à¸³à¸‡à¸²à¸™à¹à¸šà¸š recursive: process chunk â†’ wait â†’ process next chunk
 */
const processNextAudioChunk = useCallback(async () => {
  // Step 1: Check if already processing
  if (isProcessingChunkRef.current) {
    console.log('â¸ï¸ [Avatar] Already processing a chunk, waiting...');
    return;
  }

  // Step 2: Check if queue is empty
  if (audioChunksQueueRef.current.length === 0) {
    console.log('âœ… [Avatar] All audio chunks processed');
    isProcessingChunkRef.current = false;
    return;
  }

  // Step 3: Mark as processing
  isProcessingChunkRef.current = true;

  // Step 4: Get next chunk from queue
  const chunk = audioChunksQueueRef.current.shift();
  if (!chunk || !sessionRef.current) {
    console.warn('âš ï¸ [Avatar] No chunk or session not available');
    isProcessingChunkRef.current = false;
    return;
  }

  try {
    const { audio, text } = chunk;
    console.log(`ğŸ‘„ [Avatar] Processing chunk: "${text.substring(0, 30)}${text.length > 30 ? '...' : ''}"`);

    // Step 5: Calculate audio duration
    const duration = await getAudioDuration(audio);
    console.log(`â±ï¸ [Avatar] Chunk duration: ${duration.toFixed(2)}s`);

    // Step 6: Send to Avatar for lip-sync
    sessionRef.current.repeatAudio(audio);
    console.log('âœ… [Avatar] Chunk sent to Avatar, lip-sync started');

    // Step 7: Wait for duration + buffer (50ms safety margin)
    const waitTime = (duration + 0.05) * 1000; // Convert to ms
    console.log(`â¸ï¸ [Avatar] Waiting ${(waitTime / 1000).toFixed(2)}s for chunk to finish...`);

    await new Promise(resolve => setTimeout(resolve, waitTime));
    console.log('âœ… [Avatar] Chunk playback finished');

    // Step 8: Mark as not processing
    isProcessingChunkRef.current = false;

    // Step 9: Process next chunk (recursive call)
    if (audioChunksQueueRef.current.length > 0) {
      console.log(`ğŸ“¦ [Avatar] ${audioChunksQueueRef.current.length} chunks remaining in queue`);
      processNextAudioChunk();
    } else {
      console.log('ğŸ‰ [Avatar] All chunks processed successfully!');
    }

  } catch (error) {
    console.error('âŒ [Avatar] Error processing chunk:', error);
    isProcessingChunkRef.current = false;

    // Continue with next chunk even if this one failed
    if (audioChunksQueueRef.current.length > 0) {
      console.log('âš ï¸ [Avatar] Continuing with next chunk despite error...');
      processNextAudioChunk();
    }
  }
}, [sessionRef]);
```

**à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™:**
1. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸à¸³à¸¥à¸±à¸‡ process chunk à¸­à¸¢à¸¹à¹ˆà¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
2. à¸”à¸¶à¸‡ chunk à¸ˆà¸²à¸ queue
3. à¸„à¸³à¸™à¸§à¸“ duration à¸‚à¸­à¸‡ audio
4. à¸ªà¹ˆà¸‡à¹„à¸›à¸¢à¸±à¸‡ `repeatAudio()` (Avatar à¹€à¸£à¸´à¹ˆà¸¡ lip-sync)
5. à¸£à¸­à¸•à¸²à¸¡ duration + buffer 50ms
6. à¹€à¸£à¸µà¸¢à¸ `processNextAudioChunk()` à¸­à¸µà¸à¸„à¸£à¸±à¹‰à¸‡ (recursive)

---

**Step 4.2.4: à¹à¸à¹‰à¹„à¸‚ useWebSocketTTS Config à¹€à¸à¸·à¹ˆà¸­à¸£à¸±à¸š audio_data** (10-15 à¸™à¸²à¸—à¸µ)

**à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡:** à¹à¸à¹‰à¹„à¸‚ `useWebSocketTTS` config (à¸šà¸£à¸£à¸—à¸±à¸” ~104)

**à¹‚à¸„à¹‰à¸”à¹€à¸”à¸´à¸¡:**
```typescript
const {
  // ... existing code
} = useWebSocketTTS({
  wsUrl: 'ws://localhost:3013/ws/elevenlabs-tts',
  voiceId: 'moBQ5vcoHD68Es6NqdGR',
  modelId: 'eleven_v3',
  autoConnect: false,
  onAudioChunk: (chunkIndex, totalChunks, text) => {
    console.log(`ğŸ”Š [WS-TTS] Chunk ${chunkIndex + 1}/${totalChunks}: "${text}"`);
  },
  // ... rest
});
```

**à¹‚à¸„à¹‰à¸”à¹ƒà¸«à¸¡à¹ˆ:**
```typescript
const {
  isConnected: isWSTTSConnected,
  isSynthesizing: isWSTTSSynthesizing,
  progress: wsTTSProgress,
  connect: connectWSTTS,
  disconnect: disconnectWSTTS,
  synthesize: synthesizeWSTTS,
} = useWebSocketTTS({
  wsUrl: 'ws://localhost:3013/ws/elevenlabs-tts',
  voiceId: 'moBQ5vcoHD68Es6NqdGR', // George (English)
  modelId: 'eleven_v3',
  autoConnect: false,

  // ğŸ†• Handle audio chunks for progressive lip-sync
  onAudioChunk: (chunkIndex, totalChunks, text, audioData) => {
    console.log(`ğŸ“¦ [WS-TTS] Received chunk ${chunkIndex + 1}/${totalChunks}: "${text.substring(0, 30)}..."`);

    // Add chunk to queue
    audioChunksQueueRef.current.push({
      audio: audioData, // base64 audio data
      text: text
    });

    // Start processing if this is the first chunk
    if (chunkIndex === 0 && !isProcessingChunkRef.current) {
      console.log('ğŸ¬ [WS-TTS] Starting progressive lip-sync with first chunk');
      processNextAudioChunk();
    }
  },

  onComplete: (totalChunks) => {
    console.log(`âœ… [WS-TTS] Synthesis completed - Total ${totalChunks} chunks`);
  },

  onError: (error) => {
    console.error('âŒ [WS-TTS] Error:', error);
  },

  onConnectionChange: (connected) => {
    console.log(`ğŸ”Œ [WS-TTS] Connection: ${connected ? 'Connected' : 'Disconnected'}`);
  }
});
```

**à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸:** à¸•à¹‰à¸­à¸‡à¹à¸à¹‰à¹„à¸‚ `useWebSocketTTS.ts` à¹€à¸à¸·à¹ˆà¸­à¸ªà¹ˆà¸‡ `audioData` parameter (à¸”à¸¹ Step 5)

---

**Step 4.2.5: à¹à¸à¹‰à¹„à¸‚ handleVoiceToVoice() à¸‰à¸šà¸±à¸šà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ** (20-30 à¸™à¸²à¸—à¸µ)

**à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡:** à¹à¸—à¸™à¸—à¸µà¹ˆà¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ `handleVoiceToVoice` à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆ (à¸šà¸£à¸£à¸—à¸±à¸” 107-152)

**ğŸ¯ Goal:** à¸ªà¹ˆà¸‡ audio chunks à¹„à¸›à¸¢à¸±à¸‡ HeyGen Avatar `repeatAudio()` à¹à¸šà¸šà¸—à¸µà¸¥à¸° chunk à¹€à¸à¸·à¹ˆà¸­ lip-sync à¹à¸šà¸š progressive (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸­à¹ƒà¸«à¹‰ synthesis à¹€à¸ªà¸£à¹‡à¸ˆà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”)

**ğŸ’¡ Solution Overview:**

```
Flow: WebSocket TTS â†’ Audio Chunk â†’ repeatAudio() â†’ Wait for playback â†’ Next Chunk
      (Chunk 1) â”€â”€â”€â”€â†’ Avatar Lip-sync â”€â”€â”€â”€â”€â”€â”€â”€â†’ (Chunk 2) â”€â”€â”€â”€â†’ Avatar Lip-sync â”€â”€â”€â”€â†’ ...
```

**à¸«à¸¥à¸±à¸à¸à¸²à¸£:**
1. à¹€à¸¡à¸·à¹ˆà¸­à¹„à¸”à¹‰ chunk à¹à¸£à¸ â†’ à¸ªà¹ˆà¸‡à¹„à¸› `repeatAudio()` à¸—à¸±à¸™à¸—à¸µ (à¹„à¸¡à¹ˆà¸£à¸­ chunk à¸­à¸·à¹ˆà¸™)
2. à¸£à¸­à¹ƒà¸«à¹‰ Avatar à¹€à¸¥à¹ˆà¸™ chunk à¸™à¸±à¹‰à¸™à¹€à¸ªà¸£à¹‡à¸ˆ à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ `AVATAR_SPEAK_ENDED` event
3. à¹€à¸¡à¸·à¹ˆà¸­ chunk à¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²à¹€à¸¥à¹ˆà¸™à¹€à¸ªà¸£à¹‡à¸ˆ â†’ à¸ªà¹ˆà¸‡ chunk à¸–à¸±à¸”à¹„à¸›à¹„à¸›à¸¢à¸±à¸‡ `repeatAudio()`
4. à¸§à¸™à¸‹à¹‰à¸³à¸ˆà¸™à¸„à¸£à¸šà¸—à¸¸à¸ chunks

---

**ğŸ”§ Implementation: Sequential repeatAudio() with Event-based Timing**

**à¸§à¸´à¸˜à¸µà¸à¸²à¸£:**
- à¸ªà¹ˆà¸‡ audio chunk à¹„à¸›à¸¢à¸±à¸‡ `repeatAudio()` à¸—à¸µà¸¥à¸° chunk
- à¸£à¸­ `AVATAR_SPEAK_ENDED` event à¹€à¸¡à¸·à¹ˆà¸­ Avatar à¸à¸¹à¸”à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸•à¹ˆà¸¥à¸° chunk
- à¹€à¸¡à¸·à¹ˆà¸­à¹„à¸”à¹‰à¸£à¸±à¸š event â†’ à¸ªà¹ˆà¸‡ chunk à¸–à¸±à¸”à¹„à¸›à¸—à¸±à¸™à¸—à¸µ

**à¸‚à¹‰à¸­à¸”à¸µ:**
- âœ… **Timing à¹à¸¡à¹ˆà¸™à¸¢à¸³ 100%** (à¹„à¸¡à¹ˆà¸¡à¸µ drift à¹€à¸à¸£à¸²à¸°à¹ƒà¸Šà¹‰ event à¸ˆà¸£à¸´à¸‡à¸ˆà¸²à¸ Avatar)
- âœ… **Latency à¸•à¹ˆà¸³à¸—à¸µà¹ˆà¸ªà¸¸à¸”** (~1.8s, à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹ƒà¸ªà¹ˆ buffer)
- âœ… **HeyGen API à¸£à¸­à¸‡à¸£à¸±à¸šà¹€à¸•à¹‡à¸¡à¸£à¸¹à¸›à¹à¸šà¸š** (à¸¡à¸µ `AVATAR_SPEAK_ENDED` event à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰)
- âœ… **Progressive lip-sync** à¹€à¸«à¹‡à¸™ Avatar à¸à¸¹à¸”à¸—à¸±à¸™à¸—à¸µà¸—à¸µà¹ˆà¹„à¸”à¹‰ chunk à¹à¸£à¸

---

**âœ… à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š HeyGen Avatar API:**

à¸ˆà¸²à¸à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ HeyGen LiveAvatar SDK source code:

**à¹„à¸Ÿà¸¥à¹Œ:** `packages/js-sdk/src/LiveAvatarSession/events.ts`

**à¸à¸šà¸§à¹ˆà¸² HeyGen API à¸£à¸­à¸‡à¸£à¸±à¸š Event-based timing à¸œà¹ˆà¸²à¸™:**

```typescript
export enum AgentEventsEnum {
  AVATAR_SPEAK_STARTED = "avatar.speak_started",  // âœ… à¹€à¸£à¸´à¹ˆà¸¡à¸à¸¹à¸”
  AVATAR_SPEAK_ENDED = "avatar.speak_ended",      // âœ… à¸à¸¹à¸”à¹€à¸ªà¸£à¹‡à¸ˆ (à¹ƒà¸Šà¹‰à¸•à¸£à¸‡à¸™à¸µà¹‰!)
}

export type AgentEventCallbacks = {
  [AgentEventsEnum.AVATAR_SPEAK_STARTED]: (
    event: AgentEventData<AgentEventsEnum.AVATAR_SPEAK_STARTED>
  ) => void;
  [AgentEventsEnum.AVATAR_SPEAK_ENDED]: (
    event: AgentEventData<AgentEventsEnum.AVATAR_SPEAK_ENDED>
  ) => void;
  // ... other events
};
```

**à¸ªà¸£à¸¸à¸›:**
- âœ… **HeyGen Avatar à¸£à¸­à¸‡à¸£à¸±à¸š `AVATAR_SPEAK_ENDED` event**
- âœ… Event à¸ˆà¸° emit à¹€à¸¡à¸·à¹ˆà¸­ Avatar à¸à¸¹à¸” chunk à¹€à¸ªà¸£à¹‡à¸ˆ
- âœ… à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰ Event-based Progressive Lip-sync à¹„à¸”à¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ!

---

**Code Implementation (Event-based):**

```typescript
// ========== Step 1: Setup Event Listeners ==========

import { AgentEventsEnum } from '@heygen/liveavatar-web-sdk';

// à¹€à¸à¸´à¹ˆà¸¡ state à¸ªà¸³à¸«à¸£à¸±à¸š Progressive Lip-sync
const audioChunksQueueRef = useRef<Array<{ audio: string; text: string }>>([]);
const isProcessingChunkRef = useRef(false);
const currentChunkResolveRef = useRef<(() => void) | null>(null);

// ========== Step 2: Setup Avatar Event Listener ==========

useEffect(() => {
  if (!sessionRef.current) return;

  // Listen to AVATAR_SPEAK_ENDED event
  const handleAvatarSpeakEnded = (event: any) => {
    console.log('âœ… [Avatar] AVATAR_SPEAK_ENDED event received:', event.event_id);

    // Resolve the waiting promise
    if (currentChunkResolveRef.current) {
      currentChunkResolveRef.current();
      currentChunkResolveRef.current = null;
    }
  };

  // Attach event listener
  sessionRef.current.on(AgentEventsEnum.AVATAR_SPEAK_ENDED, handleAvatarSpeakEnded);

  // Cleanup on unmount
  return () => {
    if (sessionRef.current) {
      sessionRef.current.off(AgentEventsEnum.AVATAR_SPEAK_ENDED, handleAvatarSpeakEnded);
    }
  };
}, []);

// ========== Step 3: Process Audio Chunks with Event-based Timing ==========

/**
 * à¸ªà¹ˆà¸‡ audio chunk à¹„à¸›à¸¢à¸±à¸‡ Avatar à¹à¸šà¸š sequential (Event-based)
 */
const processNextAudioChunk = useCallback(async () => {
  // Check if already processing
  if (isProcessingChunkRef.current) {
    console.log('â¸ï¸ Already processing a chunk, waiting...');
    return;
  }

  // Check if queue is empty
  if (audioChunksQueueRef.current.length === 0) {
    console.log('âœ… All audio chunks processed');
    isProcessingChunkRef.current = false;
    return;
  }

  isProcessingChunkRef.current = true;

  // Get next chunk
  const chunk = audioChunksQueueRef.current.shift();
  if (!chunk || !sessionRef.current) {
    isProcessingChunkRef.current = false;
    return;
  }

  try {
    const { audio, text } = chunk;
    console.log(`ğŸ‘„ [Avatar] Sending chunk to Avatar: "${text.substring(0, 30)}..."`);

    // Create a Promise that resolves when AVATAR_SPEAK_ENDED event fires
    const waitForAvatarSpeakEnd = new Promise<void>((resolve) => {
      currentChunkResolveRef.current = resolve;
    });

    // Send to Avatar (non-blocking)
    sessionRef.current.repeatAudio(audio);
    console.log('ğŸ“¤ [Avatar] Chunk sent, waiting for AVATAR_SPEAK_ENDED event...');

    // Wait for AVATAR_SPEAK_ENDED event
    await waitForAvatarSpeakEnd;
    console.log('âœ… [Avatar] Chunk playback finished (event-based)');

    // Mark as not processing
    isProcessingChunkRef.current = false;

    // Process next chunk
    if (audioChunksQueueRef.current.length > 0) {
      processNextAudioChunk();
    }

  } catch (error) {
    console.error('âŒ [Avatar] Error processing chunk:', error);
    isProcessingChunkRef.current = false;
    currentChunkResolveRef.current = null;

    // Continue with next chunk even if this one failed
    if (audioChunksQueueRef.current.length > 0) {
      processNextAudioChunk();
    }
  }
}, []);

// ========== Step 4: Setup WebSocket listener à¹à¸¥à¸° handleVoiceToVoice() ==========
// à¹ƒà¸Šà¹‰ Event-based timing à¸ªà¸³à¸«à¸£à¸±à¸š Progressive Lip-sync

const handleVoiceToVoice = useCallback(async () => {
  try {
    const combinedText = getCombinedTranscript();
    if (!combinedText || combinedText.trim().length === 0) return;

    console.log("ğŸš€ [V2V] Starting Voice-to-Voice flow...");
    audioChunksQueueRef.current = [];
    isProcessingChunkRef.current = false;
    currentChunkResolveRef.current = null;

    // 1. OpenAI Chat
    const chatRes = await fetch("/api/openai-chat-complete", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ message: combinedText }),
    });
    const { response: aiResponse } = await chatRes.json();
    console.log("âœ… [V2V] AI Response:", aiResponse);

    // 2. Setup WebSocket listener for progressive lip-sync
    // (à¹ƒà¸Šà¹‰ onAudioChunk callback à¸ˆà¸²à¸ useWebSocketTTS)

    // 3. Synthesize
    if (!isWSTTSConnected) {
      await connectWSTTS();
      await new Promise(resolve => setTimeout(resolve, 500));
    }

    await synthesizeWSTTS(aiResponse);

    // Wait for all chunks to be processed
    while (isWSTTSSynthesizing || audioChunksQueueRef.current.length > 0 || isProcessingChunkRef.current) {
      await new Promise(resolve => setTimeout(resolve, 100));
    }

    console.log("âœ… [V2V] Voice-to-Voice flow with event-based lip-sync completed!");

  } catch (error) {
    console.error("âŒ [V2V] Error:", error);
  }
}, [getCombinedTranscript, isWSTTSConnected, connectWSTTS, synthesizeWSTTS, isWSTTSSynthesizing, processNextAudioChunk]);
```

---

**âš ï¸ à¸‚à¹‰à¸­à¸„à¸§à¸£à¸£à¸°à¸§à¸±à¸‡ (Event-based):**

1. **Event Listener Cleanup:**
   - à¸•à¹‰à¸­à¸‡ `off()` event listener à¹ƒà¸™ cleanup function à¹€à¸à¸·à¹ˆà¸­à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ memory leaks
   ```typescript
   return () => {
     sessionRef.current?.off(AgentEventsEnum.AVATAR_SPEAK_ENDED, handler);
   };
   ```

2. **Multiple Chunks:**
   - à¸–à¹‰à¸²à¸ªà¹ˆà¸‡ chunks à¸«à¸¥à¸²à¸¢à¹† chunk à¸à¸£à¹‰à¸­à¸¡à¸à¸±à¸™ â†’ events à¸­à¸²à¸ˆ fire à¹„à¸¡à¹ˆà¸•à¸£à¸‡à¸¥à¸³à¸”à¸±à¸š
   - **Solution:** à¸•à¹‰à¸­à¸‡à¸ªà¹ˆà¸‡à¸—à¸µà¸¥à¸° chunk à¹à¸¥à¸°à¸£à¸­ event à¸à¹ˆà¸­à¸™à¸ªà¹ˆà¸‡ chunk à¸–à¸±à¸”à¹„à¸› (à¸—à¸³à¹à¸¥à¹‰à¸§à¹ƒà¸™ code à¸”à¹‰à¸²à¸™à¸šà¸™)

3. **Event Timeout:**
   - à¸–à¹‰à¸² event à¹„à¸¡à¹ˆ fire (à¹€à¸Šà¹ˆà¸™ Avatar error) â†’ code à¸ˆà¸°à¸„à¹‰à¸²à¸‡à¸•à¸¥à¸­à¸”
   - **Solution:** à¹€à¸à¸´à¹ˆà¸¡ timeout à¹ƒà¸«à¹‰ Promise
   ```typescript
   const waitForAvatarSpeakEnd = Promise.race([
     new Promise<void>((resolve) => {
       currentChunkResolveRef.current = resolve;
     }),
     new Promise<void>((_, reject) =>
       setTimeout(() => reject(new Error('Timeout waiting for AVATAR_SPEAK_ENDED')), 30000)
     )
   ]);
   ```

4. **Event Data:**
   - `AVATAR_SPEAK_ENDED` event à¸¡à¸µ `event_id` à¸—à¸µà¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰ track chunk à¹„à¸”à¹‰
   - à¹à¸•à¹ˆà¹„à¸¡à¹ˆà¸¡à¸µ chunk index â†’ à¸•à¹‰à¸­à¸‡à¸ˆà¸±à¸”à¸à¸²à¸£ queue à¹€à¸­à¸‡

---

**ğŸ“‹ Step 5: Required Modifications to useWebSocketTTS.ts**

à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰ Event-based Progressive Lip-sync à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰ à¸•à¹‰à¸­à¸‡à¹à¸à¹‰à¹„à¸‚ `useWebSocketTTS.ts`:

**5.1: à¹€à¸à¸´à¹ˆà¸¡ audio_data à¹ƒà¸™ onAudioChunk callback**

```typescript
// à¹„à¸Ÿà¸¥à¹Œ: apps/demo/src/liveavatar/useWebSocketTTS.ts

// à¹à¸à¹‰à¹„à¸‚ interface TTSConfig
export interface TTSConfig {
  // ... existing fields
  /** Callback when audio chunk is received */
  onAudioChunk?: (
    chunkIndex: number,
    totalChunks: number,
    text: string,
    audioData: string // ğŸ†• à¹€à¸à¸´à¹ˆà¸¡ audio_data (base64)
  ) => void;
  // ... rest of fields
}

// à¹à¸à¹‰à¹„à¸‚ handleAudioChunk function
const handleAudioChunk = useCallback((message: AudioChunkMessage) => {
  const { chunk_index, total_chunks, audio_data, text } = message;

  console.log(`ğŸ“¦ Received audio chunk ${chunk_index + 1}/${total_chunks}`);

  // Update progress
  setProgress({
    current: chunk_index + 1,
    total: total_chunks,
    currentText: text,
  });

  // ğŸ†• Trigger callback with audio_data
  callbacksRef.current.onAudioChunk?.(chunk_index, total_chunks, text, audio_data);

  // ... existing audio processing code
}, [playNextChunk]);
```

**5.2: (Optional) Expose WebSocket ref à¸ªà¸³à¸«à¸£à¸±à¸š advanced use cases**

```typescript
// Return WebSocket ref à¸ˆà¸²à¸ hook
return {
  // ... existing returns
  wsRef, // ğŸ†• Expose WebSocket ref (for advanced users)
};
```

---

**ğŸ¯ à¹à¸™à¸°à¸™à¸³à¸ªà¸³à¸«à¸£à¸±à¸šà¸™à¸±à¸à¸à¸±à¸’à¸™à¸²:**

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 1: à¸—à¸”à¸ªà¸­à¸š Option 1 à¸à¹ˆà¸­à¸™ (Direct Web Audio Playback)**
- Implementation à¸‡à¹ˆà¸²à¸¢ à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹à¸à¹‰à¹‚à¸„à¹‰à¸”à¸¡à¸²à¸
- à¸—à¸”à¸ªà¸­à¸šà¸§à¹ˆà¸² latency à¹à¸¥à¸° UX à¹€à¸›à¹‡à¸™à¸¢à¸±à¸‡à¹„à¸‡
- **à¸–à¹‰à¸²:** à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£ lip-sync (à¹€à¸Šà¹ˆà¸™ audio-only mode) â†’ à¹ƒà¸Šà¹‰ Option 1

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 2: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š HeyGen Avatar API**
```typescript
// à¸—à¸”à¸ªà¸­à¸šà¸§à¹ˆà¸² repeatAudio() return Promise à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
const result = await sessionRef.current.repeatAudio(audio);
console.log('repeatAudio result:', result);

// à¸«à¸£à¸·à¸­à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µ event listeners à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
console.log('Available methods:', Object.keys(sessionRef.current));
```

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 3: Implement Event-based Progressive Lip-sync**
- âœ… **HeyGen Avatar API à¸£à¸­à¸‡à¸£à¸±à¸š `AVATAR_SPEAK_ENDED` event à¹à¸¥à¹‰à¸§**
- à¹à¸à¹‰à¹„à¸‚ `useWebSocketTTS.ts` à¸•à¸²à¸¡ Step 5
- Implement Event-based timing à¸•à¸²à¸¡à¹‚à¸„à¹‰à¸”à¸”à¹‰à¸²à¸™à¸šà¸™
- Setup event listeners à¹à¸¥à¸° cleanup handlers

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 4: Testing à¹à¸¥à¸° Validation**
- à¸—à¸”à¸ªà¸­à¸šà¸à¸±à¸š text à¸¢à¸²à¸§/à¸ªà¸±à¹‰à¸™, à¸ à¸²à¸©à¸²à¹„à¸—à¸¢/à¸­à¸±à¸‡à¸à¸¤à¸©
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² Avatar lip-sync à¸•à¸£à¸‡à¸à¸±à¸š audio
- à¸§à¸±à¸” latency à¹à¸¥à¸°à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸š REST API TTS
- à¸—à¸”à¸ªà¸­à¸š error handling (network fail, event timeout)

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 5: Fine-tuning**
- à¹€à¸à¸´à¹ˆà¸¡ timeout à¸ªà¸³à¸«à¸£à¸±à¸š event (à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ hang à¸–à¹‰à¸² event à¹„à¸¡à¹ˆ fire)
- à¸›à¸£à¸±à¸š chunk size delimiters (à¸–à¹‰à¸² chunks à¸¢à¸²à¸§à¹€à¸à¸´à¸™)
- à¹€à¸à¸´à¹ˆà¸¡ error recovery (retry mechanism)
- Optimize queue processing

---

**âš ï¸ à¸‚à¹‰à¸­à¸„à¸§à¸£à¸£à¸°à¸§à¸±à¸‡:**

1. **Event Listener Cleanup:** à¸•à¹‰à¸­à¸‡ cleanup listeners à¹ƒà¸™ `useEffect` return à¹€à¸à¸·à¹ˆà¸­à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ memory leaks
2. **Event Timeout:** à¹€à¸à¸´à¹ˆà¸¡ timeout à¹€à¸à¸·à¹ˆà¸­à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ code à¸„à¹‰à¸²à¸‡à¸–à¹‰à¸² `AVATAR_SPEAK_ENDED` à¹„à¸¡à¹ˆ fire
3. **Queue Management:** à¸•à¹‰à¸­à¸‡à¸ˆà¸±à¸”à¸à¸²à¸£ queue à¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸°à¸¡à¸±à¸”à¸£à¸°à¸§à¸±à¸‡à¹€à¸à¸·à¹ˆà¸­à¹„à¸¡à¹ˆà¹ƒà¸«à¹‰ chunks à¹€à¸¥à¹ˆà¸™à¸œà¸´à¸”à¸¥à¸³à¸”à¸±à¸š
4. **Audio Format:** HeyGen `repeatAudio()` à¸£à¸±à¸š base64 MP3 format (mp3_44100_128)

---

**Step 4.3: Update UI Controls** (20-30 à¸™à¸²à¸—à¸µ)

**à¹„à¸Ÿà¸¥à¹Œ:** `apps/demo/src/components/LiveAvatarSession.tsx`

**4.3.1: à¹€à¸à¸´à¹ˆà¸¡ WebSocket TTS Status UI**

**à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡:** à¹ƒà¸™ `RealtimeSTTComponents` section (à¸«à¸¥à¸±à¸‡à¸šà¸£à¸£à¸—à¸±à¸” 251)

**à¹€à¸à¸´à¹ˆà¸¡à¹‚à¸„à¹‰à¸”à¸™à¸µà¹‰:**
```typescript
const RealtimeSTTComponents = (
  <>
    <div className="w-full border-t-2 border-yellow-400 pt-4 mt-4">
      <h3 className="text-lg font-bold text-yellow-400 mb-2">
        ElevenLabs Realtime STT (Continuous Voice Chat)
      </h3>
      <p>Connected: {isRealtimeSTTConnected ? "true" : "false"}</p>

      {/* ğŸ†• à¹€à¸à¸´à¹ˆà¸¡à¸ªà¹ˆà¸§à¸™à¸™à¸µà¹‰: WebSocket TTS Status */}
      <div className="mt-2 p-2 bg-gray-800 rounded">
        <p className="text-sm">
          <span className="font-semibold">WebSocket TTS:</span>{" "}
          <span className={isWSTTSConnected ? "text-green-400" : "text-red-400"}>
            {isWSTTSConnected ? "Connected âœ…" : "Disconnected âŒ"}
          </span>
        </p>
        {isWSTTSSynthesizing && (
          <p className="text-sm text-blue-400 mt-1">
            ğŸ”Š Synthesizing... {wsTTSProgress.current}/{wsTTSProgress.total} chunks
            {wsTTSProgress.currentText && (
              <span className="text-xs text-gray-400 ml-2">
                "{wsTTSProgress.currentText.substring(0, 30)}..."
              </span>
            )}
          </p>
        )}
      </div>
      {/* à¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸”à¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆà¹€à¸à¸´à¹ˆà¸¡ */}

      {realtimePartialText && (
        <p className="text-gray-400 italic">Partial: {realtimePartialText}</p>
      )}
      {realtimeFinalText && (
        <p className="text-white font-semibold">Transcript: {realtimeFinalText}</p>
      )}
      <div className="flex gap-2 mt-2">
        <Button
          onClick={async () => {
            if (isRealtimeSTTConnected) {
              disconnectRealtimeSTT();
              await new Promise(resolve => setTimeout(resolve, 100));
              await handleVoiceToVoice();
            } else {
              connectRealtimeSTT();
            }
          }}
          // ğŸ†• Disable button à¸‚à¸“à¸° synthesizing
          disabled={isWSTTSSynthesizing}
          className={`px-6 py-3 rounded-md font-semibold transition-all ${
            isRealtimeSTTConnected
              ? "bg-red-500 text-white hover:bg-red-600"
              : "bg-green-500 text-white hover:bg-green-600"
          } ${isWSTTSSynthesizing ? "opacity-50 cursor-not-allowed" : ""}`}
        >
          {isWSTTSSynthesizing
            ? "ğŸ”Š Synthesizing..."
            : isRealtimeSTTConnected
            ? "Stop & Process with Avatar"
            : "Start Realtime Voice Chat"}
        </Button>
        <Button
          onClick={() => {
            resetRealtimeSTT();
          }}
          disabled={!isRealtimeSTTConnected || isWSTTSSynthesizing}
        >
          Reset Transcript
        </Button>
      </div>
    </div>
  </>
);
```

**4.3.2: à¹€à¸à¸´à¹ˆà¸¡ Error Notification UI (Optional)**

```typescript
// à¹€à¸à¸´à¹ˆà¸¡ state à¸ªà¸³à¸«à¸£à¸±à¸š error message
const [errorMessage, setErrorMessage] = useState<string | null>(null);

// à¹à¸à¹‰à¹„à¸‚ useWebSocketTTS config
const {
  // ... existing config
  onError: (error) => {
    console.error('âŒ [WS-TTS] Error:', error);
    setErrorMessage(typeof error === 'string' ? error : error.message);
    // Auto-clear error after 5 seconds
    setTimeout(() => setErrorMessage(null), 5000);
  },
  // ... rest of config
} = useWebSocketTTS({ /* ... */ });

// à¹€à¸à¸´à¹ˆà¸¡ UI à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸ªà¸”à¸‡ error (à¹ƒà¸™ RealtimeSTTComponents)
{errorMessage && (
  <div className="mt-2 p-3 bg-red-900 border border-red-500 rounded text-red-200 text-sm">
    âŒ Error: {errorMessage}
  </div>
)}
```

---

**Step 4.4: Testing & Validation** (20-30 à¸™à¸²à¸—à¸µ)

**4.4.1: à¸—à¸”à¸ªà¸­à¸š Integration**
```bash
# Terminal 1: Start WebSocket TTS server
cd apps/demo
pnpm ws-tts

# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š output:
# âœ… WebSocket TTS Server is listening on port 3013
# ğŸ”— Connect to: ws://localhost:3013/ws/elevenlabs-tts

# Terminal 2: Start Next.js app
pnpm dev

# à¹€à¸›à¸´à¸”à¹€à¸šà¸£à¸²à¸§à¹Œà¹€à¸‹à¸­à¸£à¹Œ: http://localhost:3012
```

**4.4.2: à¸—à¸”à¸ªà¸­à¸š Complete V2V Flow**
1. à¹€à¸¥à¸·à¸­à¸ **CUSTOM mode** â†’ à¸à¸” "Start Session"
2. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š WebSocket TTS status: "Connected âœ…"
3. à¸à¸” **"Start Realtime Voice Chat"**
4. à¸à¸¹à¸”à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ (à¹€à¸Šà¹ˆà¸™ "à¸ªà¸§à¸±à¸ªà¸”à¸µ à¸‰à¸±à¸™à¸Šà¸·à¹ˆà¸­à¸­à¸°à¹„à¸£")
5. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Transcript à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸à¸¹à¸”
6. à¸à¸” **"Stop & Process with Avatar"**
7. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Console Logs:
   ```
   ğŸš€ [V2V] Starting Voice-to-Voice flow...
   ğŸ“ [V2V] Combined transcript: à¸ªà¸§à¸±à¸ªà¸”à¸µ à¸‰à¸±à¸™à¸Šà¸·à¹ˆà¸­à¸­à¸°à¹„à¸£
   ğŸ¤– [V2V] Sending to OpenAI...
   âœ… [V2V] AI Response: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸œà¸¡...
   ğŸ”Š [V2V] Converting to speech via WebSocket TTS...
   ğŸ”Š [WS-TTS] Chunk 1/3: "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š,"
   ğŸ”Š [WS-TTS] Chunk 2/3: "à¸œà¸¡à¸„à¸·à¸­ AI..."
   ğŸ”Š [WS-TTS] Chunk 3/3: "à¸¢à¸´à¸™à¸”à¸µà¸—à¸µà¹ˆà¹„à¸”à¹‰à¸£à¸¹à¹‰à¸ˆà¸±à¸à¸„à¸£à¸±à¸š."
   âœ… [WS-TTS] Completed - Total 3 chunks
   âœ… [V2V] Voice-to-Voice flow completed!
   ```
8. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹€à¸ªà¸µà¸¢à¸‡à¹€à¸¥à¹ˆà¸™à¹à¸šà¸š progressive (à¹„à¸”à¹‰à¸¢à¸´à¸™à¹€à¸ªà¸µà¸¢à¸‡à¸—à¸±à¸™à¸—à¸µà¸—à¸µà¹ˆà¹„à¸”à¹‰ chunk à¹à¸£à¸)

**4.4.3: à¸—à¸”à¸ªà¸­à¸š Error Scenarios**
- **WebSocket Server Down:** à¸«à¸¢à¸¸à¸” `pnpm ws-tts` â†’ à¸à¸” "Stop & Process" â†’ à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š error message à¹à¸ªà¸”à¸‡
- **Network Error:** Disconnect network â†’ à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š reconnection behavior
- **Long Text:** à¸à¸¹à¸”à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§ (>500 chars) â†’ à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š chunking à¹à¸¥à¸° sequential playback

**4.4.4: à¸§à¸±à¸” Performance**
```typescript
// à¹€à¸à¸´à¹ˆà¸¡à¹ƒà¸™ handleVoiceToVoice() à¹€à¸à¸·à¹ˆà¸­à¸§à¸±à¸” latency
const startTime = performance.now();

// ... existing V2V flow code

const endTime = performance.now();
console.log(`â±ï¸ [V2V] Total latency: ${(endTime - startTime) / 1000}s`);

// Target: 1.5-2.5 à¸§à¸´à¸™à¸²à¸—à¸µ (40-50% à¹€à¸£à¹‡à¸§à¸à¸§à¹ˆà¸² REST API)
```

---

**Deliverables:**
âœ… LiveAvatarSession component integrated with WebSocket TTS
âœ… Complete V2V flow: Realtime STT â†’ OpenAI â†’ WebSocket TTS â†’ Progressive Audio Playback
âœ… UI shows connection status, synthesis progress, and errors
âœ… Reduced latency ~1.5-2.5s (40-50% improvement over REST API)
âœ… Tested with Thai/English text, long texts, and error scenarios

---

**Common Issues & Solutions:**

**Issue 1:** WebSocket TTS not connecting
```
âŒ WebSocket connection failed
```
**Solution:**
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² WebSocket server à¸£à¸±à¸™à¸­à¸¢à¸¹à¹ˆ (`pnpm ws-tts`)
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š port 3013 à¹„à¸¡à¹ˆà¸–à¸¹à¸ block à¹‚à¸”à¸¢ firewall
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š URL: `ws://localhost:3013/ws/elevenlabs-tts`

**Issue 2:** Audio à¹„à¸¡à¹ˆà¹€à¸¥à¹ˆà¸™
```
âœ… Synthesis completed à¹à¸•à¹ˆà¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸¢à¸´à¸™à¹€à¸ªà¸µà¸¢à¸‡
```
**Solution:**
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š AudioContext initialized (`useWebSocketTTS` à¸—à¸³à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´)
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š browser autoplay policy (à¸•à¹‰à¸­à¸‡ user interaction à¸à¹ˆà¸­à¸™)
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š audio format (à¸•à¹‰à¸­à¸‡à¹€à¸›à¹‡à¸™ mp3_44100_128)

**Issue 3:** Chunks à¹€à¸¥à¹ˆà¸™à¹„à¸¡à¹ˆà¹€à¸£à¸µà¸¢à¸‡à¸¥à¸³à¸”à¸±à¸š
```
Chunk 3 à¹€à¸¥à¹ˆà¸™à¸à¹ˆà¸­à¸™ Chunk 1
```
**Solution:**
- `useWebSocketTTS` à¹ƒà¸Šà¹‰ sequential queue à¸­à¸¢à¸¹à¹ˆà¹à¸¥à¹‰à¸§
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹ƒà¸Šà¹‰ hook version à¸¥à¹ˆà¸²à¸ªà¸¸à¸”
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š server à¸ªà¹ˆà¸‡ chunk_index à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡

---

**Files Modified:**
- `apps/demo/src/components/LiveAvatarSession.tsx` (main integration)

**Dependencies:**
- `useWebSocketTTS` hook (already implemented in Task 3)
- WebSocket TTS Server (already running on port 3013)

**Next Steps:**
â†’ à¸—à¸”à¸ªà¸­à¸šà¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¸•à¸²à¸¡ Step 4.4
â†’ à¹à¸à¹‰à¹„à¸‚ bugs à¸—à¸µà¹ˆà¹€à¸ˆà¸­ (à¸–à¹‰à¸²à¸¡à¸µ)
â†’ à¹„à¸›à¸•à¹ˆà¸­ Task 5: Testing & Documentation

---

#### **Task 5: Testing & Documentation** âŒ (Estimated: 1-1.5 hours)

**Step 5.1: End-to-End Testing**
- Test WebSocket server startup/shutdown
- Test React integration
- Test error scenarios (network errors, API errors)
- Test with long texts and Thai/English

**Step 5.2: Performance Testing**
- à¸§à¸±à¸” latency (first chunk, total time)
- à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸š REST API
- Target: First chunk <2s, Total 1.5-2.5s, 40-50% à¹€à¸£à¹‡à¸§à¸à¸§à¹ˆà¸² REST
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š memory leaks à¹à¸¥à¸° audio quality

**Step 5.3: Update Documentation**
- à¸­à¸±à¸à¹€à¸”à¸• V2V_REALTIME.md status à¹€à¸›à¹‡à¸™ 100%
- à¹€à¸à¸´à¹ˆà¸¡ usage examples
- à¹€à¸à¸´à¹ˆà¸¡ troubleshooting tips
- à¸­à¸±à¸à¹€à¸”à¸• latency numbers à¸ˆà¸£à¸´à¸‡

**Deliverables:**
- Test cases à¸œà¹ˆà¸²à¸™à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
- Performance à¸•à¸£à¸‡à¸•à¸²à¸¡ target
- Documentation updated
- Production ready

**à¸§à¸´à¸˜à¸µà¸—à¸”à¸ªà¸­à¸š:**
```bash
# 1. WebSocket Server Tests
pnpm ws-tts  # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸£à¸±à¸™à¹„à¸”à¹‰à¹‚à¸”à¸¢à¹„à¸¡à¹ˆ error

# 2. Integration Tests  
pnpm dev
# à¸—à¸”à¸ªà¸­à¸š V2V flow à¸„à¸£à¸šà¸–à¹‰à¸§à¸™
# à¸—à¸”à¸ªà¸­à¸š error scenarios (server down, disconnect)
# à¸—à¸”à¸ªà¸­à¸šà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§

# 3. Performance Tests
# à¸§à¸±à¸” latency à¸”à¹‰à¸§à¸¢ performance.now()
# à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š WebSocket TTS vs REST API

# 4. TypeScript Check
pnpm typecheck  # à¸•à¹‰à¸­à¸‡à¸œà¹ˆà¸²à¸™à¹„à¸¡à¹ˆà¸¡à¸µ errors
```

---

### ğŸ“Š Summary Timeline

| Task | Status | Estimated Time | Priority |
|------|--------|---------------|----------|
| Task 1: Setup | âœ… à¹€à¸ªà¸£à¹‡à¸ˆ | 15-30 à¸™à¸²à¸—à¸µ | P0 |
| Task 2: WebSocket Server | âœ… à¹€à¸ªà¸£à¹‡à¸ˆ | 3-4 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡ | P0 |
| Task 3: React Hook | âœ… à¹€à¸ªà¸£à¹‡à¸ˆ | 2-3 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡ | P0 |
| Task 4: Integration | âŒ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸—à¸³ | 1.5-2 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡ | P0 |
| Task 5: Testing & Docs | âŒ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸—à¸³ | 1-1.5 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡ | P0 |
| **COMPLETED** | **3/5 Tasks (60%)** | **~6-8 hours** | - |
| **REMAINING** | **2/5 Tasks (40%)** | **~2-3 hours** | - |

### ğŸ¯ Success Criteria

**Tasks 1-3 (à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ âœ…):**
- âœ… WebSocket server à¸£à¸±à¸™à¹„à¸”à¹‰à¸šà¸™ port 3013
- âœ… Text chunking à¸£à¸­à¸‡à¸£à¸±à¸š delimiters à¸„à¸£à¸š: `,` `!` `?` `:` `;` `.`
- âœ… Audio playback à¹à¸šà¸š sequential à¹„à¸¡à¹ˆà¸ªà¸°à¸”à¸¸à¸”
- âœ… React Hook à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ (WebSocket connection, audio queue, progress tracking)

**Tasks 4-5 (à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸—à¸³ âŒ):**
- âŒ Integration à¸à¸±à¸š LiveAvatarSession component
- âŒ Complete V2V flow (Realtime STT â†’ OpenAI â†’ WebSocket TTS â†’ Avatar)
- âŒ Latency à¸¥à¸”à¸¥à¸‡à¹€à¸›à¹‡à¸™ ~1.5-2.5 à¸§à¸´à¸™à¸²à¸—à¸µ (40-50% improvement)
- âŒ Error handling à¸„à¸£à¸šà¸–à¹‰à¸§à¸™
- âŒ Production ready

### References
- [ElevenLabs REST API Documentation](https://elevenlabs.io/docs/api-reference/text-to-speech)
- [ElevenLabs Model Comparison](https://elevenlabs.io/docs/api-reference/models)
- [Web Audio API Documentation](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- [WebSocket Protocol RFC](https://datatracker.ietf.org/doc/html/rfc6455)
- [Reference Implementation: WS_TTS_EL.md](./WS_TTS_EL.md)

---

## PHASE 6: WebSocket Integration for OpenAI Chat âš ï¸ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸—à¸³

**Status:** âš ï¸ **à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰ Implement** - à¸•à¹‰à¸­à¸‡à¸ªà¸£à¹‰à¸²à¸‡ Custom WebSocket Server
**Estimated Effort:** 5-7 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡

### à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¸¡à¸µ Phase à¸™à¸µà¹‰?

Phase 3 à¹ƒà¸Šà¹‰ OpenAI Chat à¹à¸šà¸š **REST API** (request/response à¹à¸¢à¸à¸à¸±à¸™) à¸—à¸³à¹ƒà¸«à¹‰:
- âŒ à¸•à¹‰à¸­à¸‡ establish connection à¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡ (overhead)
- âŒ à¹„à¸¡à¹ˆà¹€à¸à¹‡à¸š conversation history à¸šà¸™ server
- âŒ Latency à¸ªà¸¹à¸‡à¸à¸§à¹ˆà¸² WebSocket

Phase 6 à¸ˆà¸°à¹ƒà¸Šà¹‰ **WebSocket** à¸—à¸³à¹ƒà¸«à¹‰:
- âœ… Connection à¸„à¸‡à¸­à¸¢à¸¹à¹ˆà¸•à¸¥à¸­à¸” (persistent connection)
- âœ… à¸¥à¸” latency (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ handshake à¸‹à¹‰à¸³)
- âœ… Server à¸ˆà¸±à¸”à¸à¸²à¸£ conversation history

(à¸”à¸¹à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡à¹ƒà¸™à¹€à¸­à¸à¸ªà¸²à¸£à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š)

---

## à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸—à¸±à¹‰à¸‡à¸£à¸°à¸šà¸š

(à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸ªà¹ˆà¸§à¸™à¸™à¸µà¹‰à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡ - à¸”à¸¹à¹ƒà¸™à¹€à¸­à¸à¸ªà¸²à¸£à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š)

---

## à¸‚à¹‰à¸­à¸„à¸§à¸£à¸£à¸°à¸§à¸±à¸‡

1. **Token Expiration**: ElevenLabs single-use token à¸«à¸¡à¸”à¸­à¸²à¸¢à¸¸à¹ƒà¸™ 15 à¸™à¸²à¸—à¸µ - à¸•à¹‰à¸­à¸‡ refresh
2. **WebSocket Reconnection**: à¸•à¹‰à¸­à¸‡à¸¡à¸µ retry logic à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£ reconnect
3. **Audio Format**: à¸•à¹‰à¸­à¸‡à¹à¸™à¹ˆà¹ƒà¸ˆà¸§à¹ˆà¸²à¹ƒà¸Šà¹‰ PCM 24kHz à¸ªà¸³à¸«à¸£à¸±à¸š Avatar
4. **Chunk Size**: à¸ªà¹ˆà¸‡ audio à¹€à¸›à¹‡à¸™ chunks à¹† à¸¥à¸° 20ms (960 bytes)
5. **Error Handling**: à¸•à¹‰à¸­à¸‡à¸ˆà¸±à¸”à¸à¸²à¸£ error à¸—à¸¸à¸ phase
6. **Rate Limiting**: à¸£à¸°à¸§à¸±à¸‡ API rate limits à¸‚à¸­à¸‡à¸—à¸¸à¸à¸šà¸£à¸´à¸à¸²à¸£
7. **Cost**: à¸£à¸°à¸šà¸šà¸™à¸µà¹‰à¹ƒà¸Šà¹‰ 3 à¸šà¸£à¸´à¸à¸²à¸£à¸à¸£à¹‰à¸­à¸¡à¸à¸±à¸™ - à¸•à¹‰à¸­à¸‡à¸„à¸³à¸™à¸§à¸“ cost
8. **Model Selection**: à¹€à¸¥à¸·à¸­à¸ TTS model à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ - eleven_v3 à¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š WebSocket streaming

---

## à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡

- [HeyGen LiveAvatar Docs](https://docs.heygen.com/docs/liveavatar)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [ElevenLabs Docs](https://elevenlabs.io/docs)
- [ElevenLabs Realtime STT](https://elevenlabs.io/docs/cookbooks/speech-to-text/streaming)
- [ElevenLabs WebSocket Streaming TTS](https://elevenlabs.io/docs/api-reference/websockets)
- [LiveKit Docs](https://docs.livekit.io)
- [WebSocket API (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [Testing Documentation](./TEST_V2V_PROCESS.md)
