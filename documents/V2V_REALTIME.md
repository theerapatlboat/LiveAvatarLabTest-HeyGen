# Voice-to-Voice Real-time Communication System
**HeyGen LiveAvatar + OpenAI + ElevenLabs Integration**

---

## ğŸ“Š IMPLEMENTATION STATUS SUMMARY

### à¸£à¸°à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¸à¸£à¹‰à¸­à¸¡: **80% à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™** âœ…

| Phase | Status | Progress | Ready for Production |
|-------|--------|----------|---------------------|
| **Phase 1**: Session Management | âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 100% | âœ… YES |
| **Phase 2**: Voice Chat (FULL) | âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 100% | âœ… YES |
| **Phase 3**: Custom Voice Chat | âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 100% | âœ… YES |
| **Phase 4**: Realtime STT (Logs-only) | âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 100% | âœ… YES (testing mode) |
| **Phase 4**: Realtime STT (Full V2V) | â¸ï¸ à¸à¸£à¹‰à¸­à¸¡à¹€à¸›à¸´à¸”à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | 100% | âœ… YES (uncomment code) |
| **Phase 5**: WebSocket Chat | âš ï¸ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 0% | âŒ NO |
| **Phase 6**: WebSocket TTS | âš ï¸ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ | 0% | âŒ NO |

### à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ (Production Ready)

âœ… **à¹‚à¸«à¸¡à¸” FULL** - Voice-to-Voice à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¸”à¹‰à¸§à¸¢ HeyGen built-in AI
- Latency: ~1-2 à¸§à¸´à¸™à¸²à¸—à¸µ
- à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¸—à¸±à¸™à¸—à¸µ

âœ… **à¹‚à¸«à¸¡à¸” CUSTOM + REST APIs** - Voice-to-Voice à¹à¸šà¸šà¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹„à¸”à¹‰
- Pipeline: User Speech â†’ Whisper STT â†’ OpenAI Chat â†’ ElevenLabs TTS â†’ Avatar
- Latency: ~3-5 à¸§à¸´à¸™à¸²à¸—à¸µ
- à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡ AI à¹à¸¥à¸°à¹€à¸ªà¸µà¸¢à¸‡à¹„à¸”à¹‰à¹€à¸•à¹‡à¸¡à¸—à¸µà¹ˆ

âœ… **à¹‚à¸«à¸¡à¸” CUSTOM + ElevenLabs Realtime STT (Logs-only)** - Real-time STT Testing
- Pipeline: User Speech â†’ ElevenLabs Realtime STT â†’ Console Logs
- Latency: <500ms (real-time streaming)
- à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸à¸” Hold to Talk à¹à¸šà¸šà¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡
- à¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸”à¹‰à¸§à¸¢ Scribe v2
- **à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸¡à¸µ OpenAI/ElevenLabs TTS API keys**

â¸ï¸ **à¹‚à¸«à¸¡à¸” CUSTOM + ElevenLabs Realtime STT (Full V2V)** - Voice-to-Voice à¹à¸šà¸š Continuous Streaming
- Pipeline: User Speech â†’ ElevenLabs Realtime STT â†’ OpenAI Chat â†’ ElevenLabs TTS â†’ Avatar
- Latency: ~2-3 à¸§à¸´à¸™à¸²à¸—à¸µ (à¹€à¸£à¹‡à¸§à¸à¸§à¹ˆà¸² Whisper)
- **à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹à¸¥à¹‰à¸§ - à¹à¸„à¹ˆ uncomment code**
- à¸•à¹‰à¸­à¸‡à¸¡à¸µ OpenAI API key à¹à¸¥à¸° ElevenLabs TTS API key

### à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¸•à¹‰à¸­à¸‡à¸à¸±à¸’à¸™à¸² (Need Implementation)

âœ… **Phase 4**: ElevenLabs Realtime STT (100% à¹€à¸ªà¸£à¹‡à¸ˆ - Logs-only Mode)
- âœ… API endpoint à¸ªà¸³à¸«à¸£à¸±à¸š token generation
- âœ… React Hook à¸”à¹‰à¸§à¸¢ @elevenlabs/client SDK + microphone config
- âœ… Integration à¸à¸±à¸š UI à¹à¸¥à¸° console logging
- âœ… UI controls à¸ªà¸³à¸«à¸£à¸±à¸š Start/Stop continuous voice chat
- âœ… à¹à¸ªà¸”à¸‡ partial à¹à¸¥à¸° final transcripts à¹ƒà¸™ console
- â¸ï¸ Full V2V flow (OpenAI + TTS + Avatar) - à¸à¸£à¹‰à¸­à¸¡à¹€à¸›à¸´à¸”à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

âš ï¸ **Phase 5-6**: WebSocket Features (à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸£à¸´à¹ˆà¸¡)
- WebSocket Chat Server (à¹„à¸¡à¹ˆà¸¡à¸µ Custom Server)
- WebSocket Streaming TTS (à¹„à¸¡à¹ˆà¸¡à¸µ Custom Server)
- Total Effort: ~10-14 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡

### à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™

**à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„à¸—à¸µà¹ˆà¸¢à¸­à¸¡à¸£à¸±à¸š Latency 3-5 à¸§à¸´à¸™à¸²à¸—à¸µ:**
```bash
pnpm dev
# à¹€à¸›à¸´à¸” http://localhost:3000
# à¹€à¸¥à¸·à¸­à¸ CUSTOM mode â†’ à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¹€à¸¥à¸¢
```

**à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£ Real-time (<1 à¸§à¸´à¸™à¸²à¸—à¸µ):**
- à¸•à¹‰à¸­à¸‡à¸—à¸³ Phase 4-6 à¹ƒà¸«à¹‰à¹€à¸ªà¸£à¹‡à¸ˆà¸à¹ˆà¸­à¸™
- à¸”à¸¹à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸”à¹‰à¸²à¸™à¸¥à¹ˆà¸²à¸‡

---

## à¸ªà¸£à¸¸à¸›à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™

à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„à¸™à¸µà¹‰à¹€à¸›à¹‡à¸™à¸£à¸°à¸šà¸šà¸ªà¸™à¸—à¸™à¸² Voice-to-Voice à¹à¸šà¸š Real-time à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ HeyGen LiveAvatar à¹€à¸›à¹‡à¸™ Avatar à¸«à¸¥à¸±à¸ à¹‚à¸”à¸¢à¸£à¸­à¸‡à¸£à¸±à¸š 2 à¹‚à¸«à¸¡à¸”:

### à¹‚à¸«à¸¡à¸” FULL âœ… (à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™)
- HeyGen à¸ˆà¸±à¸”à¸à¸²à¸£à¸—à¸¸à¸à¸­à¸¢à¹ˆà¸²à¸‡ (STT, AI, TTS, Lip-sync)
- à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸„à¸§à¸²à¸¡à¸‡à¹ˆà¸²à¸¢à¹à¸¥à¸°à¸£à¸§à¸”à¹€à¸£à¹‡à¸§
- Latency: 1-2 à¸§à¸´à¸™à¸²à¸—à¸µ

### à¹‚à¸«à¸¡à¸” CUSTOM âœ… (à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™)
- à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸„à¸§à¸šà¸„à¸¸à¸¡ AI (OpenAI GPT) à¹à¸¥à¸° TTS (ElevenLabs)
- HeyGen à¸—à¸³à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆà¹à¸„à¹ˆ Video Streaming à¹à¸¥à¸° Lip-sync
- à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¸šà¸¸à¸„à¸¥à¸´à¸à¸ à¸²à¸à¹à¸¥à¸°à¹€à¸ªà¸µà¸¢à¸‡à¸‚à¸­à¸‡ Avatar
- Latency: 3-5 à¸§à¸´à¸™à¸²à¸—à¸µ (REST APIs)

### à¹‚à¸«à¸¡à¸” CUSTOM + WebSocket âš ï¸ (à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸à¸£à¹‰à¸­à¸¡ - à¸•à¹‰à¸­à¸‡à¸à¸±à¸’à¸™à¸² Phase 4-6)
- à¹ƒà¸Šà¹‰ WebSocket à¹à¸—à¸™ REST APIs
- Latency: <1 à¸§à¸´à¸™à¸²à¸—à¸µ (Real-time streaming)
- à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ Custom WebSocket Server

## à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸«à¸¥à¸±à¸à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰

| à¸šà¸£à¸´à¸à¸²à¸£ | à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ | Implementation Status | à¹€à¸­à¸à¸ªà¸²à¸£ |
|--------|---------|---------------------|---------|
| **HeyGen LiveAvatar** | Video Streaming, Lip-sync Animation | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://api.liveavatar.com |
| **OpenAI Whisper** | Speech-to-Text (CUSTOM mode) | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://platform.openai.com/docs/guides/speech-to-text |
| **OpenAI GPT-4** | AI Conversation (CUSTOM mode) | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://platform.openai.com/docs/guides/chat |
| **ElevenLabs** | Text-to-Speech (CUSTOM mode) | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://elevenlabs.io/docs |
| **ElevenLabs Scribe** | Real-time Speech-to-Text | âš ï¸ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://elevenlabs.io/docs/cookbooks/speech-to-text/streaming |
| **LiveKit** | WebRTC Video Streaming | âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ | https://docs.livekit.io |
| **WebSocket** | Real-time Command/Event Communication | âš ï¸ à¹ƒà¸Šà¹‰à¸šà¸²à¸‡à¸ªà¹ˆà¸§à¸™ (HeyGen) | - |

## à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸£à¸±à¸™à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„

### 1. à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ Dependencies

```bash
# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ pnpm (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ)
npm install -g pnpm@9.0.0

# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ dependencies
pnpm install
```

### 2. à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Environment Variables

à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ `.env.local` à¹ƒà¸™ `apps/demo/`:

```env
# HeyGen LiveAvatar (à¸ˆà¸³à¹€à¸›à¹‡à¸™)
LIVEAVATAR_API_KEY=your_heygen_api_key
LIVEAVATAR_AVATAR_ID=dd73ea75-1218-4ef3-92ce-606d5f7fbc0a

# à¸ªà¸³à¸«à¸£à¸±à¸š FULL mode (optional)
LIVEAVATAR_VOICE_ID=your_voice_id
LIVEAVATAR_CONTEXT_ID=your_context_id
LIVEAVATAR_LANGUAGE=en

# à¸ªà¸³à¸«à¸£à¸±à¸š CUSTOM mode (à¸ˆà¸³à¹€à¸›à¹‡à¸™)
OPENAI_API_KEY=your_openai_api_key
ELEVENLABS_API_KEY=your_elevenlabs_api_key
ELEVENLABS_VOICE_ID=pqHfZKP75CvOlQylNhV4
ELEVENLABS_MODEL=eleven_v3
```

### 3. à¸£à¸±à¸™à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„

```bash
# à¸£à¸±à¸™ Demo application
pnpm demo

# à¸«à¸£à¸·à¸­à¸£à¸±à¸™ Development mode
pnpm dev

# Build à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„
pnpm build
```

à¹€à¸›à¸´à¸”à¹€à¸šà¸£à¸²à¸§à¹Œà¹€à¸‹à¸­à¸£à¹Œà¸—à¸µà¹ˆ http://localhost:3000

---

# IMPLEMENTATION FLOW

## PHASE 1: Session Management âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

**Status:** âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ - à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¸—à¸±à¹‰à¸‡ FULL à¹à¸¥à¸° CUSTOM mode

### à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™

Phase à¸™à¸µà¹‰à¸ˆà¸±à¸”à¸à¸²à¸£ Session lifecycle à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”:

1. **Start Session (FULL/CUSTOM Mode)** - à¸ªà¸£à¹‰à¸²à¸‡ session token à¸ˆà¸²à¸ HeyGen API
   - FULL Mode: à¸¡à¸µ avatar_persona (voice_id, context_id, language)
   - CUSTOM Mode: à¹„à¸¡à¹ˆà¸¡à¸µ avatar_persona (à¸„à¸§à¸šà¸„à¸¸à¸¡à¹€à¸­à¸‡)

2. **Keep Session Alive** - à¸•à¹ˆà¸­à¸­à¸²à¸¢à¸¸ session à¸—à¸¸à¸ 5 à¸™à¸²à¸—à¸µ (à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ timeout)

3. **Stop Session** - à¸›à¸´à¸” session à¹à¸¥à¸° cleanup resources

4. **WebSocket Connection** - à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ WebSocket à¸ªà¸³à¸«à¸£à¸±à¸š CUSTOM mode (à¸ªà¹ˆà¸‡à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸„à¸§à¸šà¸„à¸¸à¸¡ Avatar)

### Files Implemented

- API: `apps/demo/app/api/start-session/route.ts` âœ…
- API: `apps/demo/app/api/start-custom-session/route.ts` âœ…
- API: `apps/demo/app/api/keep-session-alive/route.ts` âœ…
- API: `apps/demo/app/api/stop-session/route.ts` âœ…
- Hook: `apps/demo/src/liveavatar/useSession.ts` âœ…

### à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š

```bash
# 1. à¸—à¸”à¸ªà¸­à¸šà¸”à¹‰à¸§à¸¢ Postman
POST http://localhost:3000/api/start-session

# 2. à¸—à¸”à¸ªà¸­à¸šà¸”à¹‰à¸§à¸¢ HTML (Optional)
# à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ: public/test-session-lifecycle.html
# à¹€à¸›à¸´à¸”: http://localhost:3000/test-session-lifecycle.html

# 3. à¸—à¸”à¸ªà¸­à¸šà¹ƒà¸™à¹à¸­à¸à¸«à¸¥à¸±à¸
pnpm dev
# à¹€à¸›à¸´à¸” http://localhost:3000 â†’ Start Session
```

---

## PHASE 2: Voice Chat (FULL Mode) âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

**Status:** âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ - à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¹€à¸•à¹‡à¸¡à¸£à¸¹à¸›à¹à¸šà¸š

### à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™

FULL Mode à¹ƒà¸Šà¹‰ HeyGen à¸ˆà¸±à¸”à¸à¸²à¸£ Voice Chat à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”:

1. **Voice Chat Start** - à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™ voice chat à¸à¸£à¹‰à¸­à¸¡ microphone access
2. **Real-time STT** - HeyGen à¹à¸›à¸¥à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡
3. **AI Response** - HeyGen generate à¸„à¸³à¸•à¸­à¸šà¸”à¹‰à¸§à¸¢ built-in AI
4. **TTS & Lip-sync** - HeyGen à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¹à¸¥à¸°à¸—à¸³ lip-sync
5. **Microphone Control** - Mute/Unmute/Stop

### Flow

```
User Speaks â†’ HeyGen STT â†’ HeyGen AI â†’ HeyGen TTS â†’ Avatar Speaks
           (All handled by HeyGen internally)
```

### Files Implemented

- Hook: `apps/demo/src/liveavatar/useVoiceChat.ts` âœ…
- Component: `apps/demo/src/components/LiveAvatarSession.tsx` âœ…

### à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š

```bash
pnpm dev
# à¹€à¸›à¸´à¸” http://localhost:3000
# 1. à¹€à¸¥à¸·à¸­à¸ "FULL Mode"
# 2. à¸à¸” "Start Session"
# 3. à¸à¸” "Start Voice Chat"
# 4. à¸à¸¹à¸”à¸­à¸°à¹„à¸£à¸à¹‡à¹„à¸”à¹‰ â†’ Avatar à¸„à¸§à¸£à¸•à¸­à¸šà¸à¸¥à¸±à¸š
```

---

## PHASE 3: Custom Voice Chat (CUSTOM Mode) âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

**Status:** âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ - à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¹€à¸•à¹‡à¸¡à¸£à¸¹à¸›à¹à¸šà¸š

### à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™

CUSTOM Mode à¹ƒà¸«à¹‰à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸„à¸§à¸šà¸„à¸¸à¸¡ AI à¹à¸¥à¸° TTS à¹€à¸­à¸‡:

1. **Audio Recording** - à¸šà¸±à¸™à¸—à¸¶à¸à¹€à¸ªà¸µà¸¢à¸‡à¸”à¹‰à¸§à¸¢ Web Audio API (AudioWorklet)
2. **Speech-to-Text** - OpenAI Whisper à¹à¸›à¸¥à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ (batch)
3. **AI Chat** - OpenAI GPT-4o-mini generate à¸„à¸³à¸•à¸­à¸š
4. **Text-to-Speech** - ElevenLabs à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¸µà¸¢à¸‡ (PCM 24kHz)
5. **Avatar Lip-sync** - à¸ªà¹ˆà¸‡à¹€à¸ªà¸µà¸¢à¸‡à¹„à¸› HeyGen à¸œà¹ˆà¸²à¸™ WebSocket (chunks 20ms)

### Flow

```
User Speaks â†’ AudioWorklet â†’ Whisper STT â†’ OpenAI Chat â†’ ElevenLabs TTS â†’ Avatar Speaks
                                                                            (WebSocket chunks)
```

### Files Implemented

- Hook: `apps/demo/src/liveavatar/useCustomVoiceChat.ts` âœ…
- Hook: `apps/demo/src/liveavatar/useTextChat.ts` âœ…
- API: `apps/demo/app/api/openai-whisper-stt/route.ts` âœ…
- API: `apps/demo/app/api/openai-chat-complete/route.ts` âœ…
- API: `apps/demo/app/api/elevenlabs-text-to-speech/route.ts` âœ…
- Audio Processor: `apps/demo/public/audio-processor.js` âœ…
- SDK: `packages/js-sdk/src/audio_utils.ts` âœ…

### à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š

```bash
pnpm dev
# à¹€à¸›à¸´à¸” http://localhost:3000
# 1. à¹€à¸¥à¸·à¸­à¸ "CUSTOM Mode"
# 2. à¸à¸” "Start Session"
# 3. à¸à¸” "Start Recording" (Push-to-talk)
# 4. à¸à¸¹à¸”à¸­à¸°à¹„à¸£à¸à¹‡à¹„à¸”à¹‰
# 5. à¸à¸” "Stop Recording"
# 6. à¸£à¸°à¸šà¸šà¸ˆà¸°: STT â†’ AI â†’ TTS â†’ Avatar à¸à¸¹à¸”
```

### API Testing

```bash
# Test Whisper STT
POST http://localhost:3000/api/openai-whisper-stt
Content-Type: multipart/form-data
Body: audio file

# Test OpenAI Chat
POST http://localhost:3000/api/openai-chat-complete
Content-Type: application/json
Body: {"message": "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š"}

# Test ElevenLabs TTS
POST http://localhost:3000/api/elevenlabs-text-to-speech
Content-Type: application/json
Body: {"text": "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š"}
```

---

## PHASE 4: ElevenLabs Realtime Speech-to-Text Integration âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§

**Status:** âœ… **100% Complete** - Logs-only mode à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¹à¸¥à¹‰à¸§
**Progress:**
- âœ… TASK 4.1: Single-Use Token API (à¸ªà¸³à¹€à¸£à¹‡à¸ˆ)
- âœ… TASK 4.2: Scribe SDK Integration (à¸ªà¸³à¹€à¸£à¹‡à¸ˆ)
- âœ… TASK 4.3: Logs-only Testing Mode (à¸ªà¸³à¹€à¸£à¹‡à¸ˆ)
- â¸ï¸ TASK 4.4: Full Avatar Integration (à¸à¸±à¸à¹„à¸§à¹‰à¸à¹ˆà¸­à¸™ - à¹€à¸›à¸´à¸” comment à¹„à¸”à¹‰à¹€à¸¡à¸·à¹ˆà¸­à¸•à¹‰à¸­à¸‡à¸à¸²à¸£)

**Current Mode:** Logs-only (à¹à¸ªà¸”à¸‡à¹à¸„à¹ˆ transcripts à¹ƒà¸™ console)

### à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¸¡à¸µ Phase à¸™à¸µà¹‰?

Phase 3 à¹ƒà¸Šà¹‰ OpenAI Whisper à¹à¸šà¸š **batch** (à¸•à¹‰à¸­à¸‡à¸£à¸­à¸šà¸±à¸™à¸—à¸¶à¸à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸ªà¸£à¹‡à¸ˆà¸à¹ˆà¸­à¸™) à¸—à¸³à¹ƒà¸«à¹‰à¸¡à¸µ latency à¸ªà¸¹à¸‡ (3-5 à¸§à¸´à¸™à¸²à¸—à¸µ)

Phase 4 à¸ˆà¸°à¹ƒà¸Šà¹‰ ElevenLabs Scribe **real-time streaming** à¸”à¹‰à¸§à¸¢ `@elevenlabs/client` SDK à¸—à¸³à¹ƒà¸«à¹‰:
- âœ… à¸¡à¸µ partial transcripts (à¹€à¸«à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹à¸šà¸š real-time à¸‚à¸“à¸°à¸à¸¹à¸”)
- âœ… à¸¥à¸” latency à¹€à¸«à¸¥à¸·à¸­ <500ms
- âœ… à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸‡à¹ˆà¸²à¸¢à¸”à¹‰à¸§à¸¢ official SDK (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸ˆà¸±à¸”à¸à¸²à¸£ WebSocket à¹€à¸­à¸‡)
- âœ… Built-in microphone streaming à¹à¸¥à¸° audio processing

### à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸—à¸³

1. âœ… **API Endpoint**: `/api/elevenlabs-stt-token` - **à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§**
   - Generate single-use token à¸ªà¸³à¸«à¸£à¸±à¸š authentication
   - Token à¸«à¸¡à¸”à¸­à¸²à¸¢à¸¸à¹ƒà¸™ 15 à¸™à¸²à¸—à¸µ
   - HTML test page: `http://localhost:3000/test-elevenlabs-stt-token.html`

2. âš ï¸ **Scribe SDK Integration** - **à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸—à¸³**
   - à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ `@elevenlabs/client` package
   - à¹ƒà¸Šà¹‰ `Scribe.connect()` à¸à¸±à¸š microphone streaming
   - à¸ˆà¸±à¸”à¸à¸²à¸£ events à¹à¸¥à¸° transcripts

3. âš ï¸ **Avatar Integration** - **à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸—à¸³**
   - à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ final transcripts à¸à¸±à¸š OpenAI Chat
   - à¸ªà¹ˆà¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹„à¸›à¸¢à¸±à¸‡ Avatar

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Microphone   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (Built-in streaming)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ @elevenlabs/client           â”‚
â”‚ Scribe.connect()             â”‚
â”‚ - Auto audio processing      â”‚
â”‚ - PCM 16kHz encoding         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (WebSocket - handled by SDK)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ElevenLabs Scribe API        â”‚ â† wss://api.elevenlabs.io/v1/speech-to-text/realtime
â”‚ (Scribe v2 Realtime)         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â†’ PARTIAL_TRANSCRIPT (à¸‚à¸“à¸°à¸à¸¹à¸”)
       â””â”€â†’ COMMITTED_TRANSCRIPT (à¸à¸¹à¸”à¹€à¸ªà¸£à¹‡à¸ˆ)
```

### TASK 4.1: à¸ªà¸£à¹‰à¸²à¸‡ API Endpoint à¸ªà¸³à¸«à¸£à¸±à¸š Single-Use Token âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§

**Status:** âœ… **à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§** - API endpoint à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

**à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡:** `apps/demo/app/api/elevenlabs-stt-token/route.ts` âœ…

```typescript
import { NextResponse } from 'next/server';
import { ELEVENLABS_API_KEY } from '../secrets';

export async function POST() {
  try {
    const response = await fetch(
      'https://api.elevenlabs.io/v1/single-use-token/realtime_scribe',
      {
        method: 'POST',
        headers: { 'xi-api-key': ELEVENLABS_API_KEY }
      }
    );

    if (!response.ok) {
      throw new Error(`ElevenLabs API error: ${response.statusText}`);
    }

    const data = await response.json();
    return NextResponse.json({
      token: data.token,
      expires_at: data.expires_at
    });
  } catch (error) {
    console.error('Error generating token:', error);
    return NextResponse.json(
      { error: 'Failed to generate token' },
      { status: 500 }
    );
  }
}
```

**à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š:**

1. **à¸”à¹‰à¸§à¸¢ HTML Test Page (à¹à¸™à¸°à¸™à¸³):**
```bash
# à¸£à¸±à¸™à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„
pnpm dev

# à¹€à¸›à¸´à¸” test page
http://localhost:3000/test-elevenlabs-stt-token.html

# à¸„à¸¥à¸´à¸ "Generate Token" â†’ à¸”à¸¹à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹à¸¥à¸° countdown
```

2. **à¸”à¹‰à¸§à¸¢ Postman:**
```bash
POST http://localhost:3000/api/elevenlabs-stt-token

# Expected Response:
{
  "token": "eyJhbGci...",
  "expires_at": "2025-01-15T10:30:00Z"
}
```

**à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¹„à¸”à¹‰:**
- âœ… API endpoint à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡ single-use token
- âœ… Token à¸«à¸¡à¸”à¸­à¸²à¸¢à¸¸à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¹ƒà¸™ 15 à¸™à¸²à¸—à¸µ
- âœ… HTML test page à¸à¸£à¹‰à¸­à¸¡ countdown timer
- âœ… à¸£à¸±à¸à¸©à¸² API key à¹„à¸§à¹‰à¸šà¸™ backend (à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢)

---

### TASK 4.2: à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¹à¸¥à¸°à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ ElevenLabs Client SDK âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§

**Status:** âœ… **à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§** - Hook à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

#### Step 1: à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ Dependencies âœ…

```bash
# à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ ElevenLabs Client SDK
pnpm add @elevenlabs/client
# âœ… à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ - Version 0.10.0 installed
```

#### Step 2: Configure the SDK with Microphone Streaming âœ…

**à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¹‰à¸§:** `apps/demo/src/liveavatar/useElevenLabsRealtimeSTT.ts` âœ…

```typescript
import { useRef, useState, useCallback, useEffect } from 'react';
import { Scribe, AudioFormat, RealtimeEvents, CommitStrategy } from "@elevenlabs/client";

interface ScribeConfig {
  languageCode?: string;
  onPartialTranscript?: (text: string) => void;
  onFinalTranscript?: (text: string, timestamps?: any) => void;
  onError?: (error: any) => void;
}

export function useElevenLabsRealtimeSTT(config: ScribeConfig = {}) {
  const [isConnected, setIsConnected] = useState(false);
  const [partialText, setPartialText] = useState('');
  const [finalText, setFinalText] = useState('');
  const connectionRef = useRef<any>(null);

  const connect = useCallback(async () => {
    try {
      // 1. Get single-use token from backend
      const tokenRes = await fetch('/api/elevenlabs-stt-token', {
        method: 'POST'
      });
      const { token } = await tokenRes.json();

      // 2. Connect with Scribe SDK
      const connection = Scribe.connect({
        token,
        modelId: "scribe_v2_realtime",
        languageCode: config.languageCode || "th",
        audioFormat: AudioFormat.PCM_16000,
        commitStrategy: CommitStrategy.VAD,
        vadSilenceThresholdSecs: 1.5,
        vadThreshold: 0.4,
        minSpeechDurationMs: 100,
        minSilenceDurationMs: 100,
        microphone: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      });

      connectionRef.current = connection;

      // 3. Handle events
      connection.on(RealtimeEvents.SESSION_STARTED, () => {
        console.log('ElevenLabs Scribe session started');
        setIsConnected(true);
      });

      connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data: any) => {
        console.log('Partial:', data.text);
        setPartialText(data.text);
        config.onPartialTranscript?.(data.text);
      });

      connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data: any) => {
        console.log('Final:', data.text);
        setFinalText(prev => prev + ' ' + data.text);
        config.onFinalTranscript?.(data.text);
        setPartialText('');
      });

      connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS, (data: any) => {
        console.log('Final with timestamps:', data);
        config.onFinalTranscript?.(data.text, data.timestamps);
      });

      connection.on(RealtimeEvents.ERROR, (error: any) => {
        console.error('Scribe error:', error);
        config.onError?.(error);
      });

      connection.on(RealtimeEvents.AUTH_ERROR, (error: any) => {
        console.error('Auth error:', error);
        config.onError?.(error);
      });

      connection.on(RealtimeEvents.CLOSE, () => {
        console.log('Connection closed');
        setIsConnected(false);
      });

    } catch (error) {
      console.error('Failed to connect:', error);
      config.onError?.(error);
    }
  }, [config]);

  const disconnect = useCallback(() => {
    if (connectionRef.current) {
      connectionRef.current.close();
      connectionRef.current = null;
    }
    setIsConnected(false);
    setPartialText('');
  }, []);

  const reset = useCallback(() => {
    setFinalText('');
    setPartialText('');
  }, []);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      disconnect();
    };
  }, [disconnect]);

  return {
    isConnected,
    partialText,
    finalText,
    connect,
    disconnect,
    reset
  };
}
```

#### Step 3: Audio Format Configuration

SDK à¸ˆà¸°à¸ˆà¸±à¸”à¸à¸²à¸£ audio processing à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´:
- **Sample Rate**: 16kHz (PCM_16000) - à¹à¸™à¸°à¸™à¸³à¹€à¸à¸·à¹ˆà¸­à¸„à¸§à¸²à¸¡à¸ªà¸¡à¸”à¸¸à¸¥à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸„à¸¸à¸“à¸ à¸²à¸à¹à¸¥à¸°à¹à¸šà¸™à¸”à¹Œà¸§à¸´à¸˜
- **Encoding**: 16-bit PCM, little-endian
- **Channels**: Mono only
- **Echo Cancellation**: à¹€à¸›à¸´à¸”à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
- **Noise Suppression**: à¹€à¸›à¸´à¸”à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
- **Auto Gain Control**: à¹€à¸›à¸´à¸”à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´

#### Step 4: Commit Strategy

**Voice Activity Detection (VAD)** - à¹à¸™à¸°à¸™à¸³à¸ªà¸³à¸«à¸£à¸±à¸š real-time:
- `vadSilenceThresholdSecs: 1.5` - à¹€à¸§à¸¥à¸²à¹€à¸‡à¸µà¸¢à¸šà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸à¹ˆà¸­à¸™ commit (0.3-3.0)
- `vadThreshold: 0.4` - à¸„à¸§à¸²à¸¡à¹„à¸§à¹ƒà¸™à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¹€à¸ªà¸µà¸¢à¸‡ (0.1-0.9, à¸•à¹ˆà¸³ = à¹„à¸§à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™)
- `minSpeechDurationMs: 100` - à¸£à¸°à¸¢à¸°à¹€à¸§à¸¥à¸²à¸à¸¹à¸”à¸‚à¸±à¹‰à¸™à¸•à¹ˆà¸³ (50-2000ms)
- `minSilenceDurationMs: 100` - à¸£à¸°à¸¢à¸°à¹€à¸§à¸¥à¸²à¹€à¸‡à¸µà¸¢à¸šà¸‚à¸±à¹‰à¸™à¸•à¹ˆà¸³ (50-2000ms)

---

### TASK 4.3: Logs-only Testing Mode âœ… à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§

**Status:** âœ… **à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§** - à¹à¸ªà¸”à¸‡ transcripts à¹ƒà¸™ console à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™

**Current Implementation:** Integration à¸à¸±à¸š Avatar à¹à¸¥à¸° OpenAI Chat à¸–à¸¹à¸ comment à¹„à¸§à¹‰ à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸—à¸”à¸ªà¸­à¸š Realtime STT à¹„à¸”à¹‰à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸¡à¸µ OpenAI/ElevenLabs API keys

#### à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Hook à¹ƒà¸™ Component (LOGS ONLY MODE) âœ…

**à¹à¸à¹‰à¹„à¸‚à¹„à¸Ÿà¸¥à¹Œ:** `apps/demo/src/components/LiveAvatarSession.tsx` âœ…

```typescript
import { useElevenLabsRealtimeSTT } from '../liveavatar/useElevenLabsRealtimeSTT';

function LiveAvatarSessionComponent() {
  // Setup Realtime STT - LOGS ONLY MODE (No OpenAI/TTS integration)
  const {
    isConnected: isRealtimeSTTConnected,
    partialText: realtimePartialText,
    finalText: realtimeFinalText,
    connect: connectRealtimeSTT,
    disconnect: disconnectRealtimeSTT,
    reset: resetRealtimeSTT,
  } = useElevenLabsRealtimeSTT({
    languageCode: 'th', // à¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸—à¸¢

    onPartialTranscript: (text) => {
      console.log('ğŸ¤ [REALTIME STT] Partial transcript:', text);
    },

    onFinalTranscript: async (text) => {
      console.log('âœ… [REALTIME STT] Final transcript:', text);
      console.log('ğŸ“Š [REALTIME STT] Transcript length:', text.length, 'characters');

      // TODO: Uncomment below to enable full voice-to-voice flow
      /*
      try {
        // 1. Send transcript to OpenAI Chat API
        const chatRes = await fetch('/api/openai-chat-complete', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ message: text })
        });
        const { response: aiResponse } = await chatRes.json();
        console.log('ğŸ¤– AI Response:', aiResponse);

        // 2. Convert AI response to speech using ElevenLabs TTS
        const ttsRes = await fetch('/api/elevenlabs-text-to-speech', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ text: aiResponse })
        });
        const { audio } = await ttsRes.json();
        console.log('ğŸ”Š TTS Audio generated');

        // 3. Send audio to Avatar for lip-sync
        if (sessionRef.current) {
          await sessionRef.current.repeatAudio(audio);
          console.log('ğŸ‘„ Avatar speaking');
        }
      } catch (error) {
        console.error('âŒ Error in voice-to-voice flow:', error);
      }
      */
    },

    onError: (error) => {
      console.error('âŒ [REALTIME STT] Error:', error);
    }
  });

  return (
    <div>
      {/* Video */}
      <video ref={videoRef} autoPlay playsInline />

      {/* Realtime STT Controls */}
      <div className="border-t-2 border-yellow-400 pt-4">
        <h3 className="text-lg font-bold text-yellow-400">
          ElevenLabs Realtime STT (Continuous Voice Chat)
        </h3>
        <p>Connected: {isRealtimeSTTConnected ? "true" : "false"}</p>

        {/* Display Real-time Transcripts */}
        {realtimePartialText && (
          <p className="text-gray-400 italic">Partial: {realtimePartialText}</p>
        )}
        {realtimeFinalText && (
          <p className="text-white font-semibold">Transcript: {realtimeFinalText}</p>
        )}

        {/* Control Buttons */}
        <div className="flex gap-2 mt-2">
          <button
            onClick={() => {
              if (isRealtimeSTTConnected) {
                disconnectRealtimeSTT();
              } else {
                connectRealtimeSTT();
              }
            }}
            className={`px-6 py-3 rounded-md font-semibold ${
              isRealtimeSTTConnected
                ? "bg-red-500 text-white hover:bg-red-600"
                : "bg-green-500 text-white hover:bg-green-600"
            }`}
          >
            {isRealtimeSTTConnected ? "Stop Realtime Voice Chat" : "Start Realtime Voice Chat"}
          </button>
          <button onClick={resetRealtimeSTT} disabled={!isRealtimeSTTConnected}>
            Reset Transcript
          </button>
        </div>
      </div>
    </div>
  );
}
```

**à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¹„à¸”à¹‰:**
- âœ… Integration à¸à¸±à¸š LiveAvatarSession component
- âœ… UI controls à¸ªà¸³à¸«à¸£à¸±à¸š Start/Stop continuous voice chat
- âœ… à¹à¸ªà¸”à¸‡ partial à¹à¸¥à¸° final transcripts à¹à¸šà¸š real-time à¹ƒà¸™ console
- âœ… à¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸”à¹‰à¸§à¸¢ Scribe v2 Realtime
- ğŸ“ Voice-to-voice flow (OpenAI Chat â†’ TTS â†’ Avatar) à¸–à¸¹à¸ comment à¹„à¸§à¹‰ à¸à¸£à¹‰à¸­à¸¡ uncomment à¹€à¸¡à¸·à¹ˆà¸­à¸•à¹‰à¸­à¸‡à¸à¸²à¸£

#### Current Flow (Logs-only Mode)

```
User Speaks (Microphone)
         â†“
@elevenlabs/client SDK
  - Auto audio capture (PCM 16kHz)
  - Built-in audio processing
  - Echo cancellation
  - Noise suppression
         â†“
ElevenLabs Scribe API
  - PARTIAL_TRANSCRIPT (real-time)
  - COMMITTED_TRANSCRIPT (final)
         â†“
Browser Console (DevTools)
  - ğŸ¤ [REALTIME STT] Partial transcript: ...
  - âœ… [REALTIME STT] Final transcript: ...
  - ğŸ“Š [REALTIME STT] Transcript length: X characters
```

#### Future: Complete Voice-to-Voice Flow (Uncomment code to enable)

```
User Speaks â†’ ElevenLabs Scribe STT â†’ OpenAI Chat â†’ ElevenLabs TTS â†’ Avatar
                (Real-time)              (commented)      (commented)   (commented)
```

#### Best Practices

1. **Token Management**
   - Token à¸«à¸¡à¸”à¸­à¸²à¸¢à¸¸à¹ƒà¸™ 15 à¸™à¸²à¸—à¸µ
   - à¸„à¸§à¸£ implement token refresh mechanism à¸ªà¸³à¸«à¸£à¸±à¸š conversation à¸¢à¸²à¸§à¹†

2. **Error Handling**
   - à¸ˆà¸±à¸”à¸à¸²à¸£ `AUTH_ERROR`, `ERROR`, `QUOTA_EXCEEDED`
   - Implement reconnection logic with exponential backoff

3. **Audio Quality**
   - à¹ƒà¸Šà¹‰ PCM_16000 (16kHz) à¹€à¸à¸·à¹ˆà¸­ optimal performance
   - Enable echo cancellation à¹à¸¥à¸° noise suppression

4. **Chunk Size Strategy**
   - SDK à¸ˆà¸±à¸”à¸à¸²à¸£ chunk size à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
   - Processing à¹€à¸£à¸´à¹ˆà¸¡à¸«à¸¥à¸±à¸‡à¸ªà¹ˆà¸‡à¹€à¸ªà¸µà¸¢à¸‡ 2 à¸§à¸´à¸™à¸²à¸—à¸µà¹à¸£à¸

5. **VAD Configuration**
   - à¸›à¸£à¸±à¸š `vadSilenceThresholdSecs` à¸•à¸²à¸¡à¸¥à¸±à¸à¸©à¸“à¸°à¸à¸²à¸£à¸ªà¸™à¸—à¸™à¸²
   - à¸„à¹ˆà¸²à¸ªà¸¹à¸‡ = à¸£à¸­à¹ƒà¸«à¹‰à¹€à¸‡à¸µà¸¢à¸šà¸™à¸²à¸™à¸à¸§à¹ˆà¸², à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸›à¸£à¸°à¹‚à¸¢à¸„à¸¢à¸²à¸§
   - à¸„à¹ˆà¸²à¸•à¹ˆà¸³ = commit à¹€à¸£à¹‡à¸§à¸à¸§à¹ˆà¸², à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸š dialog à¸ªà¸±à¹‰à¸™à¹†

---

### Testing Phase 4 (Logs-only Mode)

**Requirements:**
- âœ… ELEVENLABS_API_KEY in `.env.local` (à¸ªà¸³à¸«à¸£à¸±à¸š token generation)
- âŒ OPENAI_API_KEY **à¹„à¸¡à¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™** (à¸–à¸¹à¸ comment à¹„à¸§à¹‰)
- âŒ ElevenLabs TTS API key **à¹„à¸¡à¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™** (à¸–à¸¹à¸ comment à¹„à¸§à¹‰)

---

**1. Test Token Generation API:**
```bash
# à¸—à¸”à¸ªà¸­à¸š Token endpoint
POST http://localhost:3012/api/elevenlabs-stt-token

# Expected Response:
{
  "token": "eyJhbGci...",
  "expires_at": "2025-01-15T12:00:00Z"
}
```

**2. Test Realtime STT (Recommended - Logs Only):**

**Quick Test (à¹à¸™à¸°à¸™à¸³):**

```bash
# 1. à¸£à¸±à¸™à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„
pnpm dev

# 2. à¹€à¸›à¸´à¸”à¹€à¸šà¸£à¸²à¸§à¹Œà¹€à¸‹à¸­à¸£à¹Œ
http://localhost:3012
```

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™:**
1. à¹€à¸¥à¸·à¸­à¸ **CUSTOM Mode** â†’ à¸à¸” **Start Session**
2. à¹€à¸¥à¸·à¹ˆà¸­à¸™à¸¥à¸‡à¸¡à¸²à¸«à¸² **"ElevenLabs Realtime STT"** section (à¸ªà¸µà¹€à¸«à¸¥à¸·à¸­à¸‡)
3. à¸à¸” **"Start Realtime Voice Chat"** (à¸›à¸¸à¹ˆà¸¡à¸ªà¸µà¹€à¸‚à¸µà¸¢à¸§)
4. à¸­à¸™à¸¸à¸à¸²à¸• **Microphone Access**
5. **à¸à¸¹à¸”à¸ à¸²à¸©à¸²à¹„à¸—à¸¢** à¹€à¸Šà¹ˆà¸™ "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸—à¸”à¸ªà¸­à¸šà¸£à¸°à¸šà¸š"
6. **à¹€à¸›à¸´à¸” Browser Console (F12)** à¹€à¸à¸·à¹ˆà¸­à¸”à¸¹ logs

**Expected Console Output:**
```
ğŸ”Œ Starting connection to ElevenLabs Scribe...
âœ… Token received
ğŸ¤ Requesting microphone access...
ğŸ“¦ Connection object created
âœ… SESSION_STARTED - ElevenLabs Scribe session started
ğŸ™ï¸ You can now speak into your microphone...
ğŸ¤ [REALTIME STT] Partial transcript: à¸ªà¸§à¸±à¸ª
ğŸ¤ [REALTIME STT] Partial transcript: à¸ªà¸§à¸±à¸ªà¸”à¸µ
ğŸ¤ [REALTIME STT] Partial transcript: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š
âœ… [REALTIME STT] Final transcript: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸—à¸”à¸ªà¸­à¸šà¸£à¸°à¸šà¸š
ğŸ“Š [REALTIME STT] Transcript length: 28 characters
```

**à¹€à¸¡à¸·à¹ˆà¸­à¸à¸” "Stop Realtime Voice Chat" à¸«à¸£à¸·à¸­ Disconnect:**
```
ğŸ”Œ CONNECTION CLOSED
ğŸ“ [REALTIME STT] Combined full transcript: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸—à¸”à¸ªà¸­à¸šà¸£à¸°à¸šà¸š
ğŸ“Š [REALTIME STT] Total segments: 1
ğŸ“Š [REALTIME STT] Total length: 28 characters
```

**à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸:** à¸£à¸°à¸šà¸šà¸ˆà¸°à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸ˆà¸²à¸ COMMITTED_TRANSCRIPT events à¸•à¸¥à¸­à¸”à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ à¹à¸¥à¸°à¹à¸ªà¸”à¸‡à¸›à¸£à¸°à¹‚à¸¢à¸„à¸£à¸§à¸¡à¹€à¸¡à¸·à¹ˆà¸­à¸›à¸´à¸”à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­

**Expected UI Behavior:**
- âœ… "Connected: true" à¹à¸ªà¸”à¸‡à¹ƒà¸™ UI
- âœ… **Partial text** (à¸ªà¸µà¹€à¸—à¸², italic) à¸­à¸±à¸à¹€à¸”à¸•à¹à¸šà¸š real-time à¸‚à¸“à¸°à¸à¸¹à¸”
- âœ… **Final text** (à¸ªà¸µà¸‚à¸²à¸§, bold) à¹à¸ªà¸”à¸‡à¸«à¸¥à¸±à¸‡à¹€à¸‡à¸µà¸¢à¸š ~1.5 à¸§à¸´à¸™à¸²à¸—à¸µ
- âŒ **Avatar à¸ˆà¸°à¹„à¸¡à¹ˆà¸•à¸­à¸šà¸à¸¥à¸±à¸š** (à¹€à¸à¸£à¸²à¸° OpenAI/TTS à¸–à¸¹à¸ comment à¹„à¸§à¹‰)

---

**3. Test SDK Integration (Browser Console - Advanced):**

à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸ `@elevenlabs/client` à¸–à¸¹à¸à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡à¹€à¸›à¹‡à¸™ dependency à¸‚à¸­à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„à¹à¸¥à¹‰à¸§ à¸„à¸¸à¸“à¸ªà¸²à¸¡à¸²à¸£à¸–à¸—à¸”à¸ªà¸­à¸š SDK à¹„à¸”à¹‰à¹‚à¸”à¸¢à¸•à¸£à¸‡à¹ƒà¸™ Browser Console

**à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š:**

1. **à¸£à¸±à¸™à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„à¹ƒà¸™à¹‚à¸«à¸¡à¸” Development:**
```bash
pnpm dev
# à¹€à¸›à¸´à¸” http://localhost:3012
```

2. **à¹€à¸›à¸´à¸” Browser DevTools Console** (F12 à¸«à¸£à¸·à¸­ Ctrl+Shift+J)

3. **à¸§à¸²à¸‡ Code à¸™à¸µà¹‰à¹ƒà¸™ Console à¹€à¸à¸·à¹ˆà¸­à¸—à¸”à¸ªà¸­à¸š SDK:**

```javascript
// Step 1: Import SDK à¸ˆà¸²à¸ node_modules
// à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: à¹ƒà¸™ Browser Console à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰ import à¹„à¸”à¹‰à¹‚à¸”à¸¢à¸•à¸£à¸‡
// à¹à¸•à¹ˆ SDK à¸ˆà¸°à¸–à¸¹à¸ bundle à¸¡à¸²à¸à¸±à¸šà¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„à¹à¸¥à¹‰à¸§à¸–à¹‰à¸²à¸„à¸¸à¸“à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸«à¸™à¹‰à¸² Next.js app

// à¸§à¸´à¸˜à¸µà¸—à¸”à¸ªà¸­à¸šà¸—à¸µà¹ˆà¸‡à¹ˆà¸²à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸”: à¹ƒà¸Šà¹‰ dynamic import
(async () => {
  // Step 2: Get single-use token à¸ˆà¸²à¸ backend API
  console.log('ğŸ”‘ Requesting token...');
  const tokenRes = await fetch('/api/elevenlabs-stt-token', {
    method: 'POST'
  });
  const { token, expires_at } = await tokenRes.json();
  console.log('âœ… Token received:', { token: token.substring(0, 20) + '...', expires_at });

  // Step 3: Import ElevenLabs SDK dynamically
  const { Scribe, AudioFormat, RealtimeEvents, CommitStrategy } =
    await import('@elevenlabs/client');

  console.log('ğŸ“¦ SDK imported successfully');

  // Step 4: Connect with Scribe SDK (with microphone access)
  console.log('ğŸ¤ Requesting microphone access...');

  const connection = Scribe.connect({
    token,
    modelId: "scribe_v2_realtime",
    languageCode: "th", // à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ (à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸›à¹‡à¸™ "en", "ja" à¹„à¸”à¹‰à¸•à¸²à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£)
    audioFormat: AudioFormat.PCM_16000,
    commitStrategy: CommitStrategy.VAD,
    vadSilenceThresholdSecs: 1.5,
    vadThreshold: 0.4,
    minSpeechDurationMs: 100,
    minSilenceDurationMs: 100,
  });

  console.log('ğŸ”Œ Connection object created:', connection);

  // Step 5: Listen to events
  connection.on(RealtimeEvents.SESSION_STARTED, () => {
    console.log('âœ… SESSION_STARTED - Scribe session started!');
    console.log('ğŸ™ï¸ You can now speak into your microphone...');
  });

  connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data) => {
    console.log('ğŸ¤ PARTIAL_TRANSCRIPT (real-time):', data.text);
  });

  connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {
    console.log('âœ… COMMITTED_TRANSCRIPT (final):', data.text);
  });

  connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS, (data) => {
    console.log('ğŸ“ COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS:', {
      text: data.text,
      timestamps: data.timestamps
    });
  });

  connection.on(RealtimeEvents.ERROR, (error) => {
    console.error('âŒ ERROR:', error);
  });

  connection.on(RealtimeEvents.AUTH_ERROR, (error) => {
    console.error('ğŸš« AUTH_ERROR:', error);
  });

  connection.on(RealtimeEvents.CLOSE, () => {
    console.log('ğŸ”Œ CONNECTION CLOSED');
  });

  // Store connection in window for manual control
  window.elevenLabsConnection = connection;
  console.log('ğŸ’¾ Connection saved to window.elevenLabsConnection');
  console.log('ğŸ“ You can now:');
  console.log('   - Speak into your microphone to see transcripts');
  console.log('   - Close connection: window.elevenLabsConnection.close()');
})();
```

4. **à¸­à¸™à¸¸à¸à¸²à¸•à¹ƒà¸«à¹‰à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡ Microphone** à¹€à¸¡à¸·à¹ˆà¸­ Browser à¸‚à¸­ permission

5. **à¸à¸¹à¸”à¸­à¸°à¹„à¸£à¸à¹‡à¹„à¸”à¹‰à¸ à¸²à¸©à¸²à¹„à¸—à¸¢** à¹€à¸Šà¹ˆà¸™ "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š", "à¸—à¸”à¸ªà¸­à¸šà¸£à¸°à¸šà¸š"

**à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸—à¸µà¹ˆà¸„à¸§à¸£à¹€à¸«à¹‡à¸™à¹ƒà¸™ Console:**
```
ğŸ”‘ Requesting token...
âœ… Token received: { token: 'eyJhbGci...', expires_at: '2025-01-15T12:00:00Z' }
ğŸ“¦ SDK imported successfully
ğŸ¤ Requesting microphone access...
ğŸ”Œ Connection object created: [Object]
ğŸ’¾ Connection saved to window.elevenLabsConnection
ğŸ“ You can now:
   - Speak into your microphone to see transcripts
   - Close connection: window.elevenLabsConnection.close()
âœ… SESSION_STARTED - Scribe session started!
ğŸ™ï¸ You can now speak into your microphone...
ğŸ¤ PARTIAL_TRANSCRIPT (real-time): à¸ªà¸§à¸±à¸ª
ğŸ¤ PARTIAL_TRANSCRIPT (real-time): à¸ªà¸§à¸±à¸ªà¸”à¸µ
ğŸ¤ PARTIAL_TRANSCRIPT (real-time): à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š
âœ… COMMITTED_TRANSCRIPT (final): à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š
```

**à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡à¸ªà¸³à¸«à¸£à¸±à¸š Testing:**

```javascript
// à¸›à¸´à¸” connection
window.elevenLabsConnection.close();

// à¸”à¸¹ connection state
console.log(window.elevenLabsConnection);

// à¸—à¸”à¸ªà¸­à¸š error handling - à¹ƒà¸Šà¹‰ expired token
// (à¸£à¸­ 15 à¸™à¸²à¸—à¸µà¸«à¸£à¸·à¸­à¹ƒà¸Šà¹‰ token à¹€à¸à¹ˆà¸²)
```

**Troubleshooting:**

- **à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¹€à¸«à¹‡à¸™ partial transcripts:** à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² microphone access à¹„à¸”à¹‰à¸£à¸±à¸šà¸­à¸™à¸¸à¸à¸²à¸•à¹à¸¥à¹‰à¸§
- **à¸–à¹‰à¸²à¹€à¸«à¹‡à¸™ AUTH_ERROR:** Token à¸«à¸¡à¸”à¸­à¸²à¸¢à¸¸ (15 à¸™à¸²à¸—à¸µ) à¹ƒà¸«à¹‰à¸‚à¸­ token à¹ƒà¸«à¸¡à¹ˆ
- **à¸–à¹‰à¸²à¹€à¸«à¹‡à¸™ ERROR:** à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š ELEVENLABS_API_KEY à¹ƒà¸™à¹„à¸Ÿà¸¥à¹Œ `.env.local`
- **à¸–à¹‰à¸² import à¹„à¸¡à¹ˆà¹„à¸”à¹‰:** à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸£à¸±à¸™à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„à¹à¸¥à¹‰à¸§à¹à¸¥à¸°à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸«à¸™à¹‰à¸² Next.js app

---

---

**4. How to Enable Full Voice-to-Voice Flow:**

à¹€à¸¡à¸·à¹ˆà¸­à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹ƒà¸«à¹‰ Avatar à¸•à¸­à¸šà¸à¸¥à¸±à¸šà¸”à¹‰à¸§à¸¢à¹€à¸ªà¸µà¸¢à¸‡ à¹ƒà¸«à¹‰à¸—à¸³à¸•à¸²à¸¡à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸™à¸µà¹‰:

1. **à¹€à¸à¸´à¹ˆà¸¡ API Keys** à¹ƒà¸™ `.env.local`:
```env
OPENAI_API_KEY=your_openai_api_key
ELEVENLABS_VOICE_ID=pqHfZKP75CvOlQylNhV4
```

2. **Uncomment code** à¹ƒà¸™ `apps/demo/src/components/LiveAvatarSession.tsx`:
   - à¹„à¸›à¸—à¸µà¹ˆà¸šà¸£à¸£à¸—à¸±à¸” ~100-129
   - à¸¥à¸š `/*` à¹à¸¥à¸° `*/` à¸­à¸­à¸
   - à¸šà¸±à¸™à¸—à¸¶à¸à¹„à¸Ÿà¸¥à¹Œ

3. **Restart dev server**:
```bash
# à¸à¸” Ctrl+C à¹€à¸à¸·à¹ˆà¸­à¸«à¸¢à¸¸à¸” server
pnpm dev
```

4. **à¸—à¸”à¸ªà¸­à¸šà¸­à¸µà¸à¸„à¸£à¸±à¹‰à¸‡** - à¸•à¸­à¸™à¸™à¸µà¹‰ Avatar à¸ˆà¸°à¸•à¸­à¸šà¸à¸¥à¸±à¸šà¸”à¹‰à¸§à¸¢à¹€à¸ªà¸µà¸¢à¸‡à¹à¸¥à¹‰à¸§

**Expected Console Output (Full Flow):**
```
ğŸ¤ [REALTIME STT] Partial transcript: à¸ªà¸§à¸±à¸ª
ğŸ¤ [REALTIME STT] Partial transcript: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š
âœ… [REALTIME STT] Final transcript: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š
ğŸ“Š [REALTIME STT] Transcript length: 12 characters
ğŸ¤– AI Response: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸¡à¸µà¸­à¸°à¹„à¸£à¹ƒà¸«à¹‰à¸Šà¹ˆà¸§à¸¢à¹„à¸«à¸¡?
ğŸ”Š TTS Audio generated
ğŸ‘„ Avatar speaking
```

---

**5. Troubleshooting (Logs-only Mode):**

**à¸›à¸±à¸à¸«à¸²: à¹„à¸¡à¹ˆà¹€à¸«à¹‡à¸™ logs à¹ƒà¸™ console**
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹€à¸›à¸´à¸” Browser Console (F12) à¹à¸¥à¹‰à¸§
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸à¸”à¸›à¸¸à¹ˆà¸¡ "Start Realtime Voice Chat" à¹à¸¥à¹‰à¸§
- à¸”à¸¹à¸§à¹ˆà¸²à¸¡à¸µ error à¹ƒà¸™ console à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ

**à¸›à¸±à¸à¸«à¸²: Microphone permission denied**
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š browser settings â†’ Site permissions â†’ Microphone
- à¸¥à¸­à¸‡ refresh page à¹à¸¥à¸°à¸­à¸™à¸¸à¸à¸²à¸•à¹ƒà¸«à¸¡à¹ˆ

**à¸›à¸±à¸à¸«à¸²: AUTH_ERROR**
- Token à¸«à¸¡à¸”à¸­à¸²à¸¢à¸¸ (15 à¸™à¸²à¸—à¸µ)
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š ELEVENLABS_API_KEY à¹ƒà¸™ `.env.local`
- Restart dev server

**à¸›à¸±à¸à¸«à¸²: à¹„à¸¡à¹ˆà¸¡à¸µ partial transcripts**
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸à¸¹à¸”à¸”à¸±à¸‡à¸à¸­
- à¸¥à¸­à¸‡ adjust `vadThreshold` à¹ƒà¸™ hook (à¸¥à¸”à¸„à¹ˆà¸²à¸¥à¸‡à¹€à¸›à¹‡à¸™ 0.2)
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² microphone à¸—à¸³à¸‡à¸²à¸™à¸”à¹‰à¸§à¸¢ "Hold to Talk" button

---

**Performance (Logs-only Mode):**
- **STT Latency**: < 500ms (real-time streaming)
- **Partial Transcript Update**: Real-time (à¸‚à¸“à¸°à¸à¸¹à¸”)
- **Final Transcript**: ~1.5 à¸§à¸´à¸™à¸²à¸—à¸µà¸«à¸¥à¸±à¸‡à¹€à¸‡à¸µà¸¢à¸š
- **Total**: à¸”à¸¹à¸œà¸¥à¹ƒà¸™ console à¸—à¸±à¸™à¸—à¸µ

**à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸š Whisper batch mode:**
| Metric | Whisper (PHASE 3) | ElevenLabs Realtime (PHASE 4 - Logs Only) |
|--------|-------------------|------------------------------------------|
| STT Method | Batch (à¸•à¹‰à¸­à¸‡à¸£à¸­à¸šà¸±à¸™à¸—à¸¶à¸à¹€à¸ªà¸£à¹‡à¸ˆ) | Real-time streaming |
| Partial Transcript | âŒ à¹„à¸¡à¹ˆà¸¡à¸µ | âœ… à¸¡à¸µ (à¹à¸šà¸š real-time) |
| User Experience | à¸à¸”à¸„à¹‰à¸²à¸‡ "Hold to Talk" | Continuous (à¸à¸¹à¸”à¹„à¸”à¹‰à¹€à¸£à¸·à¹ˆà¸­à¸¢à¹†) |
| STT Latency | 2-3 à¸§à¸´à¸™à¸²à¸—à¸µ | <500ms |
| Thai Support | âœ… Yes | âœ… Yes (Scribe v2) |
| Output | Text only | Console logs only (à¸•à¸­à¸™à¸™à¸µà¹‰) |

**4. Test Error Handling & Edge Cases:**

**Test Case 4.1: Expired Token (15 minutes)**
```javascript
// à¹ƒà¸™ Browser Console:
// 1. Start Realtime Voice Chat
// 2. à¸£à¸­ 15 à¸™à¸²à¸—à¸µ (à¸«à¸£à¸·à¸­ force expire à¹‚à¸”à¸¢à¹à¸à¹‰à¹„à¸‚ token)
// 3. à¸à¸¢à¸²à¸¢à¸²à¸¡à¸à¸¹à¸”à¹ƒà¸«à¸¡à¹ˆ

// Expected: à¹€à¸«à¹‡à¸™ AUTH_ERROR à¹ƒà¸™ console
// Console output:
// ğŸš« AUTH_ERROR: { message: "Token expired", code: 401 }
```

**Test Case 4.2: Network Disconnection**
```javascript
// 1. Start Realtime Voice Chat
// 2. à¹€à¸›à¸´à¸” DevTools â†’ Network tab â†’ Offline
// 3. à¸à¸¢à¸²à¸¢à¸²à¸¡à¸à¸¹à¸”

// Expected: à¹€à¸«à¹‡à¸™ ERROR à¹ƒà¸™ console
// Console output:
// âŒ ERROR: WebSocket connection failed
// ğŸ”Œ CONNECTION CLOSED
```

**Test Case 4.3: Microphone Permission Denied**
```javascript
// 1. Block microphone permission à¹ƒà¸™ browser settings
// 2. à¸à¸¢à¸²à¸¢à¸²à¸¡ Start Realtime Voice Chat

// Expected: Browser à¹à¸ªà¸”à¸‡ error, connection à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ
// Console output:
// âŒ Error in voice-to-voice flow: NotAllowedError: Permission denied
```

**Test Case 4.4: Invalid API Key**
```javascript
// 1. à¹à¸à¹‰à¹„à¸‚ ELEVENLABS_API_KEY à¹ƒà¸™ .env.local à¹ƒà¸«à¹‰à¸œà¸´à¸”
// 2. Restart dev server
// 3. à¸¥à¸­à¸‡ Start Realtime Voice Chat

// Expected:
// ğŸš« AUTH_ERROR: Invalid API key
```

**Test Case 4.5: Reconnection Logic**
```javascript
// à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£ reconnect à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
// à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: Hook à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ auto-reconnect
// à¸•à¹‰à¸­à¸‡ implement manually à¹‚à¸”à¸¢à¹€à¸à¸´à¹ˆà¸¡ reconnection logic

connection.on(RealtimeEvents.CLOSE, async () => {
  console.log('Connection closed, attempting reconnect...');
  // Wait 2 seconds before retry
  await new Promise(resolve => setTimeout(resolve, 2000));
  // Get new token and reconnect
  await connect();
});
```

---

**Testing Summary: Phase 4 - Logs-only Mode**

| Test Case | Status | Notes |
|-----------|--------|-------|
| **Token Generation API** | âœ… Passed | `/api/elevenlabs-stt-token` working |
| **SDK Installation** | âœ… Passed | `@elevenlabs/client` v0.10.0 installed with microphone config |
| **Hook Implementation** | âœ… Passed | `useElevenLabsRealtimeSTT.ts` with microphone capture |
| **UI Integration** | âœ… Passed | Controls added to LiveAvatarSession (logs-only) |
| **Browser Console Test** | âœ… Passed | Dynamic import & manual testing works |
| **Real-time STT** | âœ… Passed | Partial transcripts streaming to console |
| **Final Transcripts** | âœ… Passed | Committed after ~1.5s silence |
| **Console Logging** | âœ… Passed | `[REALTIME STT]` prefix for easy filtering |
| **OpenAI Chat Integration** | â¸ï¸ Commented | Ready to uncomment when needed |
| **ElevenLabs TTS Integration** | â¸ï¸ Commented | Ready to uncomment when needed |
| **Avatar Lip-sync** | â¸ï¸ Commented | Ready to uncomment when needed |
| **Thai Language Support** | âœ… Passed | Scribe v2 handles Thai correctly |
| **Error Handling** | âœ… Passed | Console error logging with `[REALTIME STT]` prefix |
| **Token Refresh** | âš ï¸ Not Implemented | Manual reconnect needed after 15 min |

**Overall Phase 4 Status: âœ… 100% Complete (Logs-only Mode)**

**What Works Now:**
- âœ… Real-time Speech-to-Text à¹à¸ªà¸”à¸‡à¸œà¸¥à¹ƒà¸™ console
- âœ… Partial transcripts à¹à¸šà¸š real-time
- âœ… Final transcripts à¸«à¸¥à¸±à¸‡à¹€à¸‡à¸µà¸¢à¸š ~1.5 à¸§à¸´à¸™à¸²à¸—à¸µ
- âœ… à¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸—à¸¢
- âœ… à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸¡à¸µ OpenAI/ElevenLabs TTS API keys
- âœ… **Combined transcript summary** - à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹à¸¥à¸°à¹à¸ªà¸”à¸‡à¹€à¸¡à¸·à¹ˆà¸­à¸›à¸´à¸”à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­
- âœ… **Auto transcript reset** - à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸£à¸µà¹€à¸‹à¹‡à¸•à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸£à¸´à¹ˆà¸¡ session à¹ƒà¸«à¸¡à¹ˆ
- âœ… **Voice-to-Voice with Avatar** - à¹€à¸›à¸´à¸”à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹à¸¥à¹‰à¸§ à¹‚à¸”à¸¢à¸ªà¹ˆà¸‡ combined transcript à¹„à¸›à¹ƒà¸«à¹‰ AI à¹à¸¥à¸° Avatar à¸•à¸­à¸šà¸à¸¥à¸±à¸šà¹€à¸›à¹‡à¸™à¹€à¸ªà¸µà¸¢à¸‡

**Voice-to-Voice Flow (ENABLED):**

à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™:
1. User à¸à¸”à¸›à¸¸à¹ˆà¸¡ "Start Realtime Voice Chat" à¹à¸¥à¸°à¸à¸¹à¸”à¹€à¸‚à¹‰à¸²à¹„à¸¡à¸„à¹Œ
2. ElevenLabs Scribe v2 Realtime à¸ˆà¸° transcribe à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹à¸šà¸š real-time
3. Transcripts à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸–à¸¹à¸à¸£à¸§à¸¡à¹€à¸à¹‡à¸šà¹„à¸§à¹‰à¹ƒà¸™ `allTranscriptsRef`
4. à¹€à¸¡à¸·à¹ˆà¸­ User à¸à¸”à¸›à¸¸à¹ˆà¸¡ "Stop & Process with Avatar" à¸£à¸°à¸šà¸šà¸ˆà¸°:
   - Disconnect à¸ˆà¸²à¸ ElevenLabs Realtime STT
   - à¸”à¸¶à¸‡ combined transcript à¸ˆà¸²à¸à¸—à¸±à¹‰à¸‡ session
   - à¸ªà¹ˆà¸‡à¹„à¸›à¹ƒà¸«à¹‰ OpenAI Chat API (`/api/openai-chat-complete`)
   - à¸™à¸³ AI response à¸¡à¸²à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™à¹€à¸ªà¸µà¸¢à¸‡à¸”à¹‰à¸§à¸¢ ElevenLabs TTS (`/api/elevenlabs-text-to-speech`)
   - à¸ªà¹ˆà¸‡ audio à¹„à¸›à¹ƒà¸«à¹‰ Avatar à¹€à¸à¸·à¹ˆà¸­à¸—à¸³ lip-sync (`sessionRef.current.repeatAudio()`)

**à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¹à¸à¹‰à¹„à¸‚:**
- `apps/demo/src/liveavatar/useElevenLabsRealtimeSTT.ts` - à¹€à¸à¸´à¹ˆà¸¡ `getCombinedTranscript()` function
- `apps/demo/src/components/LiveAvatarSession.tsx` - à¹€à¸à¸´à¹ˆà¸¡ `handleVoiceToVoice()` à¹à¸¥à¸°à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸à¸±à¸šà¸›à¸¸à¹ˆà¸¡ Stop

**Console Output à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡:**
```
ğŸ¤ [REALTIME STT] Partial transcript: à¸ªà¸§à¸±à¸ªà¸”à¸µ
âœ… [REALTIME STT] Final transcript: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š
ğŸ”Œ CONNECTION CLOSED
ğŸ“ [REALTIME STT] Combined full transcript: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š
ğŸš€ [V2V] Starting Voice-to-Voice flow...
ğŸ“ [V2V] Combined transcript: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š
ğŸ¤– [V2V] Sending to OpenAI...
âœ… [V2V] AI Response: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸¡à¸µà¸­à¸°à¹„à¸£à¹ƒà¸«à¹‰à¸œà¸¡à¸Šà¹ˆà¸§à¸¢à¹„à¸«à¸¡à¸„à¸£à¸±à¸š
ğŸ”Š [V2V] Converting to speech...
âœ… [V2V] TTS Audio generated
ğŸ‘„ [V2V] Sending to Avatar...
âœ… [V2V] Avatar speaking!
```

**à¸‚à¹‰à¸­à¸à¸³à¸«à¸™à¸”à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™:**
- âœ… à¸•à¹‰à¸­à¸‡à¸¡à¸µ `OPENAI_API_KEY` à¹ƒà¸™ `.env.local`
- âœ… à¸•à¹‰à¸­à¸‡à¸¡à¸µ `ELEVENLABS_API_KEY` à¹à¸¥à¸° `ELEVENLABS_VOICE_ID` à¹ƒà¸™ `.env.local`
- âœ… Avatar session à¸•à¹‰à¸­à¸‡ active à¸­à¸¢à¸¹à¹ˆ

**Next Steps (Optional):**
1. âœ… ~~Uncomment full voice-to-voice flow (OpenAI + TTS + Avatar)~~ - **à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§!**
2. ğŸ”„ Auto token refresh mechanism (before 15 min expiry)
3. ğŸ”„ Auto reconnection with exponential backoff
4. ğŸ”„ UI loading states during AI processing
5. ğŸ”„ Add "Process Now" button (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸­ disconnect)

---

## PHASE 5: WebSocket Integration for OpenAI Chat âš ï¸ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸—à¸³

**Status:** âš ï¸ **à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰ Implement** - à¸•à¹‰à¸­à¸‡à¸ªà¸£à¹‰à¸²à¸‡ Custom WebSocket Server
**Estimated Effort:** 5-7 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡

### à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¸¡à¸µ Phase à¸™à¸µà¹‰?

Phase 3 à¹ƒà¸Šà¹‰ OpenAI Chat à¹à¸šà¸š **REST API** (request/response à¹à¸¢à¸à¸à¸±à¸™) à¸—à¸³à¹ƒà¸«à¹‰:
- âŒ à¸•à¹‰à¸­à¸‡ establish connection à¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡ (overhead)
- âŒ à¹„à¸¡à¹ˆà¹€à¸à¹‡à¸š conversation history à¸šà¸™ server
- âŒ Latency à¸ªà¸¹à¸‡à¸à¸§à¹ˆà¸² WebSocket

Phase 5 à¸ˆà¸°à¹ƒà¸Šà¹‰ **WebSocket** à¸—à¸³à¹ƒà¸«à¹‰:
- âœ… Connection à¸„à¸‡à¸­à¸¢à¸¹à¹ˆà¸•à¸¥à¸­à¸” (persistent connection)
- âœ… à¸¥à¸” latency (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ handshake à¸‹à¹‰à¸³)
- âœ… Server à¸ˆà¸±à¸”à¸à¸²à¸£ conversation history

### à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¸•à¹‰à¸­à¸‡à¸ªà¸£à¹‰à¸²à¸‡

1. âŒ **Custom WebSocket Server**: `apps/demo/server/websocket-server.ts`
2. âŒ **React Hook**: `apps/demo/src/liveavatar/useWebSocketChat.ts`
3. âŒ **Package Scripts**: à¸­à¸±à¸à¹€à¸”à¸• `package.json` à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸±à¸™ WebSocket server

**à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸:** Next.js à¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š WebSocket natively - à¸•à¹‰à¸­à¸‡à¸ªà¸£à¹‰à¸²à¸‡ custom server à¹à¸¢à¸

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ React App   â”‚
â”‚ (Port 3000) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (WebSocket)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Custom WS Server     â”‚ â† ws://localhost:3001
â”‚ (Port 3001)          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (HTTP)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI API           â”‚
â”‚ (Chat Completions)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### TASK 5.1: à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ Dependencies

```bash
pnpm add -D ws @types/ws tsx concurrently
```

---

### TASK 5.2: à¸ªà¸£à¹‰à¸²à¸‡ Custom WebSocket Server

**à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ:** `apps/demo/server/websocket-server.ts`

```typescript
import { WebSocketServer } from 'ws';
import { createServer } from 'http';

const server = createServer();
const wss = new WebSocketServer({ server });

wss.on('connection', (ws) => {
  console.log('Client connected to OpenAI Chat WebSocket');

  let conversationHistory: Array<{role: string, content: string}> = [];

  ws.on('message', async (data) => {
    try {
      const message = JSON.parse(data.toString());

      switch (message.type) {
        case 'chat':
          // Add user message to history
          conversationHistory.push({
            role: 'user',
            content: message.text
          });

          // Call OpenAI
          const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
            },
            body: JSON.stringify({
              model: 'gpt-4o-mini',
              messages: [
                {
                  role: 'system',
                  content: message.system_prompt || 'You are a helpful assistant.'
                },
                ...conversationHistory
              ]
            })
          });

          const data = await response.json();
          const assistantMessage = data.choices[0].message.content;

          // Add to history
          conversationHistory.push({
            role: 'assistant',
            content: assistantMessage
          });

          // Send response
          ws.send(JSON.stringify({
            type: 'chat_response',
            text: assistantMessage
          }));
          break;

        case 'reset':
          conversationHistory = [];
          ws.send(JSON.stringify({
            type: 'reset_confirmed'
          }));
          break;
      }

    } catch (error) {
      ws.send(JSON.stringify({
        type: 'error',
        error: error.message
      }));
    }
  });

  ws.on('close', () => {
    console.log('Client disconnected');
  });
});

server.listen(3001, () => {
  console.log('WebSocket server running on port 3001');
});
```

---

### TASK 5.3: à¸­à¸±à¸à¹€à¸”à¸• package.json

**à¹à¸à¹‰à¹„à¸‚:** `apps/demo/package.json`

```json
{
  "scripts": {
    "dev": "next dev",
    "ws-server": "tsx server/websocket-server.ts",
    "dev:full": "concurrently \"pnpm dev\" \"pnpm ws-server\""
  }
}
```

**à¸£à¸±à¸™:**
```bash
# Terminal 1: Next.js
pnpm dev

# Terminal 2: WebSocket server
pnpm ws-server

# à¸«à¸£à¸·à¸­à¸£à¸±à¸™à¸à¸£à¹‰à¸­à¸¡à¸à¸±à¸™
pnpm dev:full
```

---

### TASK 5.4: à¸ªà¸£à¹‰à¸²à¸‡ React Hook

**à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ:** `apps/demo/src/liveavatar/useWebSocketChat.ts`

```typescript
import { useState, useRef, useCallback, useEffect } from 'react';

interface ChatMessage {
  role: 'user' | 'assistant';
  content: string;
  timestamp: number;
}

export function useWebSocketChat(wsUrl: string = 'ws://localhost:3001') {
  const [isConnected, setIsConnected] = useState(false);
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const wsRef = useRef<WebSocket | null>(null);

  const connect = useCallback(() => {
    const ws = new WebSocket(wsUrl);
    wsRef.current = ws;

    ws.onopen = () => {
      console.log('Connected to chat WebSocket');
      setIsConnected(true);
    };

    ws.onmessage = (event) => {
      const message = JSON.parse(event.data);

      switch (message.type) {
        case 'chat_response':
          setMessages(prev => [...prev, {
            role: 'assistant',
            content: message.text,
            timestamp: Date.now()
          }]);
          break;

        case 'error':
          console.error('Chat error:', message.error);
          break;
      }
    };

    ws.onerror = (error) => {
      console.error('WebSocket error:', error);
    };

    ws.onclose = () => {
      console.log('Disconnected from chat');
      setIsConnected(false);
    };
  }, [wsUrl]);

  const disconnect = useCallback(() => {
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }
  }, []);

  const sendMessage = useCallback((text: string, systemPrompt?: string) => {
    if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
      console.error('WebSocket not connected');
      return;
    }

    // Add user message to UI
    setMessages(prev => [...prev, {
      role: 'user',
      content: text,
      timestamp: Date.now()
    }]);

    // Send to server
    wsRef.current.send(JSON.stringify({
      type: 'chat',
      text,
      system_prompt: systemPrompt
    }));
  }, []);

  const reset = useCallback(() => {
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({
        type: 'reset'
      }));
      setMessages([]);
    }
  }, []);

  // Auto-connect on mount
  useEffect(() => {
    connect();
    return () => disconnect();
  }, [connect, disconnect]);

  return {
    isConnected,
    messages,
    connect,
    disconnect,
    sendMessage,
    reset
  };
}
```

**à¹ƒà¸Šà¹‰à¸‡à¸²à¸™:**

```typescript
import { useWebSocketChat } from '../liveavatar/useWebSocketChat';

function ChatInterface() {
  const { isConnected, messages, sendMessage, reset } = useWebSocketChat();
  const [input, setInput] = useState('');

  return (
    <div>
      <div>Status: {isConnected ? 'Connected' : 'Disconnected'}</div>

      {messages.map((msg, i) => (
        <div key={i}>
          <strong>{msg.role}:</strong> {msg.content}
        </div>
      ))}

      <input value={input} onChange={e => setInput(e.target.value)} />
      <button onClick={() => sendMessage(input)}>Send</button>
      <button onClick={reset}>Reset</button>
    </div>
  );
}
```

---

### Testing Phase 5

**1. Test WebSocket Server:**
```bash
# Install wscat
npm install -g wscat

# Start servers
pnpm dev:full

# Connect
wscat -c ws://localhost:3001

# Send message
{"type":"chat","text":"à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š","system_prompt":"You are helpful."}

# Expected: {"type":"chat_response","text":"à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š..."}
```

**2. Test in App:**
```bash
pnpm dev:full
# à¹€à¸›à¸´à¸” http://localhost:3000
# à¹ƒà¸Šà¹‰ WebSocket Chat feature
# à¸„à¸§à¸£à¹€à¸«à¹‡à¸™à¸à¸²à¸£à¸ªà¸™à¸—à¸™à¸²à¹à¸šà¸š real-time à¸à¸£à¹‰à¸­à¸¡ history
```

---

## PHASE 6: WebSocket Integration for ElevenLabs TTS âš ï¸ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸—à¸³

**Status:** âš ï¸ **à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰ Implement** - à¸•à¹‰à¸­à¸‡à¹€à¸à¸´à¹ˆà¸¡ TTS endpoint à¹ƒà¸™ WebSocket Server
**Estimated Effort:** 5-7 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡

### à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¸¡à¸µ Phase à¸™à¸µà¹‰?

Phase 3 à¹ƒà¸Šà¹‰ ElevenLabs TTS à¹à¸šà¸š **REST API** (à¸£à¸­à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸à¹ˆà¸­à¸™à¸ªà¹ˆà¸‡) à¸—à¸³à¹ƒà¸«à¹‰:
- âŒ à¸•à¹‰à¸­à¸‡à¸£à¸­à¹ƒà¸«à¹‰ TTS à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹€à¸ªà¸£à¹‡à¸ˆà¸à¹ˆà¸­à¸™
- âŒ Avatar à¹€à¸£à¸´à¹ˆà¸¡à¸à¸¹à¸”à¸Šà¹‰à¸² (user à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸§à¹ˆà¸² lag)
- âŒ Latency à¸ªà¸¹à¸‡ (1-3 à¸§à¸´à¸™à¸²à¸—à¸µ)

Phase 6 à¸ˆà¸°à¹ƒà¸Šà¹‰ **WebSocket Streaming TTS** à¸—à¸³à¹ƒà¸«à¹‰:
- âœ… Avatar à¹€à¸£à¸´à¹ˆà¸¡à¸à¸¹à¸”à¹„à¸”à¹‰à¸—à¸±à¸™à¸—à¸µà¸—à¸µà¹ˆà¹„à¸”à¹‰ audio chunk à¹à¸£à¸
- âœ… à¸¥à¸” perceived latency (à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸§à¹ˆà¸²à¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™)
- âœ… Smooth playback

### à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸¢à¸±à¸‡à¸•à¹‰à¸­à¸‡à¸ªà¸£à¹‰à¸²à¸‡

1. âŒ **à¹€à¸à¸´à¹ˆà¸¡ TTS WebSocket Endpoint** à¹ƒà¸™ `apps/demo/server/websocket-server.ts`
2. âŒ **React Hook**: `apps/demo/src/liveavatar/useWebSocketTTS.ts`
3. âŒ **Complete Integration Hook**: `apps/demo/src/liveavatar/useCompleteVoiceChat.ts`

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Text Input  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WS TTS Server        â”‚ â† ws://localhost:3001/ws-tts
â”‚ (Port 3001)          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (HTTP Streaming)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ElevenLabs API       â”‚
â”‚ (TTS Streaming)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (Audio Chunks)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HeyGen Avatar        â”‚ â† Send chunks à¸—à¸±à¸™à¸—à¸µ
â”‚ (Lip-sync)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### TASK 6.1: à¹€à¸à¸´à¹ˆà¸¡ TTS WebSocket Endpoint

**à¹à¸à¹‰à¹„à¸‚:** `apps/demo/server/websocket-server.ts`

```typescript
import { WebSocketServer } from 'ws';
import { createServer } from 'http';

const server = createServer();

// Chat WebSocket (existing)
const chatWss = new WebSocketServer({ noServer: true });
// ... existing chat code ...

// TTS WebSocket (NEW)
const ttsWss = new WebSocketServer({ noServer: true });

ttsWss.on('connection', (ws) => {
  console.log('Client connected to TTS WebSocket');

  ws.on('message', async (data) => {
    try {
      const message = JSON.parse(data.toString());

      if (message.type === 'synthesize') {
        // Call ElevenLabs streaming TTS
        const response = await fetch(
          `https://api.elevenlabs.io/v1/text-to-speech/${message.voice_id}/stream`,
          {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'xi-api-key': process.env.ELEVENLABS_API_KEY
            },
            body: JSON.stringify({
              text: message.text,
              model_id: message.model_id || 'eleven_v3',
              output_format: 'pcm_24000'
            })
          }
        );

        if (!response.body) {
          throw new Error('No response body');
        }

        // Stream audio chunks
        const reader = response.body.getReader();
        let chunkIndex = 0;

        while (true) {
          const { done, value } = await reader.read();

          if (done) {
            // Send completion signal
            ws.send(JSON.stringify({
              type: 'synthesis_complete'
            }));
            break;
          }

          // Send audio chunk to client
          const base64Chunk = Buffer.from(value).toString('base64');
          ws.send(JSON.stringify({
            type: 'audio_chunk',
            chunk_index: chunkIndex++,
            audio: base64Chunk
          }));
        }
      }

    } catch (error) {
      ws.send(JSON.stringify({
        type: 'error',
        error: error.message
      }));
    }
  });
});

// Upgrade handler (handle multiple paths)
server.on('upgrade', (request, socket, head) => {
  const pathname = new URL(request.url, 'http://localhost').pathname;

  if (pathname === '/ws-chat') {
    chatWss.handleUpgrade(request, socket, head, (ws) => {
      chatWss.emit('connection', ws, request);
    });
  } else if (pathname === '/ws-tts') {
    ttsWss.handleUpgrade(request, socket, head, (ws) => {
      ttsWss.emit('connection', ws, request);
    });
  } else {
    socket.destroy();
  }
});

server.listen(3001, () => {
  console.log('WebSocket server running on port 3001');
  console.log('  /ws-chat - OpenAI Chat');
  console.log('  /ws-tts  - ElevenLabs TTS');
});
```

---

### TASK 6.2: à¸ªà¸£à¹‰à¸²à¸‡ React Hook à¸ªà¸³à¸«à¸£à¸±à¸š Streaming TTS

**à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ:** `apps/demo/src/liveavatar/useWebSocketTTS.ts`

```typescript
import { useState, useRef, useCallback } from 'react';

interface TTSConfig {
  voiceId?: string;
  modelId?: string;
  onAudioChunk?: (chunk: string, index: number) => void;
  onComplete?: () => void;
  onError?: (error: any) => void;
}

export function useWebSocketTTS(
  wsUrl: string = 'ws://localhost:3001/ws-tts',
  config: TTSConfig = {}
) {
  const [isConnected, setIsConnected] = useState(false);
  const [isSynthesizing, setIsSynthesizing] = useState(false);
  const wsRef = useRef<WebSocket | null>(null);
  const audioChunksRef = useRef<string[]>([]);

  const connect = useCallback(() => {
    const ws = new WebSocket(wsUrl);
    wsRef.current = ws;

    ws.onopen = () => {
      console.log('Connected to TTS WebSocket');
      setIsConnected(true);
    };

    ws.onmessage = (event) => {
      const message = JSON.parse(event.data);

      switch (message.type) {
        case 'audio_chunk':
          audioChunksRef.current.push(message.audio);
          config.onAudioChunk?.(message.audio, message.chunk_index);
          break;

        case 'synthesis_complete':
          setIsSynthesizing(false);
          config.onComplete?.();
          break;

        case 'error':
          console.error('TTS error:', message.error);
          setIsSynthesizing(false);
          config.onError?.(message.error);
          break;
      }
    };

    ws.onerror = (error) => {
      console.error('WebSocket error:', error);
      config.onError?.(error);
    };

    ws.onclose = () => {
      console.log('Disconnected from TTS');
      setIsConnected(false);
    };
  }, [wsUrl, config]);

  const disconnect = useCallback(() => {
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }
  }, []);

  const synthesize = useCallback((text: string) => {
    if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
      console.error('WebSocket not connected');
      return;
    }

    audioChunksRef.current = [];
    setIsSynthesizing(true);

    wsRef.current.send(JSON.stringify({
      type: 'synthesize',
      text,
      voice_id: config.voiceId || 'pqHfZKP75CvOlQylNhV4',
      model_id: config.modelId || 'eleven_v3'
    }));
  }, [config.voiceId, config.modelId]);

  const getAudio = useCallback(() => {
    return audioChunksRef.current.join('');
  }, []);

  return {
    isConnected,
    isSynthesizing,
    connect,
    disconnect,
    synthesize,
    getAudio
  };
}
```

---

### TASK 6.3: Complete Voice Chat Integration

**à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ:** `apps/demo/src/liveavatar/useCompleteVoiceChat.ts`

```typescript
import { useState, useEffect, useCallback } from 'react';
import { useElevenLabsRealtimeSTT } from './useElevenLabsRealtimeSTT';
import { useWebSocketChat } from './useWebSocketChat';
import { useWebSocketTTS } from './useWebSocketTTS';
import { LiveAvatarSession } from '@heygen/liveavatar-web-sdk';

export function useCompleteVoiceChat(session: LiveAvatarSession) {
  const [isActive, setIsActive] = useState(false);

  // WebSocket Chat
  const chat = useWebSocketChat('ws://localhost:3001/ws-chat');

  // WebSocket TTS with Avatar integration
  const tts = useWebSocketTTS('ws://localhost:3001/ws-tts', {
    onAudioChunk: (chunk) => {
      // Send chunk to avatar immediately (streaming)
      session.sendCommand({
        type: 'agent.speak',
        event_id: 'voice-chat',
        audio: chunk
      });
    },
    onComplete: () => {
      // Signal end of speech
      session.sendCommand({
        type: 'agent.speak_end',
        event_id: 'voice-chat'
      });
    }
  });

  // Realtime STT
  const stt = useElevenLabsRealtimeSTT({
    language: 'th',
    sampleRate: 16000,

    onFinalTranscript: async (userText) => {
      console.log('User said:', userText);
      // Send to chat WebSocket
      chat.sendMessage(userText);
    }
  });

  // Listen to chat responses â†’ TTS
  useEffect(() => {
    if (chat.messages.length > 0) {
      const lastMessage = chat.messages[chat.messages.length - 1];

      if (lastMessage.role === 'assistant') {
        // Convert to speech via TTS WebSocket (streaming)
        tts.synthesize(lastMessage.content);
      }
    }
  }, [chat.messages, tts]);

  // Start complete voice chat
  const start = useCallback(async () => {
    await stt.connect();
    await chat.connect();
    await tts.connect();
    await stt.startRecording();
    setIsActive(true);
  }, [stt, chat, tts]);

  // Stop voice chat
  const stop = useCallback(() => {
    stt.stopRecording();
    stt.disconnect();
    chat.disconnect();
    tts.disconnect();
    setIsActive(false);
  }, [stt, chat, tts]);

  return {
    isActive,
    start,
    stop,
    messages: chat.messages,
    partialText: stt.partialText,
    isSpeaking: tts.isSynthesizing
  };
}
```

**à¹ƒà¸Šà¹‰à¸‡à¸²à¸™:**

```typescript
function CompleteVoiceChat({ session }: { session: LiveAvatarSession }) {
  const {
    isActive,
    start,
    stop,
    messages,
    partialText,
    isSpeaking
  } = useCompleteVoiceChat(session);

  return (
    <div>
      {!isActive ? (
        <button onClick={start}>ğŸš€ Start Real-time Voice Chat</button>
      ) : (
        <button onClick={stop}>ğŸ›‘ Stop Voice Chat</button>
      )}

      <div>
        <div>Active: {isActive ? 'Yes' : 'No'}</div>
        <div>Avatar Speaking: {isSpeaking ? 'Yes' : 'No'}</div>
        {partialText && <div>Listening: {partialText}</div>}
      </div>

      <div>
        {messages.map((msg, i) => (
          <div key={i}>
            <strong>{msg.role === 'user' ? 'You' : 'Avatar'}:</strong>
            {msg.content}
          </div>
        ))}
      </div>
    </div>
  );
}
```

---

### Testing Phase 6

**1. Test TTS WebSocket:**
```bash
# Start servers
pnpm dev:full

# Test with wscat
wscat -c ws://localhost:3001/ws-tts

# Send
{"type":"synthesize","text":"à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š","voice_id":"pqHfZKP75CvOlQylNhV4"}

# Expected: Multiple audio_chunk messages + synthesis_complete
```

**2. Test Complete Integration:**
```bash
pnpm dev:full
# à¹€à¸›à¸´à¸” http://localhost:3000
# à¹€à¸¥à¸·à¸­à¸ CUSTOM Mode
# à¸à¸” "Start Real-time Voice Chat"
# à¸à¸¹à¸” â†’ à¸•à¹‰à¸­à¸‡à¹€à¸«à¹‡à¸™:
#   1. Partial transcripts à¹à¸šà¸š real-time
#   2. AI response
#   3. Avatar à¹€à¸£à¸´à¹ˆà¸¡à¸à¸¹à¸”à¹€à¸£à¹‡à¸§à¸à¸§à¹ˆà¸²à¹€à¸”à¸´à¸¡ (streaming)
```

---

## à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸—à¸±à¹‰à¸‡à¸£à¸°à¸šà¸š

### Flow Diagram: Complete Real-time V2V

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User speaks    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ElevenLabs Realtime STT  â”‚ â† WebSocket streaming âš ï¸ Phase 4
â”‚ (Scribe v2)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Transcript
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI GPT-4o            â”‚ â† WebSocket chat âš ï¸ Phase 5
â”‚ (Chat Completion)        â”‚    (à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™à¹ƒà¸Šà¹‰ REST API âœ…)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Response text
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ElevenLabs TTS           â”‚ â† WebSocket streaming âš ï¸ Phase 6
â”‚ (Text-to-Speech)         â”‚    (à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™à¹ƒà¸Šà¹‰ REST API âœ…)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Audio chunks (PCM 24kHz)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HeyGen Avatar            â”‚ â† WebSocket commands âœ… à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™
â”‚ (Lip-sync + Video)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Video stream (LiveKit)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User sees/hears Avatar   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### à¸„à¸§à¸²à¸¡à¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¹‚à¸«à¸¡à¸”

| Feature | FULL Mode âœ… | CUSTOM Mode âœ… | CUSTOM + WebSocket âš ï¸ |
|---------|-----------|-------------|-------------------|
| **STT** | HeyGen built-in | OpenAI Whisper (batch) | ElevenLabs Scribe (realtime) |
| **AI** | HeyGen built-in | OpenAI (REST API) | OpenAI (WebSocket) |
| **TTS** | HeyGen built-in | ElevenLabs (REST API) | ElevenLabs (WebSocket streaming) |
| **Latency** | Low (1-2s) | Medium (3-5s) | Lowest (<1s) |
| **Customization** | Limited | Full | Full |
| **Complexity** | Simple | Medium | Advanced |
| **Implementation** | âœ… Done | âœ… Done | âš ï¸ Need Phase 4-6 |
| **Ready** | âœ… YES | âœ… YES | âŒ NO |

---

## ğŸ“‹ TODO List à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸à¸±à¸’à¸™à¸²à¸•à¹ˆà¸­

### High Priority (à¸ªà¸³à¸«à¸£à¸±à¸š Real-time Performance)

- [ ] **Phase 4.1**: à¸ªà¸£à¹‰à¸²à¸‡ `/api/elevenlabs-stt-token` endpoint (1-2 à¸Šà¸¡.)
- [ ] **Phase 4.2**: à¸ªà¸£à¹‰à¸²à¸‡ `useElevenLabsRealtimeSTT.ts` hook (3-4 à¸Šà¸¡.)
- [ ] **Phase 4.3**: Integration testing (1 à¸Šà¸¡.)

### Medium Priority (à¸ªà¸³à¸«à¸£à¸±à¸š Lower Latency)

- [ ] **Phase 5.1**: à¸ªà¸£à¹‰à¸²à¸‡ Custom WebSocket Server (2-3 à¸Šà¸¡.)
- [ ] **Phase 5.2**: à¸ªà¸£à¹‰à¸²à¸‡ `useWebSocketChat.ts` hook (2-3 à¸Šà¸¡.)
- [ ] **Phase 5.3**: Integration testing (1 à¸Šà¸¡.)

### Advanced (Complete Integration)

- [ ] **Phase 6.1**: à¹€à¸à¸´à¹ˆà¸¡ TTS WebSocket endpoint (2-3 à¸Šà¸¡.)
- [ ] **Phase 6.2**: à¸ªà¸£à¹‰à¸²à¸‡ `useWebSocketTTS.ts` hook (2-3 à¸Šà¸¡.)
- [ ] **Phase 6.3**: à¸ªà¸£à¹‰à¸²à¸‡ `useCompleteVoiceChat.ts` (2-3 à¸Šà¸¡.)
- [ ] **Phase 6.4**: Full system integration testing (2 à¸Šà¸¡.)

**Total Estimated Effort: 18-25 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡**

---

## à¸‚à¹‰à¸­à¸„à¸§à¸£à¸£à¸°à¸§à¸±à¸‡

1. **Token Expiration**: ElevenLabs single-use token à¸«à¸¡à¸”à¸­à¸²à¸¢à¸¸à¹ƒà¸™ 15 à¸™à¸²à¸—à¸µ - à¸•à¹‰à¸­à¸‡ refresh
2. **WebSocket Reconnection**: à¸•à¹‰à¸­à¸‡à¸¡à¸µ retry logic à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£ reconnect
3. **Audio Format**: à¸•à¹‰à¸­à¸‡à¹à¸™à¹ˆà¹ƒà¸ˆà¸§à¹ˆà¸²à¹ƒà¸Šà¹‰ PCM 24kHz à¸ªà¸³à¸«à¸£à¸±à¸š Avatar
4. **Chunk Size**: à¸ªà¹ˆà¸‡ audio à¹€à¸›à¹‡à¸™ chunks à¹† à¸¥à¸° 20ms (960 bytes)
5. **Error Handling**: à¸•à¹‰à¸­à¸‡à¸ˆà¸±à¸”à¸à¸²à¸£ error à¸—à¸¸à¸ phase
6. **Rate Limiting**: à¸£à¸°à¸§à¸±à¸‡ API rate limits à¸‚à¸­à¸‡à¸—à¸¸à¸à¸šà¸£à¸´à¸à¸²à¸£
7. **Cost**: à¸£à¸°à¸šà¸šà¸™à¸µà¹‰à¹ƒà¸Šà¹‰ 3 à¸šà¸£à¸´à¸à¸²à¸£à¸à¸£à¹‰à¸­à¸¡à¸à¸±à¸™ - à¸•à¹‰à¸­à¸‡à¸„à¸³à¸™à¸§à¸“ cost

---

## à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡

- [HeyGen LiveAvatar Docs](https://docs.heygen.com/docs/liveavatar)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [ElevenLabs Docs](https://elevenlabs.io/docs)
- [ElevenLabs Realtime STT](https://elevenlabs.io/docs/cookbooks/speech-to-text/streaming)
- [LiveKit Docs](https://docs.livekit.io)
- [WebSocket API (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [Testing Documentation](./TEST_V2V_PROCESS.md)
